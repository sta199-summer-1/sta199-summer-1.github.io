{
  "hash": "6fda30089e3baa1f2a0f2b52f9dc8354",
  "result": {
    "markdown": "---\ntitle: \"ae-23-starter\"\nformat: pdf\neditor: visual\n---\n\n\n## Two Categorical Variables: Case study: CPR and blood thinner\n\nCardiopulmonary resuscitation (CPR) is a procedure used on individuals suffering a heart attack when other emergency resources are unavailable. This procedure is helpful in providing some blood circulation to keep a person alive, but CPR chest compressions can also cause internal injuries. Internal bleeding and other injuries that can result from CPR complicate additional treatment efforts. For instance, blood thinners may be used to help release a clot that is causing the heart attack once a patient arrives in the hospital. However, blood thinners negatively affect internal injuries.\n\nHere we consider an experiment with patients who underwent CPR for a heart attack and were subsequently admitted to a hospital. Each patient was randomly assigned to either receive a blood thinner (treatment group) or not receive a blood thinner (control group). The outcome variable of interest was whether the patient died within the 24 hours.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\nv ggplot2 3.4.0     v purrr   0.3.5\nv tibble  3.1.8     v dplyr   1.0.9\nv tidyr   1.2.1     v stringr 1.4.1\nv readr   2.1.3     v forcats 0.5.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching packages -------------------------------------- tidymodels 1.0.0 --\nv broom        1.0.1     v rsample      1.1.0\nv dials        1.1.0     v tune         1.0.1\nv infer        1.0.3     v workflows    1.1.0\nv modeldata    1.0.1     v workflowsets 1.0.0\nv parsnip      1.0.3     v yardstick    1.1.0\nv recipes      1.0.3     \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'broom' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dials' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'parsnip' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'recipes' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Conflicts ----------------------------------------- tidymodels_conflicts() --\nx scales::discard() masks purrr::discard()\nx dplyr::filter()   masks stats::filter()\nx recipes::fixed()  masks stringr::fixed()\nx dplyr::lag()      masks stats::lag()\nx yardstick::spec() masks readr::spec()\nx recipes::step()   masks stats::step()\n* Use suppressPackageStartupMessages() to eliminate package startup messages\n```\n:::\n\n```{.r .cell-code}\nlibrary(openintro)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames\n```\n:::\n\n```{.r .cell-code}\ndata(cpr)\n```\n:::\n\n\nRemind ourselves of the situation:\n\nResponse Variable - outcome\n\nCategorical Variable - group\n\nSuccess - \"died\"\n\nHo: $\\pi_{yes} - \\pi_{no}$ = 0\n\nHa:$\\pi_{yes} - \\pi_{no}$ $\\neq$ 0\n\nCalculate your sample statistic below. Next, write out your sample statistic using proper notation **(control - treatment)**. \\<- fix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstat_df <- cpr |>\n  group_by(group, outcome) |>\n  summarize(props = n()) |>\n  pull(props)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'group'. You can override using the\n`.groups` argument.\n```\n:::\n\n```{.r .cell-code}\ncontrol_stat <- stat_df[1]/(stat_df[1] + stat_df[2])\noutcome_stat <- stat_df[3]/(stat_df[3] + stat_df[4])\n\nobs_stat <- control_stat - outcome_stat\n\nobs_stat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.13\n```\n:::\n:::\n\n\n$\\hat{p_{no}} - \\hat{p_{yes}}$ = 0.13\n\n## Conditions for the sampling distribution to be Normal\n\n-- Independence\n\n-- Success and failure condition\n\nWe use a special proportion called the pooled proportion to check the success-failure condition\n\np-pooled = Total number of successes (deaths) divided by the Total number of participants in the study\n\n-- Report this value below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_pool <- (stat_df[1] + stat_df[3]) / nrow(cpr) #nrow should be 90\n```\n:::\n\n\nThis proportion is an estimate of survival rate across the study if the null hypothesis is true. We then use the following formula to check this condition:\n\n$\\hat{p_{pool}}$ x $n_1$ \\> 10 ?\n\n$\\hat{p_{pool}}$ x $n_2$ \\> 10 ?\n\n$1 - \\hat{p_{pool}}$ x $n_1$ \\> 10 ?\n\n$1 - \\hat{p_{pool}}$ x $n_2$ \\> 10 ?\n\nLet's remind ourselves of each sample size...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncpr |>\n  group_by(group) |>\n  summarize(count = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n  group     count\n  <fct>     <int>\n1 control      50\n2 treatment    40\n```\n:::\n:::\n\n\nThe success-failure condition is satisfied since all values are at least 10.\n\nDo we satisfy this condition?\n\n**Yes! We expect to see at least 10 successes and failures within each group**\n\nWith both conditions satisfied, we can safely model the difference in proportions using a normal distribution.\n\n![](images/p-pool.png)\n\nCalculate the standard error under the assumption of the null hypothesis below. Your calculation should come out to 0.0952\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- sqrt(p_pool*(1-p_pool)*((1/50) + (1/40)))\n```\n:::\n\n\n![](images/z-stat.png)\n\nUsing the above information, calculate our zscore:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nzscore <- obs_stat / se\n```\n:::\n\n\nUsing the normal distribution, calculate our p-value\n\n\n::: {.cell}\n\n```{.r .cell-code}\n2*pnorm(zscore, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1712462\n```\n:::\n:::\n\n\nWhy lower.tail = FALSE?\n\n**Because we want to look above our statistic and not below!**\n\nWhy are we multiplying by 2?\n\n**Because we have a 2 sided test and are working with a symmetric distribution**\n\n# Simpler Version: 1 Categorical Variable\n\n## Bumba or Kiki\n\nHow well can humans distinguish one \"Martian\" letter from another? In today's activity, we'll find out. When shown the two Martian letters, kiki and bumba, answer the poll https://app.sli.do/event/etoay5PwN5Mg5qiYg6BnDf whether you think bumba is option 1 or option 2.\n\nOnce it's revealed which option is correct, please write our sample statistic below:\n\n**.86**\n\nLet's write out the null and alternative hypotheses below\n\nHo: $\\pi$ = 0.5\n\nHa: $\\pi$ \\> 0.5\n\nNow, let's quickly make a data frame of the data we just collected as a class. Replace the ... with the number of correct and incorrect guesses.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass_data <- tibble(\n  correct_guess = c((rep(\"Correct\" , 86)), rep(\"Incorrect\" , 14))\n\n)\n```\n:::\n\n\nNow let's simulate our null distribution by filling in the blanks. Below, detail how this distribution is created?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(333)\n\nnull_dist <- class_data |> \n  specify(response = correct_guess, success = \"Correct\") |>\n  hypothesize(null = \"point\", p = 0.5) |>\n  generate(reps = 1000, type = \"draw\") |>\n  calculate(stat = \"prop\")\n```\n:::\n\n\nHelpful Hint: Remember that you can use `?` next to the function name to pull up the help file!\n\n**Set up a \"spinner with half of it being correct and half being incorrect; spin it n = 100 times and record the new proportion of correct guesses**\n\nDo this above process 1000 times to create a distribution under the assumption of the null hypothesis!\n\nCalculate and visualize the distribution below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisualize(null_dist) +\n  shade_p_value(.86, direction = \"right\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in min(diff(unique_loc)): no non-missing arguments to min; returning Inf\n```\n:::\n\n::: {.cell-output-display}\n![](ae-23-A_files/figure-pdf/unnamed-chunk-10-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nnull_dist |>\n  get_p_value(.86, direction = \"right\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step. See\n`?get_p_value()` for more information.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n  p_value\n    <dbl>\n1       0\n```\n:::\n:::\n\n\nSo, can we read Martian?\n\n## Ted Talk\n\nhttp://www.ted.com/talks/vilayanur_ramachandran_on_your_mind\n\n# Optional (Discussion on Theory Based Methods for 1 categorical)\n\nTheory based is very similar to the two categorical variable case.\n\n![](images/se-1-cat.png)\n\n![](images/z-stat-2.png)\n",
    "supporting": [
      "ae-23-A_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}