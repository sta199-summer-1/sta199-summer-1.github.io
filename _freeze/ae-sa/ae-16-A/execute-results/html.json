{
  "hash": "6a0d35ab47b4ddbd345dfe4c3cb1deeb",
  "result": {
    "markdown": "---\ntitle: \"Suggested Answers: Prediction\"\nformat: html\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'broom' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dials' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'parsnip' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'recipes' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggridges)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggridges' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(patchwork)\nlibrary(palmerpenguins)\n```\n:::\n\n\nBy the end of today, you will...\n\n-   Understand the ideas behind testing vs training data sets\n-   (continued) fit a logistic regression model in R\n-   Evaluate your model based on predictions\n-   Evaluate linear regression model + check assumption\n\nWe will again be working with the email data set. Please re-familiarize yourself with these data below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail <- read_csv(\"data/email.csv\") |>\n  mutate(spam = factor(spam),\n         image = factor(image))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 3890 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): winner, number\ndbl  (18): spam, to_multiple, from, cc, sent_email, image, attach, dollar, i...\ndttm  (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#|label: glimpse\n\nglimpse(email)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 3,890\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         <dttm> 2012-01-01 06:16:41, 2012-01-01 07:03:59, 2012-01-01 16:…\n$ image        <fct> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       <chr> \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no…\n$ inherit      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     <dbl> 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  <dbl> 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       <dbl> 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       <chr> \"big\", \"small\", \"small\", \"small\", \"none\", \"none\", \"big\", …\n```\n:::\n:::\n\n\n## Testing vs Training\n\nBefore we decide on our model, let's build a testing and training data set using the following code.\n\n-- Go through line by line and comment what the code is doing...\n\nOnce complete, take a glimpse at each new data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(0310) # to make sure we are consist\n\nemail_split <- initial_split(email, prop = 0.80) \n\ntrain_data <- training(email_split)\ntest_data <- testing(email_split)\n\nglimpse(test_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 778\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <dbl> 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, …\n$ from         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <dbl> 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, …\n$ sent_email   <dbl> 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, …\n$ time         <dttm> 2012-01-01 16:00:32, 2012-01-01 17:55:06, 2012-01-01 18:…\n$ image        <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 9, 0, 0, 0, 0, 0, …\n$ winner       <chr> \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no…\n$ inherit      <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ num_char     <dbl> 7.773, 4.837, 2.643, 0.200, 4.549, 10.614, 45.842, 2.317,…\n$ line_breaks  <dbl> 192, 193, 68, 10, 67, 118, 881, 30, 51, 24, 411, 54, 81, …\n$ format       <dbl> 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ re_subj      <dbl> 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, …\n$ urgent_subj  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 6, 1, 0, 0, 1, 1, 5, 0, 3, 0, 49, 0, 4, 1, 8, 4, 16, 0, 3…\n$ number       <chr> \"small\", \"big\", \"small\", \"small\", \"small\", \"small\", \"big\"…\n```\n:::\n:::\n\n\nNow that our testing and training data sets have been built, let's practice picking a model!\n\nFirst, we are going to decide on our model to model the if an email is spam or not.\n\nThe variables we'll use for the first model will be:\n\n-   `spam`: 1 if the email is spam, 0 otherwise\n-   `exclaim_mess`: The number of exclamation points in the email message\n-   `winner`: Has the word \"winner\" in the email or not\n\nThe variables we'll use for the second model will be:\n\n-   `spam`: 1 if the email is spam, 0 otherwise\n-   `exclaim_mess`: The number of exclamation points in the email message\n-   `image`: Had an image attached to the email\n\nNow, fit each of these two additive generalized linear models below. Use AIC to make an argument for which model we should use to analyze if an email is spam or not.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_fit <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + winner, data = train_data, family = \"binomial\")\n\nglance(email_fit)$AIC  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1806.426\n```\n:::\n\n```{.r .cell-code}\nmodel2 <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + image, data = train_data , family = \"binomial\")\n\nglance(model2)$AIC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1848.544\n```\n:::\n:::\n\n\nName your chosen model `email_fit`.\n\n## Prediction\n\nNow, let's evaluate our model using our test data using the following code below. Comment on what the code is doing...\n\nNote: Not predicting probability of success for a single response (type = response - see ae-15); Calculating probabilities for both success and failure for all of testing data (type = \"prob)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_pred <- predict(email_fit, test_data, type = \"prob\") |>  \n  bind_cols(test_data |> select(spam))  \n```\n:::\n\n\nName the above tibble `email_pred`\n\n## How can we plot this?\n\nMake an Receiver operating characteristic (ROC) curve (plot true positive rate vs false positive rate)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_pred |>\n  roc_curve(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success?\n  ) |>\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](ae-16-A_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n**Note** Any small movement to the right indicates when a decision was made incorrectly.\n\nWhat is this ROC curve telling us?\n\nWe have more true positives than false positives. We are doing a better job than just predicting spam by flipping a coin (50-50).\n\nHow did R create this graph?\n\n**Picked a cutoff that maximizes area under the ROC curve**\n\n## Area under the curve\n\nWe can calculate the area under the curve using the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_pred |>\n  roc_auc(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success\n  ) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.650\n```\n:::\n:::\n\n\nWhat is the AUC?\n\n**0.650**\n\nThere are two things we can do with this number...\n\n-- Is this number \\> 0.5?\n\n-- How does this number compare to another AUC calculation?\n\n## Your Turn!\n\n-- Fit a competing model\n\n-- Generate an ROC plot\n\n-- Calculate the AUC and compare it to the model above\n\nHint: You can either rewrite code from above, or copy, paste, and edit to save time during class\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_class <- logistic_reg() |>\n  set_engine(\"glm\") |>\n    fit(spam ~ viagra + exclaim_mess , data = train_data , family = \"binomial\")\n\nglance(model_class)$AIC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1836.059\n```\n:::\n\n```{.r .cell-code}\nemail_pred2 <- predict(model_class, test_data, type = \"prob\") |>  \n  bind_cols(test_data |> select(spam))  \n\n\nemail_pred2 |>\n  roc_curve(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success?\n  ) |>\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](ae-16-A_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nemail_pred2 |>\n  roc_auc(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success\n  ) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.657\n```\n:::\n:::\n\n\n## Questions for next time?\n\nIn general, how does a cut point effect sensitivity (true positive)? False negatives?\n\nWe will explore this in R next time!\n\n# Only if time\n\n# Linear Regression\n\n## What if we don't have a testing data set?\n\n![](images/penguin.png){fig-align=\"center\"}\n\nThese are the data our model were trained on. Not optimal for assessing performance but it is something.\n\nEven if we don't have a test data set, we could still create a new column of predictions like before:\n\nContext of Penguins data set\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# predict based on new data\n\nmyPredictiveModel <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\npredict_peng <- penguins |>\n  mutate(myPrediction = predict(myPredictiveModel, penguins)$.pred)\n```\n:::\n\n\nFrom here we can plot $\\hat{y}$ vs $y$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_peng |>\n  ggplot(aes(x = body_mass_g, y = myPrediction)) +\n  geom_point() +\n  labs(x = \"True Body Mass\", y = \"Predicted Body Mass\", title = \"Predicted vs True Body Mass\") +\n  geom_abline(slope = 1, intercept = 0, color = \"steelblue\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](ae-16-A_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Assumptions of Linear Regression\n\nAlternatively, we could create a **residual plot**. Residual plots can be used to assess whether a linear model is appropriate.\n\nA common assumption of linear regression models is that the error term, $\\epsilon$, has constant variance everywhere.\n\n-   If the linear model is appropriate, a residual plot should show this.\n\n-   Patterned or nonconstant residual spread may sometimes be indicative a model is missing predictors or missing interactions.\n\n## Residuals\n\nCreate a new column `residuals` in `predict_peng` and save your data frame as `predict_peng_2`\n\n\n## The Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_peng_2 <- predict_peng |>\n  mutate(residuals = body_mass_g - myPrediction)\n\n\npredict_peng_2 |>\n  ggplot(aes(x = myPrediction, y = residuals)) + \n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = \"Predicted body_mass\", y = \"Residual\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](ae-16-A_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "ae-16-A_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}