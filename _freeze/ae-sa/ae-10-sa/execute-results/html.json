{
  "hash": "0623a4c01aef32aeb4cfae6de304e942",
  "result": {
    "markdown": "---\ntitle: \"Regression with MLR and Logistic Regression\"\nsubtitle: \"Suggested Answers\"\ncategories: \n  - Application exercise\neditor: visual\n---\n\n\n## Packages\n\nNote - if you don't have the plotly or widgetframe package, you can install these before running `library` by writing the following code in the console:\n\ninstall.packages(\"plotly\") install.packages(\"widgetframe\")\n\nThese packages are not necessary to finish the AE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nlibrary(plotly)\nlibrary(widgetframe)\nlibrary(ggridges)\nlibrary(patchwork)\n```\n:::\n\n\n# Finish MLR\n\nLast class, we fit MLR models with island and flipper length as explanatory variables vs our response body mass. Now, let's model body mass using 2 quantitative explanatory variables to explore the difference.\n\n## Two Quantitative Explanatory Variables\n\nHow does the picture change if our two explanatory variables are quantitative?\n\n**In this example, let's explore body mass, and it's relationship to bill length and flipper length.**\n\n-- Brainstorm, how could we visualize this?\n\nNote: This code is beyond the scope of this course!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquanplot <- plot_ly(penguins, \n                    x = ~ flipper_length_mm, y = ~ body_mass_g, z = ~bill_length_mm,\n                    marker = list(size = 3, color = \"lightgray\" , alpha = 0.5, \n                                  line = list(color = \"gray\" , width = 2))) |>\n                      add_markers() |>\n                      plotly::layout(scene = list(\n                        xaxis = list(title = \"Flipper (mm)\"),\n                        yaxis = list(title = \"Bill (mm)\"), \n                        zaxis = list(title = \"Body Mass (g)\")\n                      )) |>\n                    config(displayModeBar = FALSE)\n                  frameWidget(quanplot)\n```\n:::\n\n\nNow, fit the additive model in R below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm + bill_length_mm, data = penguins) |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)       -5737.      308.      -18.6  7.80e-54\n2 flipper_length_mm    48.1       2.01     23.9  7.56e-75\n3 bill_length_mm        6.05      5.18      1.17 2.44e- 1\n```\n:::\n:::\n\n\n*Holding bill length constant, for a 1 mm increase in flipper length, we estimate on average a 48.1 g increase in body mass*\n\nAnd finally, fit the interaction model in R below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm * bill_length_mm , data = penguins) |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 5\n  term                             estimate std.error statistic  p.value\n  <chr>                               <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                       5091.    2925.        1.74  0.0827  \n2 flipper_length_mm                   -7.31    15.0      -0.486 0.627   \n3 bill_length_mm                    -229.      63.4      -3.61  0.000347\n4 flipper_length_mm:bill_length_mm     1.20     0.322     3.72  0.000232\n```\n:::\n:::\n\n\n# Learning goals\n\nBy the end of today, you will...\n\n-   use logistic regression to fit a model for a binary response variable\n-   fit a logistic regression model in R\n-   think about using a logistic regression model for classification\n\nTo illustrate logistic regression, we will build a spam filter from email data. Today's data represent incoming emails in David Diez's (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012 . All personally identifiable information has been removed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail <- read_csv(\"data/email.csv\") |>\n  mutate(spam = factor(spam))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 3890 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): winner, number\ndbl  (18): spam, to_multiple, from, cc, sent_email, image, attach, dollar, i...\ndttm  (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(email)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 3,890\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         <dttm> 2012-01-01 06:16:41, 2012-01-01 07:03:59, 2012-01-01 16:…\n$ image        <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       <chr> \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no…\n$ inherit      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     <dbl> 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  <dbl> 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       <dbl> 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       <chr> \"big\", \"small\", \"small\", \"small\", \"none\", \"none\", \"big\", …\n```\n:::\n:::\n\n\nThe variables we'll use in this analysis are\n\n-   `spam`: 1 if the email is spam, 0 otherwise\n-   `exclaim_mess`: The number of exclamation points in the email message\n\n**We want to use the number of exclamation points in an email to predict whether or not it is spam.**\n\n## Exploratory Data Analysis\n\nLet's start by taking a look at our data. Create an density plot to investigate the relationship between `spam` and `exclaim_mess`. Additionally, calculate the mean number of exclamation points for both spam and non-spam emails.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail |>\n  ggplot(\n    aes(x = exclaim_mess , fill = spam)\n  ) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](ae-10-sa_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nemail |> \n  group_by(spam) |>\n  summarize(exmean = mean(exclaim_mess))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  spam  exmean\n  <fct>  <dbl>\n1 0       4.04\n2 1       1.27\n```\n:::\n:::\n\n\n## Let's try a linear model (but we know it won't work....)\n\nSuppose we try using a linear model to describe the relationship between the number of exclamation points and whether an email is spam. Write up a linear model that models spam by exclamation marks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(spam ~ exclaim_mess , data = email) |>\n  tidy()\n```\n:::\n\n\n**It won't run!**\n\nA visualization of a linear model is below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail |>\n  ggplot() + \n  geom_jitter(aes(x = exclaim_mess, y = spam, color = spam), alpha = 0.5) + \n  geom_smooth(aes(x = exclaim_mess, y = as.numeric(spam)), method = \"lm\", se = FALSE, color = \"black\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](ae-10-sa_files/figure-html/linear-model-1.png){width=672}\n:::\n:::\n\n\n-   Is the linear model a good fit for the data? Why or why not?\n\n**No. That line doesn't make sense**\n\n*How do you build a model to fit a binary response variable (a categorical response variable with 2 outcomes)?*\n\n# Logistic regression\n\n**Logistic regression** takes in a number of explanatory variables and outputs the log-odds of \"success\" in a binary response variable. The log-odds are then used to predict the probability of \"success\".\n\nLet's see what the logistic regression model looks like for our example:\n\nLet $p$ be the probability an email is spam.\n\n-   $\\frac{p}{1-p}$: odds an email is spam (if p = 0.7, then the odds are 0.7/(1 - 0.7) = 2.33)\n-   $\\log\\Big(\\frac{p}{1-p}\\Big)$: \"log-odds\", i.e., the natural log, an email is spam\n\nThen, the logistic regression model using the number of exclamation points as an explanatory variable is\n\n\n$$\\log\\Big(\\frac{p}{1-p}\\Big) = \\beta_0 + \\beta_1 \\times exclaim\\_mess$$\n\n\nThe probability an email is spam is\n\n\n$$p = \\frac{\\exp\\{\\beta_0 + \\beta_1 \\times exclaim\\_mess\\}}{1 + \\exp\\{\\beta_0 + \\beta_1 \\times exclaim\\_mess\\}}$$\n\n\n## Exercise 1\n\nBefore we fit a model, we need to understand what R thinks is a success....\n\nAs a factor: 'success' is interpreted as:\n\n1)  the factor not having the first level (and hence usually of having the second level). added note: this usually means the first level alphabetically, since this is how R defines factors by default.\n\nSo, let's assume you are in the situation where your response variable is \"Yes\" and \"No\". The default will be to treat \"No\" as a failure (because alphabetical), but you can treat \"No\" as the success by making it the second level using `fct_relevel`!\n\n2)  As a numerical vector with values between '0' and '1', interpreted as the proportion of successful cases (with the total number of cases given by the 'weights'). Or, R treats the value of 1 as a success.\n\n-   Let's fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\nThings to note: We are no longer doing linear regression (we are doing logistic regression); We are not fitting a linear model (we are fitting a generalized linear model); we need to specify `family = binomial` in the fit function.\n\nName this model `spam_model`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspam_model <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess , data = email, family = \"binomial\")\n\nspam_model |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    -1.91     0.0640    -29.8  9.82e-196\n2 exclaim_mess   -0.168    0.0240     -7.02 2.21e- 12\n```\n:::\n:::\n\n\n-   How does the code above differ from previous code we've used to fit regression models?\n\n\\*\\*logistc_reg(); \"glm\" , family = \"binomial\"\\*\n\n-   Now, compare your summary output to the estimated model below.\n\n\n$$\\log\\Big(\\frac{p}{1-p}\\Big) = -1.9114 - 0.1684 \\times exclaim\\_mess$$\n\n\n### Interpretation\n\nWhat does -0.1684 mean in this context?\n\n**For an additional exclaim_mess, we estimate the log odds of a spam email to decrease by 0.1684**\n\n## Exercise 2\n\nWhat is the probability the email is spam if it contains 10 exclamation points?\n\nUse R as a calculator to calculate the predicted probability (do not use predict)\n\nFirst, calculate the log odds by plugging in 10.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n-1.91 - 0.168*10\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3.59\n```\n:::\n:::\n\n\nNow, exponentiate!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(-3.59) / (1+exp(-3.59))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02685712\n```\n:::\n:::\n\n\nThe predicted probability of a spam email when the number of exclamation points equals 10 is *0.027*\n\nWe can use the predict function in R to produce the probability as well.\n\nNote, in logistic, we have to pull out the model estimates using `$fit`. The type=\"response\" option tells R to output probabilities of the form P(Y = 1\\|X), as opposed to other information such as the logit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_email <- tibble(exclaim_mess = 2)\n\npredict(spam_model$fit, new_email) # log-odds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1 \n-2.248108 \n```\n:::\n\n```{.r .cell-code}\npredict(spam_model$fit, new_email, type = \"response\") # probability\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1 \n0.0955128 \n```\n:::\n:::\n\n\n## Exercise 3 - Classification\n\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a **decision-making threshold**, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\n\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\n\nWhat are some tradeoffs you would consider as you set the decision-making threshold? Discuss with your neighbor.\n\n**AWV: Think about benefits and consequences of making a threshold to low vs to high in this context.... what about in a situation more serious?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail <- email |>\n  mutate(pred_prob = predict(spam_model$fit, type = \"response\"))\nggplot(data = email) + \n  geom_point(aes(x = exclaim_mess, y = as.numeric(spam) -1, \n                        color = spam)) + \n  geom_line(aes(x = exclaim_mess, y = pred_prob)) + \n  labs(x = \"Number of exclamation points\", \n       y = \"Predicted probability an email is spam\", \n       color = \"Is email spam?\"\n       )\n```\n\n::: {.cell-output-display}\n![](ae-10-sa_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nNext time, we will discuss how to evaluate these models with testing + training data sets!\n",
    "supporting": [
      "ae-10-sa_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}