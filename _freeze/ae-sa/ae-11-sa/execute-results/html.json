{
  "hash": "1f04fea8e332fa38ab2d563a0170b9d0",
  "result": {
    "markdown": "---\ntitle: \"Prediction\"\nsubtitle: \"Suggested Answers\"\ncategories: \n  - Application exercise\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'broom' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dials' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'parsnip' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'recipes' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggridges)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggridges' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(patchwork)\nlibrary(palmerpenguins)\n```\n:::\n\n\nBy the end of today, you will...\n\n-   Practice calculating AIC\n-   Understand the ideas behind testing vs training data sets\n-   (continued) fit a logistic regression model in R\n-   Evaluate your model based on predictions\n\nWe will again be working with the email data set. Please re-familiarize yourself with these data below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail <- read_csv(\"data/email.csv\") |>\n  mutate(spam = factor(spam),\n         image = factor(image),\n         winner = factor(winner))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 3890 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): winner, number\ndbl  (18): spam, to_multiple, from, cc, sent_email, image, attach, dollar, i...\ndttm  (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#|label: glimpse\n\nglimpse(email)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 3,890\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         <dttm> 2012-01-01 06:16:41, 2012-01-01 07:03:59, 2012-01-01 16:…\n$ image        <fct> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       <fct> no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     <dbl> 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  <dbl> 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       <dbl> 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       <chr> \"big\", \"small\", \"small\", \"small\", \"none\", \"none\", \"big\", …\n```\n:::\n:::\n\n\nMuch like in the multiple linear regression case, we can have multiple predictors to model our categorical response. See example below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + winner, data = email) |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    -1.95     0.0648    -30.1  7.33e-199\n2 exclaim_mess   -0.173    0.0239     -7.26 3.89e- 13\n3 winneryes       1.88     0.307       6.13 8.84e- 10\n```\n:::\n:::\n\n\nBased on this output, is it more or less likely an email is spam if the email contains the phrase \"winner\", after holding the number of exclamation points constant?\n\n**More likely. 1.88 is positive**\n\nWhat is the predicted probability of an email being spam if there is only 1 exclamation point, and the email contains the phrase winner?\n\nHow much does the probability increase/decrease if the email does not contain the phrase \"winner\"?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_fit <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + winner, data = email, family = \"binomial\") \n\n\nnew_email <- tibble(exclaim_mess = 1, winner = \"yes\" )\n\npredict(email_fit$fit, new_email, type = \"response\") # probability\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1 \n0.4405064 \n```\n:::\n:::\n\n\n(5-min) The person responsible for this model claims that this is the best model to classify emails as spam. Below, calculate the AIC for their model. Then, create a model that is \"better\" based on AIC evidence.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(email_fit)$AIC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2293.629\n```\n:::\n\n```{.r .cell-code}\nclass_model <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ line_breaks + dollar + winner, data = email , family = \"binomial\")\n\nglance(class_model)$AIC\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2220.657\n```\n:::\n:::\n\n\n# Prediction\n\nFor the next portion, we are going to compare predictive performance between two models.\n\nThe variables we'll use for the first model will be:\n\n-   `spam`: 1 if the email is spam, 0 otherwise\n-   `exclaim_mess`: The number of exclamation points in the email message\n-   `winner`: Has the word \"winner\" in the email or not\n\nThe variables we'll use for the second model will be:\n\n-   `spam`: 1 if the email is spam, 0 otherwise\n-   `exclaim_mess`: The number of exclamation points in the email message\n-   `image`: Had an image attached to the email\n\n## Testing vs Training\n\nLet's build a testing and training data set using the following code.\n\n-- Go through line by line and comment what the code is doing...\n\nOnce complete, take a glimpse at each new data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(0610) \n\nemail_split <- initial_split(email, prop = 0.80) \n\ntrain_data <- training(email_split)\ntest_data <- testing(email_split)\n\nglimpse(test_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 778\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n$ from         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <dbl> 0, 2, 0, 0, 2, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 1, 0, 0, 2, …\n$ sent_email   <dbl> 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, …\n$ time         <dttm> 2012-01-01 10:00:01, 2012-01-01 23:32:53, 2012-01-02 01:…\n$ image        <fct> 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 2, 0, 9, 0, 0, 0, 2, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ winner       <fct> no, no, no, no, no, no, no, no, yes, no, no, no, no, no, …\n$ inherit      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ num_char     <dbl> 1.231, 19.693, 0.596, 11.453, 7.813, 1.566, 15.420, 7.844…\n$ line_breaks  <dbl> 29, 330, 33, 344, 97, 39, 595, 142, 134, 248, 279, 68, 38…\n$ format       <dbl> 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, …\n$ re_subj      <dbl> 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ urgent_subj  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 1, 4, 2, 4, 1, 3, 9, 6, 10, 0, 2, 16, 0, 1, 4, 4, 0, 8, 4…\n$ number       <chr> \"none\", \"big\", \"small\", \"big\", \"small\", \"small\", \"big\", \"…\n```\n:::\n:::\n\n\nNow that our testing and training data sets have been built, let's practice picking a model!\n\n1)  Refit the first model with the training data. Next, fit the other additive generalized linear model below (you have fit email_fit above). Name these models email_fit and email_fit2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_fit <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + winner, data = train_data, family = \"binomial\")\n\nemail_fit2 <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + image , data = train_data, family = \"binomial\")\n```\n:::\n\n\n## Prediction\n\nNow, let's evaluate our models using our test data using the following code below. Comment on what the code is doing...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_pred <- predict(email_fit, test_data, type = \"prob\") |>  \n  bind_cols(test_data |> select(spam))  \n```\n:::\n\n\n## How can we plot this?\n\nMake an Receiver operating characteristic (ROC) curve (plot true positive rate vs false positive rate)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_pred |>\n  roc_curve(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success?\n  ) |>\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](ae-11-sa_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nWhat is this ROC curve telling us? How was the ROC curve created?\n\n**The relationship at different cutoffs between true positive and false positives**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## all of the thresholds and predictions are in these data here\n\nemail_pred |>\n  roc_curve(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success?\n  ) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 × 3\n      .threshold specificity sensitivity\n           <dbl>       <dbl>       <dbl>\n 1 -Inf              0             1    \n 2    0.00000952     0             1    \n 3    0.0000144      0.00280       1    \n 4    0.0000217      0.00420       1    \n 5    0.0000494      0.00420       0.984\n 6    0.0000917      0.00560       0.984\n 7    0.000138       0.00700       0.984\n 8    0.000209       0.00840       0.984\n 9    0.000257       0.0126        0.984\n10    0.000315       0.0182        0.984\n# … with 37 more rows\n```\n:::\n\n```{.r .cell-code}\nemail_pred |>\n  arrange(.pred_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 778 × 3\n   .pred_0    .pred_1 spam \n     <dbl>      <dbl> <fct>\n 1    1.00 0.00000952 0    \n 2    1.00 0.00000952 0    \n 3    1.00 0.0000144  0    \n 4    1.00 0.0000217  1    \n 5    1.00 0.0000494  0    \n 6    1.00 0.0000917  0    \n 7    1.00 0.000138   0    \n 8    1.00 0.000209   0    \n 9    1.00 0.000209   0    \n10    1.00 0.000209   0    \n# … with 768 more rows\n```\n:::\n:::\n\n\n## Area under the curve\n\nWe can calculate the area under the curve using the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_pred |>\n  roc_auc(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success\n  ) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.663\n```\n:::\n:::\n\n\nWhat is the AUC?\n\n**0.663**\n\nThere are two things we can do with this number...\n\n-- Is this number \\> 0.5?\n\n-- How does this number compare to another AUC calculation?\n\n# Check Linear Regression Models\n\n## What if we don't have a testing data set?\n\n![](images/penguin.png){fig-align=\"center\"}\n\nThese are the data our model were trained on. Not optimal for assessing performance but it is something.\n\nEven if we don't have a test data set, we could still create a new column of predictions like before:\n\nContext of Penguins data set\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# predict based on new data\n\nmyPredictiveModel <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\npredict_peng <- penguins |>\n  mutate(myPrediction = predict(myPredictiveModel, penguins)$.pred)\n```\n:::\n\n\nFrom here we can plot $\\hat{y}$ vs $y$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_peng |>\n  ggplot(aes(x = body_mass_g, y = myPrediction)) +\n  geom_point() +\n  labs(x = \"True Body Mass\", y = \"Predicted Body Mass\", title = \"Predicted vs True Body Mass\") +\n  geom_abline(slope = 1, intercept = 0, color = \"steelblue\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](ae-11-sa_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Assumptions of Linear Regression\n\nAlternatively, we could create a **residual plot**. Residual plots can be used to assess whether a linear model is appropriate.\n\nA common assumption of linear regression models is that the error term, $\\epsilon$, has constant variance everywhere.\n\n-   If the linear model is appropriate, a residual plot should show this.\n\n-   **Patterned or non-constant residual spread may sometimes be indicative a model is missing predictors or missing interactions.**\n\n## Residuals\n\nCreate a new column `residuals` in `predict_peng` and save your data frame as `predict_peng_2`\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_peng_2 <- predict_peng |>\n  mutate(residuals = body_mass_g - myPrediction)\n```\n:::\n\n\n## The Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_peng_2 |>\n  ggplot(aes(x = myPrediction, y = residuals)) + \n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = \"Predicted body_mass\", y = \"Residual\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](ae-11-sa_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nNote: If you encounter a residual plot where the points in the plot have a curved pattern, it likely means that the regression model you have specified for the data is not correct.\n",
    "supporting": [
      "ae-11-sa_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}