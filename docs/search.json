[
  {
    "objectID": "ae-sa/ae-01-sa.html",
    "href": "ae-sa/ae-01-sa.html",
    "title": "Quarto & R Demo",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "ae-sa/ae-01-sa.html#render",
    "href": "ae-sa/ae-01-sa.html#render",
    "title": "Quarto & R Demo",
    "section": "Render",
    "text": "Render\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. Note: if something is wrong with your code, your document will not render."
  },
  {
    "objectID": "ae-sa/ae-01-sa.html#showing-the-margin",
    "href": "ae-sa/ae-01-sa.html#showing-the-margin",
    "title": "Quarto & R Demo",
    "section": "Showing the Margin",
    "text": "Showing the Margin\nIt is not professional to have your code run off the page. We are going to have R display the margin so we can avoid this in our rendered documents!\n\nGo to Tools\nGlobal Options\nClick Code\nClick Display\nClick Show Margin (Should have 80 margin column)\n\nNotice the line appear? It may be faint, but it’s important. If your code (not writing) goes beyond this, it will appear off the page causing you to lose points on assignments (and your document will look sloppy)."
  },
  {
    "objectID": "ae-sa/ae-01-sa.html#packages-for-class",
    "href": "ae-sa/ae-01-sa.html#packages-for-class",
    "title": "Quarto & R Demo",
    "section": "Packages for class",
    "text": "Packages for class\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   0.3.5\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tidyr' was built under R version 4.2.2\n\n\nWarning: package 'readr' was built under R version 4.2.2\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nWhat is a package? Why is it important we library packages?\nPackages in R have a lot of different functions that we want to use!\nThe term library = unpack! This tells R we want to use the functions inside the packages"
  },
  {
    "objectID": "ae-sa/ae-01-sa.html#how-to-take-notes-for-class",
    "href": "ae-sa/ae-01-sa.html#how-to-take-notes-for-class",
    "title": "Quarto & R Demo",
    "section": "How to take notes for class",
    "text": "How to take notes for class\n– These AEs are for YOU\n– Use # within a code chunk to comment codes\n– Scratch paper"
  },
  {
    "objectID": "ae-sa/ae-01-sa.html#mtcars",
    "href": "ae-sa/ae-01-sa.html#mtcars",
    "title": "Quarto & R Demo",
    "section": "mtcars",
    "text": "mtcars\nFor the remainder of the class, we will use the mtcars data set. This is a prebuilt data set in R. The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models).\nTo see more about these data, please visit here: https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars\n\nTake a glimpse of the data set using the glimpse function in R\n\nBefore we use this function, run ?glimpse in the console below. What happens?\n\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  <dbl> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp <dbl> 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat <dbl> 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   <dbl> 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\nYou can run code in a few different ways. You can click the green arrow in the code chunk; use a keyboard short cut (Ctrl+Enter for PC; Cmd+Return for Mac). For a list of other keyboard shortcuts, please visit the following: https://support.posit.co/hc/en-us/articles/200711853-Keyboard-Shortcuts-in-the-RStudio-IDE\nI HIGHLY suggest using the posted cheat sheets throughout the session linked here. Before answering the next question, please follow the link and download the dplyr cheat sheet (top right).\n\nNow, filter out the any cars who weigh more than 4000 lbs in a single pipeline. Note, wt is input in 1000s of lbs in the data set.\n\nThings to note:\n\nWhat is our data set name?\n\nmtcars\n\nWhat is our variable?\n\nwt\n\nWhat is our objective?\n\n*Remove cars that are more than 4000 lbs**\n\nmtcars |> \n  filter(wt > 4)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n\n\nWhat does “in a single pipeline” mean?\nNo “breaks” in our code\n\nNotice how the data were not overwritten by running mtcars in the console.\n\nNow, filter out the any cars who weigh more than 4000 lbs and save the new data set named large_cars.\n\nlarge_cars <- mtcars |>\n  filter(wt > 4)\n\n\nUsing your new data set, take the mean weight of cars using the summarise function. Report the mean below. Hint, look up the help file to the function, and scroll down to the examples. You are also encouraged to use the cheat sheet.\n\n\nlarge_cars |> \n  summarise(avg = mean(wt))\n\n      avg\n1 5.02225"
  },
  {
    "objectID": "ae-sa/ae-01-sa.html#lets-make-a-plot",
    "href": "ae-sa/ae-01-sa.html#lets-make-a-plot",
    "title": "Quarto & R Demo",
    "section": "Let’s make a plot!",
    "text": "Let’s make a plot!\nA large part of this course is going to focus on data visualization. Today we are going to make our first plot in R. You are encouraged to download the ggplot cheat sheet (top left). Additionally, we will be using this resource: https://ggplot2.tidyverse.org/reference/\nLet’s make a plot of mpg. What are some plots that would be appropriate to create?\nWe could make a boxplot! Or a histogram."
  },
  {
    "objectID": "ae-sa/ae-01-sa.html#first-plot",
    "href": "ae-sa/ae-01-sa.html#first-plot",
    "title": "Quarto & R Demo",
    "section": "First Plot",
    "text": "First Plot\nLet’s walk through the steps to create a boxplot. For this exercise, we will use the mtcars data set.\n\nmtcars |>\n  ggplot(\n    aes(x = mpg)\n  ) + \n  geom_boxplot()"
  },
  {
    "objectID": "ae-sa/ae-02-sa.html",
    "href": "ae-sa/ae-02-sa.html",
    "title": "Geom AE",
    "section": "",
    "text": "For this ae, we’ll use the tidyverse and palmerpenguins packages.\nThese data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (“No Rights Reserved”) in accordance with the Palmer Station Data Policy."
  },
  {
    "objectID": "ae-sa/ae-02-sa.html#packages",
    "href": "ae-sa/ae-02-sa.html#packages",
    "title": "Geom AE",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n#The data set name is penguins\n\nWhat are the #| above?\nCode chunk arguments\nWhich ones will we use during the semester? State and define them below.\nlabel message warnings echo eval\nWhy label? Makes navigation and referencing code easier.\nBut sometimes, they can cause issues….. render your document and read the error. Why won’t the document render?"
  },
  {
    "objectID": "ae-sa/ae-02-sa.html#data",
    "href": "ae-sa/ae-02-sa.html#data",
    "title": "Geom AE",
    "section": "Data",
    "text": "Data\nThe dataset we will visualize is called penguins. Let’s glimpse() at it. Also let’s practice using the useful function of the day names() on our data set.\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\nnames(penguins)\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\""
  },
  {
    "objectID": "ae-sa/ae-02-sa.html#useful-links",
    "href": "ae-sa/ae-02-sa.html#useful-links",
    "title": "Geom AE",
    "section": "Useful links:",
    "text": "Useful links:\nhttps://ggplot2.tidyverse.org/reference/\nDon’t forget about your ggplot cheetsheet as well!"
  },
  {
    "objectID": "ae-sa/ae-02-sa.html#single-variable",
    "href": "ae-sa/ae-02-sa.html#single-variable",
    "title": "Geom AE",
    "section": "Single variable",
    "text": "Single variable\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the a single variable is called univariate analysis.\n\n\nCreate visualizations of the distribution of weights of penguins.\nBefore making a visualization of penguins’ weight, let’s brainstorm what types of would and would not be appropriate. Indicate Yes or No next to each. If no, suggest when it would be appropriate to make such a plot.\n\nScatterplot? N\nHistogram? Y\nBoxplot? Y\nBar plot? N\nSegmented Bar plot? N"
  },
  {
    "objectID": "ae-sa/ae-02-sa.html#two-variables",
    "href": "ae-sa/ae-02-sa.html#two-variables",
    "title": "Geom AE",
    "section": "Two variables",
    "text": "Two variables\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the relationship between two variables is called bivariate analysis.\n\n\nWhat if we want to make side by side boxplots to look at body mass across species? Do so below…\n\npenguins |>\n  ggplot(\n    aes(x = species, y = body_mass_g)\n  ) + \n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nWe can do more in the aesthetics then specify x and y variables. Note: aesthetic is a visual property of one of the objects in your plot. Aesthetic options are:\n\nshape\ncolor\nsize\nfill\n\nBelow, we are going to practice with each of these options.\n\nMake a histogram of penguins’ weight where the bars are filled in by species type. Set an appropriate binwidth and alpha value. At the same time, comment each line of code to articulate what it’s doing.\n\n\npenguins |>\n  ggplot( \n       aes(x = body_mass_g, fill = species )) +\n       geom_histogram(binwidth = 200, alpha = 0.3)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\nWhat happens when we change fill to color?\nWhat happens when we change fill to shape?\nWhat happens when you change the binwidth?\nWhat happens when you change alpha?\n\n\nWhat if we don’t want the overlap? We can use facet_wrap to split the histograms apart! This function takes the name of the variable you want to split by, and how many cols/rows you want your plots to show up in. Run ?facet_wrap in your console and read the first two arguments of the function. Then, use facet_wrap to split the histograms apart!\n\n\npenguins |>\n  ggplot( \n       aes(x = body_mass_g, fill = species )) +\n       geom_histogram(binwidth = 200, alpha = .7) +\n       facet_wrap(~species, ncol = 2)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIn 1-2 sentences, describe what you see in the plot you created.\nCan comment on center and skew of each distribution\n\nWe need to think critically about color when thinking about creating visualizations for a larger audience: https://ggplot2.tidyverse.org/reference/scale_viridis.html\n\nWe will do more with colors throughout the semester. Think about this is as our first introduction. We can create a colorblind friendly pallet using scale_colour_viridis_d() or scale_colour_viridis_c() depending on the type of variable we are working with. Below, comment the code below to describe what it’s doing:\n\np <- penguins |> # this is the data set | we are saving this plot as object p\n  ggplot( #this sets up my plot\n    aes(x = body_mass_g, y = bill_length_mm , color = species)\n  ) + \n    geom_point() \n\n\np\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\np + scale_colour_viridis_d()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nChange the above code to say scale_colour_viridis_c(). Does the code run? Why or why not?\nBecause species is categorical\nLet’s get practice using scale_colour_viridis_c(). Below, create a scatterplot between bill_length and bill_depth. Color the dots of the scatterplot by the penguins flipper length. Use scale_colour_viridis_c() to create a colorblind friendly pallet.\nHint: if you create points, give it a color, not a fill. In general fill changes the color within shapes, and color changes the outline. However, default points are not considered shapes.\n\npenguins |> \n  ggplot(\n    aes(x = bill_length_mm, y = bill_depth_mm, color = flipper_length_mm )\n  ) + \n  geom_point() + \n  scale_colour_viridis_c()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis is a good time to practice with size. Remove scale_colour_viridis_c() and change color = to size =. What changed?\nWe now see the size of the points change by flipper length instead of being colored by flipper length"
  },
  {
    "objectID": "ae-sa/ae-03-sa.html",
    "href": "ae-sa/ae-03-sa.html",
    "title": "Data Viz + Data Manipulation",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-03-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, May 26th at 11:59pm."
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#packages",
    "href": "ae-sa/ae-03-sa.html#packages",
    "title": "Data Viz + Data Manipulation",
    "section": "Packages",
    "text": "Packages\n\n\n\nLet’s remind ourselves what the following code chunk labels are doing above:\nlabel: load-packages - name of your code chunk warning: false - hide warnings message: false - hide messages echo: false - Code will not show up in PDF eval: false - Code will not run when you make PDF"
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#data",
    "href": "ae-sa/ae-03-sa.html#data",
    "title": "Data Viz + Data Manipulation",
    "section": "Data",
    "text": "Data\nThese data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (“No Rights Reserved”) in accordance with the Palmer Station Data Policy."
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#mapping-variables-coding-warm-up",
    "href": "ae-sa/ae-03-sa.html#mapping-variables-coding-warm-up",
    "title": "Data Viz + Data Manipulation",
    "section": "Mapping Variables (Coding Warm Up)",
    "text": "Mapping Variables (Coding Warm Up)\nBelow, the researcher is trying to create a scatterplot between flipper length and bill length. They also want to color all the points red (for some reason).\nBelow, run the two sets of code. Why does the first set of code not run?\n\npenguins |>\n  ggplot(\n    aes(x = flipper_length_mm, y = bill_length_mm , color = \"red\")\n  ) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\npenguins |>\n  ggplot(\n    aes(x = flipper_length_mm, y = bill_length_mm)\n  ) + \n  geom_point(color = \"red\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAdd response"
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#plot-recreation",
    "href": "ae-sa/ae-03-sa.html#plot-recreation",
    "title": "Data Viz + Data Manipulation",
    "section": "Plot Recreation",
    "text": "Plot Recreation\nWe can use multiple geoms on a single plot! Be deliberate about the order of plotting. Our task is to recreate the following image below. Hint: This plot uses theme_minimal and scale_color_viridis_d(option = \"D\").\nNote: Themes are a powerful way to customize the non-data components of your plots: i.e. titles, labels, fonts, background, gridlines, and legends: theme(). This is different than theme_minimal. Hint: pull up the help file for theme() and search for legend.position.\n\n\n\n\n\nMake your own code chunk below\nRecreate the plot\n\nStart your code chunk here. Make sure to give it an appropriate label:\n\npenguins |>\n  ggplot(\n    aes(x = body_mass_g , y = species, color = species)\n  ) +\n  labs(title = \"Weight Distribution of Penguins\",\n       x = \"Weight\",\n       y = \"Species\") +\n  geom_point(position = \"jitter\") +\n  geom_boxplot() +\n  scale_color_viridis_d(option = \"D\") + \n  theme_minimal() +\n  theme(legend.position = \"none\") \n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAbove, we made note to “be deliberate about the order of plotting.” Let’s show why. Switch the order of the geoms used above and re-run your code. What happened?\nAdd Response"
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#tibble-vs.-data-frame",
    "href": "ae-sa/ae-03-sa.html#tibble-vs.-data-frame",
    "title": "Data Viz + Data Manipulation",
    "section": "Tibble vs. data frame",
    "text": "Tibble vs. data frame\nA tibble is an opinionated version of the R data frame. In other words, all tibbles are data frames, but not all data frames are tibbles!\nThere are many differences between a tibble and a data frame. The main one is…\n\nWhen you print a tibble, the first ten rows and all of the columns that fit on the screen will display, along with the type of each column.\n\nLet’s look at the differences in the output when we type flights (tibble) in the console versus typing cars (data frame) in the console."
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#the-pipe-a-review",
    "href": "ae-sa/ae-03-sa.html#the-pipe-a-review",
    "title": "Data Viz + Data Manipulation",
    "section": "The pipe (a review)",
    "text": "The pipe (a review)\nBefore working with more data wrangling functions, let’s formally introduce the pipe. The pipe, |>, is an operator (a tool) for passing information from one process to another. We will use |> mainly in data pipelines to pass the output of the previous line of code as the first input of the next line of code.\nWhen reading code “in English”, say “and then” whenever you see a pipe."
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#select",
    "href": "ae-sa/ae-03-sa.html#select",
    "title": "Data Viz + Data Manipulation",
    "section": "select()",
    "text": "select()\n\nDemo: Make a data frame that only contains the variables dep_delay and arr_delay.\n\n\nflights |>\n  select(dep_delay, arr_delay)\n\n# A tibble: 336,776 × 2\n   dep_delay arr_delay\n       <dbl>     <dbl>\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# … with 336,766 more rows\n\n\n\nDemo: Make a data frame that keeps every variable except dep_delay. Call the new data frame new.data\n\n\n\nnew.data <- flights |> \n  select(-dep_delay)\n\n\nIn the console, type 1:10 and hit enter. What happened?\nDemo: Make a data frame that includes all variables between year through dep_delay (inclusive). These are all variables that provide information about the departure of each flight.\n\n\nflights |> \n  select(year:dep_delay)\n\n# A tibble: 336,776 × 6\n    year month   day dep_time sched_dep_time dep_delay\n   <int> <int> <int>    <int>          <int>     <dbl>\n 1  2013     1     1      517            515         2\n 2  2013     1     1      533            529         4\n 3  2013     1     1      542            540         2\n 4  2013     1     1      544            545        -1\n 5  2013     1     1      554            600        -6\n 6  2013     1     1      554            558        -4\n 7  2013     1     1      555            600        -5\n 8  2013     1     1      557            600        -3\n 9  2013     1     1      557            600        -3\n10  2013     1     1      558            600        -2\n# … with 336,766 more rows\n\n\n\nDemo: Use the select helper contains() to make a data frame that includes the variables associated with the arrival, i.e., contains the string \"arr_\" in the name. Reminder: Thinking about code as sentences can help make nesting functions more intuitive.\n\nHint: Run ?contains and click Select variables that match a pattern. Scroll down to the examples. Next answer the question below.\n\nflights |>\n  select(contains(\"arr_\"))\n\n# A tibble: 336,776 × 3\n   arr_time sched_arr_time arr_delay\n      <int>          <int>     <dbl>\n 1      830            819        11\n 2      850            830        20\n 3      923            850        33\n 4     1004           1022       -18\n 5      812            837       -25\n 6      740            728        12\n 7      913            854        19\n 8      709            723       -14\n 9      838            846        -8\n10      753            745         8\n# … with 336,766 more rows\n\n\n\nReview: Why is arr_in quotes?\n\nAdd response here\nThis is a good time to render and push to GitHub. Let’s go through this demonstration now. This is how you will turn in your AEs for the summer session"
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#slice",
    "href": "ae-sa/ae-03-sa.html#slice",
    "title": "Data Viz + Data Manipulation",
    "section": "slice()",
    "text": "slice()\n\nDemo: Display the first five rows of the flights data frame.\n\n\nflights |>\n  slice(1:5)\n\n# A tibble: 5 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     1     1      517         515       2     830     819      11 UA     \n2  2013     1     1      533         529       4     850     830      20 UA     \n3  2013     1     1      542         540       2     923     850      33 AA     \n4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n5  2013     1     1      554         600      -6     812     837     -25 DL     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: Display the last two rows of the flights data frame. Hint: n() produces the number of the last row in the data set.\n\n\nflights |> \n  slice((n()-1):n())\n\n# A tibble: 2 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     9    30       NA        1159      NA      NA    1344      NA MQ     \n2  2013     9    30       NA         840      NA      NA    1020      NA MQ     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n# OR\n\nflights |>\n  slice_tail(n = 2)\n\n# A tibble: 2 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     9    30       NA        1159      NA      NA    1344      NA MQ     \n2  2013     9    30       NA         840      NA      NA    1020      NA MQ     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay"
  },
  {
    "objectID": "ae-sa/ae-03-sa.html#arrange",
    "href": "ae-sa/ae-03-sa.html#arrange",
    "title": "Data Viz + Data Manipulation",
    "section": "arrange()",
    "text": "arrange()\n\nDemo: Let’s arrange the data by departure delay, so the flights with the shortest departure delays will be at the top of the data frame.\n\n\nflights |>\n  arrange(dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013    12     7     2040       2123     -43      40    2352      48 B6     \n 2  2013     2     3     2022       2055     -33    2240    2338     -58 DL     \n 3  2013    11    10     1408       1440     -32    1549    1559     -10 EV     \n 4  2013     1    11     1900       1930     -30    2233    2243     -10 DL     \n 5  2013     1    29     1703       1730     -27    1947    1957     -10 F9     \n 6  2013     8     9      729        755     -26    1002     955       7 MQ     \n 7  2013    10    23     1907       1932     -25    2143    2143       0 EV     \n 8  2013     3    30     2030       2055     -25    2213    2250     -37 MQ     \n 9  2013     3     2     1431       1455     -24    1601    1631     -30 9E     \n10  2013     5     5      934        958     -24    1225    1309     -44 B6     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: Now let’s arrange the data by descending departure delay, so the flights with the longest departure delays will be at the top. Hint, run ?desc in the console.\n\n\nflights |>\n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     9      641        900    1301    1242    1530    1272 HA     \n 2  2013     6    15     1432       1935    1137    1607    2120    1127 MQ     \n 3  2013     1    10     1121       1635    1126    1239    1810    1109 MQ     \n 4  2013     9    20     1139       1845    1014    1457    2210    1007 AA     \n 5  2013     7    22      845       1600    1005    1044    1815     989 MQ     \n 6  2013     4    10     1100       1900     960    1342    2211     931 DL     \n 7  2013     3    17     2321        810     911     135    1020     915 DL     \n 8  2013     6    27      959       1900     899    1236    2226     850 DL     \n 9  2013     7    22     2257        759     898     121    1026     895 DL     \n10  2013    12     5      756       1700     896    1058    2020     878 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\n\nYour turn (5 minutes): Create a data frame that only includes the plane tail number (tailnum), carrier (carrier), and departure delay for the flight with the longest departure delay. What is the plane tail number (tailnum) for this flight?\n\n\nflights |>\n  select(tailnum, carrier, dep_delay) |>\n  arrange(desc(dep_delay)) |>\n  slice(1) |>\n  select(tailnum)\n\n# A tibble: 1 × 1\n  tailnum\n  <chr>  \n1 N384HA"
  },
  {
    "objectID": "ae-sa/ae-04-sa.html",
    "href": "ae-sa/ae-04-sa.html",
    "title": "Dplyr + Joins",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-04-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, May 26th at 11:59pm."
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#data",
    "href": "ae-sa/ae-04-sa.html#data",
    "title": "Dplyr + Joins",
    "section": "Data",
    "text": "Data\nThese data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (“No Rights Reserved”) in accordance with the Palmer Station Data Policy."
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#filter",
    "href": "ae-sa/ae-04-sa.html#filter",
    "title": "Dplyr + Joins",
    "section": "filter()",
    "text": "filter()\n\nDemo: Filter the data frame by selecting the rows where the destination airport is RDU. Comment the code below.\n\n\nflights |>\n  filter(dest == \"RDU\")\n\n# A tibble: 8,163 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1240       1235       5    1415    1415       0 MQ     \n 9  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n10  2013     1     1     1449       1450      -1    1651    1640      11 MQ     \n# … with 8,153 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n# = is the same as <-\n\nNow, run the following code with one equals sign instead of two. Does it still work?\n(=) is a Assignment operator while (==) is a Equal to operator. (=) is used for assigning the values from right to left while (==) is used for showing equality between values.\n\nDemo: We can also filter using more than one condition. Here we select all rows where the destination airport is RDU and the arrival delay is less than 0. As we’ve learned, conditions within functions are separated by a ,.\n\n\nflights |>\n  filter(dest == \"RDU\" , arr_delay < 0 )\n\n# A tibble: 4,232 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n 9  2013     1     1     1505       1510      -5    1654    1655      -1 MQ     \n10  2013     1     1     1800       1800       0    1945    1951      -6 B6     \n# … with 4,222 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nWe can do more complex tasks using logical operators:\n\n\noperator\ndefinition\n\n\n\n<\nis less than?\n\n\n<=\nis less than or equal to?\n\n\n>\nis greater than?\n\n\n>=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?\n\n\nx & y\nis x AND y?\n\n\nx  | y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x?\n\n\n\nThe final operator only makes sense if x is logical (TRUE / FALSE).\n\n\nYour turn (4 minutes): Describe what the code is doing in words.\n\n\nflights |> # data set and \n  filter(dest %in% \"RDU\", \n         arr_delay < 0 | dep_delay < 0\n         )\n\n# A tibble: 5,308 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n 9  2013     1     1     1449       1450      -1    1651    1640      11 MQ     \n10  2013     1     1     1505       1510      -5    1654    1655      -1 MQ     \n# … with 5,298 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nWhat if we want to land at destinations of RDU and GSO? How does the below code change?\n\n\nflights |>\n  filter(dest %in% c(\"RDU\", \"GSO\"),\n         arr_delay < 0 | dep_delay < 0\n         )\n\n# A tibble: 6,203 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n 9  2013     1     1     1449       1450      -1    1651    1640      11 MQ     \n10  2013     1     1     1505       1510      -5    1654    1655      -1 MQ     \n# … with 6,193 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nWhy c?\nCombine. Use when we have a list larger than one."
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#count",
    "href": "ae-sa/ae-04-sa.html#count",
    "title": "Dplyr + Joins",
    "section": "count()",
    "text": "count()\n\nDemo: Create a frequency table of the destination locations for flights from New York.\n\n\nflights |>\n  count(dest)\n\n# A tibble: 105 × 2\n   dest      n\n   <chr> <int>\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# … with 95 more rows\n\n\n\nDemo: In which month was there the fewest number of flights? How many flights were there in that month? Hint: Type ?min into the console.\n\n\nflights |>\n  count(month) |>\n  filter(n == min(n))\n\n\nOn which date (month + day) was there the largest number of flights? How many flights were there on that day? Comment the code below.\n\n\nflights |>\n  count(month, day) |>\n  filter(n == max(n))\n\n# A tibble: 1 × 3\n  month   day     n\n  <int> <int> <int>\n1    11    27  1014"
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#mutate",
    "href": "ae-sa/ae-04-sa.html#mutate",
    "title": "Dplyr + Joins",
    "section": "mutate()",
    "text": "mutate()\nUse mutate() to create a new variable.\n\nDemo: In the code chunk below, air_time (minutes in the air) is converted to hours, and then new variable mph is created, corresponding to the miles per hour of the flight. Comment each line of code below.\n\n\nflights |> \n  mutate(hours = air_time / 60, \n         mph = distance / hours) |>\nselect(air_time, distance, hours, mph)\n\n# A tibble: 336,776 × 4\n   air_time distance hours   mph\n      <dbl>    <dbl> <dbl> <dbl>\n 1      227     1400 3.78   370.\n 2      227     1416 3.78   374.\n 3      160     1089 2.67   408.\n 4      183     1576 3.05   517.\n 5      116      762 1.93   394.\n 6      150      719 2.5    288.\n 7      158     1065 2.63   404.\n 8       53      229 0.883  259.\n 9      140      944 2.33   405.\n10      138      733 2.3    319.\n# … with 336,766 more rows\n\n\n\n\nYour turn (4 minutes): Create a new variable to calculate the percentage of flights in each month. What percentage of flights take place in July?\n\n\nflights |> \n  count(month) |>\n  mutate(perc = (n / sum(n)) *100)\n\n# A tibble: 12 × 3\n   month     n  perc\n   <int> <int> <dbl>\n 1     1 27004  8.02\n 2     2 24951  7.41\n 3     3 28834  8.56\n 4     4 28330  8.41\n 5     5 28796  8.55\n 6     6 28243  8.39\n 7     7 29425  8.74\n 8     8 29327  8.71\n 9     9 27574  8.19\n10    10 28889  8.58\n11    11 27268  8.10\n12    12 28135  8.35\n\n\nWe can also use mutate to change the type of the same variable (think back to Monday slides)\nFirst, show / justify why we can not currently make boxplots of dep_delay by month without altering these data. Next write the following code to create boxplots of dep_delay by month.\n\nflights |> \n  mutate(month = as.factor(month)) \n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <fct> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013 1         1      517        515       2     830     819      11 UA     \n 2  2013 1         1      533        529       4     850     830      20 UA     \n 3  2013 1         1      542        540       2     923     850      33 AA     \n 4  2013 1         1      544        545      -1    1004    1022     -18 B6     \n 5  2013 1         1      554        600      -6     812     837     -25 DL     \n 6  2013 1         1      554        558      -4     740     728      12 UA     \n 7  2013 1         1      555        600      -5     913     854      19 B6     \n 8  2013 1         1      557        600      -3     709     723     -14 EV     \n 9  2013 1         1      557        600      -3     838     846      -8 B6     \n10  2013 1         1      558        600      -2     753     745       8 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\nglimpse(flights)\n\nRows: 336,776\nColumns: 19\n$ year           <int> 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ dep_time       <int> 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, …\n$ sched_dep_time <int> 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600, …\n$ dep_delay      <dbl> 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -1…\n$ arr_time       <int> 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849,…\n$ sched_arr_time <int> 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851,…\n$ arr_delay      <dbl> 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -1…\n$ carrier        <chr> \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", \"…\n$ flight         <int> 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 4…\n$ tailnum        <chr> \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N394…\n$ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\",…\n$ dest           <chr> \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\",…\n$ air_time       <dbl> 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 1…\n$ distance       <dbl> 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, …\n$ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6…\n$ minute         <dbl> 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0…\n$ time_hour      <dttm> 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 0…"
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#summarize",
    "href": "ae-sa/ae-04-sa.html#summarize",
    "title": "Dplyr + Joins",
    "section": "summarize()",
    "text": "summarize()\nsummarize() collapses the rows into summary statistics and removes columns irrelevant to the calculation.\nBelow, find the mean dep_delay time.\n\nflights |> \n  summarize(mean_dep_delay = mean(dep_delay))\n\nQuestion: Why did this code return NA?\nLet’s fix it! We can use na.rm to remove NAs.\n\nflights |> \n  summarize(mean_dep_delay = mean(dep_delay, na.rm = T))"
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#group_by",
    "href": "ae-sa/ae-04-sa.html#group_by",
    "title": "Dplyr + Joins",
    "section": "group_by()",
    "text": "group_by()\ngroup_by() is used for grouped operations. It’s very powerful when paired with summarise() to calculate summary statistics by group.\nHere we find the mean and standard deviation of departure delay for each month. Comment each line of code below.\n\nflights |> \n  group_by(month) |>\n  summarize(mean_dep_delay = mean(dep_delay, na.rm=T),\n            sd_dep_delay = sd(dep_delay, na.rm=T)\n            )\n\n# A tibble: 12 × 3\n   month mean_dep_delay sd_dep_delay\n   <int>          <dbl>        <dbl>\n 1     1          10.0          36.4\n 2     2          10.8          36.3\n 3     3          13.2          40.1\n 4     4          13.9          43.0\n 5     5          13.0          39.4\n 6     6          20.8          51.5\n 7     7          21.7          51.6\n 8     8          12.6          37.7\n 9     9           6.72         35.6\n10    10           6.24         29.7\n11    11           5.44         27.6\n12    12          16.6          41.9\n\n\n\n\nYour turn (4 minutes): What is the median departure delay for each airports around NYC (origin)?\n\n\nflights |>\n  group_by(origin) |>\n  summarize(med_dep_delay = median(dep_delay, na.rm = T))\n\n# A tibble: 3 × 2\n  origin med_dep_delay\n  <chr>          <dbl>\n1 EWR               -1\n2 JFK               -1\n3 LGA               -3"
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#joining-fisheries",
    "href": "ae-sa/ae-04-sa.html#joining-fisheries",
    "title": "Dplyr + Joins",
    "section": "Joining Fisheries",
    "text": "Joining Fisheries\n\nfisheries <- read_csv(\"data/fisheries.csv\")\n\nRows: 82 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): country\ndbl (3): capture, aquaculture, total\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncontinents <- read_csv(\"data/continents.csv\")\n\nRows: 245 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): country, continent\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#working-with-multiple-data-frames",
    "href": "ae-sa/ae-04-sa.html#working-with-multiple-data-frames",
    "title": "Dplyr + Joins",
    "section": "Working with multiple data frames",
    "text": "Working with multiple data frames\nOften instead of being provided the data you need for your analysis in a single data frame, you will need to bring information from multiple datasets together into a data frame yourself. These datasets will be linked to each other via a column (usually an identifier, something that links the two datasets together) that you can use to join them together.\nThere are many possible types of joins. All have the format something_join(x, y).\n\nx <- tibble(\n  value = c(1, 2, 3),\n  xcol = c(\"x1\", \"x2\", \"x3\")\n  )\n\ny <- tibble(\n  value = c(1, 2, 4),\n  ycol = c(\"y1\", \"y2\", \"y4\")\n  )\n\nx\n\n# A tibble: 3 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n  value ycol \n  <dbl> <chr>\n1     1 y1   \n2     2 y2   \n3     4 y4   \n\n\nWe will demonstrate each of the joins on these small, toy datasets.\nNote: These functions below know to join x and y by value because each dataset has value as a column. See for yourself!\n\nnames(x)\n\n[1] \"value\" \"xcol\" \n\nnames(y)\n\n[1] \"value\" \"ycol\" \n\n\n\ninner_join() join all rows in x where there are matching y values\n\ninner_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n\n\n\nleft_join() keeps all values of x\n\nleft_join(x , y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n\n\n\nright_join() keeps all rows of y\n\nright_join(x, y) \n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     4 <NA>  y4   \n\n\n\nfull_join() keeping all rows (both x and y)\n\nfull_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 4 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n4     4 <NA>  y4   \n\n\n\nsemi_join()returns all rows from x only that match y\n\nsemi_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n\n\n\nanti_join() reutrns all rows from x that do not match y\n\nanti_join(x,y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 1 × 2\n  value xcol \n  <dbl> <chr>\n1     3 x3"
  },
  {
    "objectID": "ae-sa/ae-04-sa.html#global-aquaculture-production",
    "href": "ae-sa/ae-04-sa.html#global-aquaculture-production",
    "title": "Dplyr + Joins",
    "section": "Global aquaculture production",
    "text": "Global aquaculture production\nThe Fisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries.\nOur goal is to create a visualization of the mean share of aquaculture by continent.\n\n\n\n\nLet’s start by looking at the fisheries data frame.\n\nglimpse(fisheries)\n\nRows: 82\nColumns: 4\n$ country     <chr> \"Angola\", \"Argentina\", \"Australia\", \"Bangladesh\", \"Brazil\"…\n$ capture     <dbl> 486490, 755226, 174629, 1674770, 705000, 629950, 233190, 8…\n$ aquaculture <dbl> 655, 3673, 96847, 2203554, 581230, 172500, 2315, 200765, 9…\n$ total       <dbl> 487145, 758899, 271476, 3878324, 1286230, 802450, 235505, …\n\n\nWe have the countries, but our goal is to make a visualization by continent. Let’s take a look at the continents data frame.\n\nglimpse(continents)\n\nRows: 245\nColumns: 2\n$ country   <chr> \"Afghanistan\", \"Åland Islands\", \"Albania\", \"Algeria\", \"Ameri…\n$ continent <chr> \"Asia\", \"Europe\", \"Europe\", \"Africa\", \"Oceania\", \"Europe\", \"…\n\n\n\n\nYour turn (2 minutes):\n\nWhich variable(s) will we use to join the fisheries and continents data frames?\nWe want to keep all rows and columns from fisheries and add a column for corresponding continents. Which join function should we use?\n\n\n\nDemo: Join the two data frames and name assign the joined data frame back to fisheries.\n\n\nfisheries <- fisheries |>\n  left_join(continents)\n\nJoining, by = \"country\"\n\n#same as the following\n\nleft_join(fisheries, continents)\n\nJoining, by = c(\"country\", \"continent\")\n\n\n# A tibble: 82 × 5\n   country    capture aquaculture   total continent\n   <chr>        <dbl>       <dbl>   <dbl> <chr>    \n 1 Angola      486490         655  487145 Africa   \n 2 Argentina   755226        3673  758899 Americas \n 3 Australia   174629       96847  271476 Oceania  \n 4 Bangladesh 1674770     2203554 3878324 Asia     \n 5 Brazil      705000      581230 1286230 Americas \n 6 Cambodia    629950      172500  802450 Asia     \n 7 Cameroon    233190        2315  235505 Africa   \n 8 Canada      874727      200765 1075492 Americas \n 9 Chad        110000          94  110094 Africa   \n10 Chile      1829238     1050117 2879355 Americas \n# … with 72 more rows"
  },
  {
    "objectID": "ae-sa/ae-05-sa.html",
    "href": "ae-sa/ae-05-sa.html",
    "title": "Joining Fisheries + Tidy Data",
    "section": "",
    "text": "The Fisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries.\nOur goal is to create a visualization of the mean share of aquaculture by continent.\n\n\n\n\n\n\nYour turn (2 minutes):\n\nWhich variable(s) will we use to join the fisheries and continents data frames?\nWe want to keep all rows and columns from fisheries and add a column for corresponding continents. Which join function should we use?\n\n\n\nDemo: Join the two data frames and name assign the joined data frame back to fisheries.\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   0.3.5\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tidyr' was built under R version 4.2.2\n\n\nWarning: package 'readr' was built under R version 4.2.2\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\n\nfisheries <- read_csv(\"data/fisheries.csv\")\n\nRows: 82 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): country\ndbl (3): capture, aquaculture, total\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncontinents <- read_csv(\"data/continents.csv\")\n\nRows: 245 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): country, continent\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nfisheries <- fisheries |>\n  left_join(continents)\n\nJoining, by = \"country\"\n\n#same as the following\n\nleft_join(fisheries, continents)\n\nJoining, by = c(\"country\", \"continent\")\n\n\n# A tibble: 82 × 5\n   country    capture aquaculture   total continent\n   <chr>        <dbl>       <dbl>   <dbl> <chr>    \n 1 Angola      486490         655  487145 Africa   \n 2 Argentina   755226        3673  758899 Americas \n 3 Australia   174629       96847  271476 Oceania  \n 4 Bangladesh 1674770     2203554 3878324 Asia     \n 5 Brazil      705000      581230 1286230 Americas \n 6 Cambodia    629950      172500  802450 Asia     \n 7 Cameroon    233190        2315  235505 Africa   \n 8 Canada      874727      200765 1075492 Americas \n 9 Chad        110000          94  110094 Africa   \n10 Chile      1829238     1050117 2879355 Americas \n# … with 72 more rows"
  },
  {
    "objectID": "ae-sa/ae-05-sa.html#break-for-if_else-practice",
    "href": "ae-sa/ae-05-sa.html#break-for-if_else-practice",
    "title": "Joining Fisheries + Tidy Data",
    "section": "Break for if_else practice",
    "text": "Break for if_else practice\nRun ?if_else if the Console.\nLet’s use the mock y data set to answer this question.\nLet’s make a new column called ind. In this column, if the input of value is larger than 3, make the input of the ind column say “yes”. If not, make it say no.\n\ny <- tibble(\n  value = c(1, 2, 4),\n  ycol = c(\"y1\", \"y2\", \"y4\")\n  )\n\nnames(y)\n\n[1] \"value\" \"ycol\" \n\nnew.data <- y |>\n  mutate(ind = if_else(value > 3, \"yes\" , \"no\"))  \n\nBelow fixes the NA with the appropriate country. Run ?case_when and comment through each line of code below.\n\nfisheries <- fisheries |> # data then\n  mutate( # create or change variables\n    continent = case_when(\n    country == \"Democratic Republic of the Congo\" ~ \"Africa\",\n    country == \"Hong Kong\" ~ \"Asia\",\n    country == \"Myanmar\" ~ \"Asia\", \n    TRUE ~ continent\n    )\n  )\n\n\n\nDemo: Add a new column to the fisheries data frame called aq_prop. We will calculate it as aquaculture / total. Save the resulting frame as fisheries.\n\n\nfisheries <- fisheries |> \n  mutate(aq_prop = aquaculture / total )\n\n\n\nYour turn (5 minutes): Now expand your calculations to also calculate the mean, minimum and maximum aquaculture proportion for continents in the fisheries data. Note that the functions for calculating minimum and maximum in R are min() and max() respectively.\n\n\nfisheries |> \n  group_by(continent) |>\n  summarize(min_aq_prop = min(aq_prop),\n            mean_aq_prop = mean(aq_prop),\n            max_aq_prop = max(aq_prop))\n\n# A tibble: 5 × 4\n  continent min_aq_prop mean_aq_prop max_aq_prop\n  <chr>           <dbl>        <dbl>       <dbl>\n1 Africa        0             0.0943       0.803\n2 Americas      0             0.192        0.529\n3 Asia          0             0.367        0.782\n4 Europe        0.00682       0.165        0.618\n5 Oceania       0.0197        0.150        0.357\n\n\n\n\nDemo: Using your code above, create a new data frame called fisheries_summary that calculates minimum, mean, and maximum aquaculture proportion for each continent in the fisheries data.\n\n\nfisheries_summary <- fisheries |> \n  group_by(continent) |>\n  summarize(min_aq_prop = min(aq_prop),\n            mean_aq_prop = mean(aq_prop),\n            max_aq_prop = max(aq_prop))\n\n\n\nDemo: Then, determine which continent has the largest value of max_ap. Take the fisheries_summary data frame and order the results in descending order of max aquaculture proportion.\n\n\nfisheries_summary |>\n  arrange(desc(max_aq_prop))\n\n# A tibble: 5 × 4\n  continent min_aq_prop mean_aq_prop max_aq_prop\n  <chr>           <dbl>        <dbl>       <dbl>\n1 Africa        0             0.0943       0.803\n2 Asia          0             0.367        0.782\n3 Europe        0.00682       0.165        0.618\n4 Americas      0             0.192        0.529\n5 Oceania       0.0197        0.150        0.357\n\n\n\n\nDemo: Recreate the following plot using the data frame you have developed so far.\n\n\n\n\n\nHint: https://ggplot2.tidyverse.org/reference/geom_bar.html\nHint: https://forcats.tidyverse.org/reference/fct_reorder.html\nHint: We can control labels using scale_x_continious or scale_y_continous. Within this function, we can change label specifications: https://scales.r-lib.org/reference/label_percent.html\n\nfisheries_summary |>\n  ggplot(\n    aes(y = fct_reorder(continent , mean_aq_prop) , x = mean_aq_prop)\n  ) +\n  geom_col() +\n  labs(title = \"Average share of aquaculture by continent\",\n       subtitle = \"out of total fisheries harvest, 2016\",\n       x = NULL, \n       y = NULL) + \n  scale_x_continuous(label = label_percent(accuracy = 1))"
  },
  {
    "objectID": "ae-sa/ae-05-sa.html#pivot-practice",
    "href": "ae-sa/ae-05-sa.html#pivot-practice",
    "title": "Joining Fisheries + Tidy Data",
    "section": "Pivot Practice",
    "text": "Pivot Practice\nRun the following code below. Are these data in long or wide format? Why?\n\nx <- tibble(\n  state = rep(c(\"MT\", \"NC\" , \"SC\"),2),\n  group = c(rep(\"C\", 3), rep(\"D\", 3)),\n  obs = c(1:6)\n  )\n\nx\n\n# A tibble: 6 × 3\n  state group   obs\n  <chr> <chr> <int>\n1 MT    C         1\n2 NC    C         2\n3 SC    C         3\n4 MT    D         4\n5 NC    D         5\n6 SC    D         6\n\n\nPivot these data so that the data are wide. i.e. Each state should be it’s own unique observation (row). Save this new data set as y.\n\ny <- x |> \n  pivot_wider(names_from = group, values_from = obs)\n\nNow, let’s change it back. Introducing pivot_longer. There are three things we need to consider with pivot_longer:\n\nWhat the columns will be\nnames_to\nvalues_to\n\nHint: !variable.name can be read as “not this variable” or “everything but this variable”\n\ny |>\n  pivot_longer(cols = c(C,D), names_to = \"group\" , values_to = \"obs\")\n\n# A tibble: 6 × 3\n  state group   obs\n  <chr> <chr> <int>\n1 MT    C         1\n2 MT    D         4\n3 NC    C         2\n4 NC    D         5\n5 SC    C         3\n6 SC    D         6"
  },
  {
    "objectID": "ae-sa/ae-05-sa.html#pivot-practice-2",
    "href": "ae-sa/ae-05-sa.html#pivot-practice-2",
    "title": "Joining Fisheries + Tidy Data",
    "section": "Pivot Practice 2",
    "text": "Pivot Practice 2\nLet’s try this on a real data set.\nThe Portland Trailblazers are a National Basketball Association (NBA) sports team. These data reflect the points scored by 9 Portland Trailblazers players across the first 10 games of the 2021-2022 NBA season.\n\ntrailblazer <- read_csv(\"data/trailblazer21.csv\")\n\nRows: 9 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Player\ndbl (10): Game1_Home, Game2_Home, Game3_Away, Game4_Home, Game5_Home, Game6_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n– Take a slice at the data. Are these data in wide or long format?\n\nslice(trailblazer)\n\n# A tibble: 9 × 11\n  Player Game1…¹ Game2…² Game3…³ Game4…⁴ Game5…⁵ Game6…⁶ Game7…⁷ Game8…⁸ Game9…⁹\n  <chr>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Damia…      20      19      12      20      25      14      20      26       4\n2 CJ Mc…      24      28      20      25      14      25      20      21      27\n3 Norma…      14      16      NA      NA      12      14      22      23      25\n4 Rober…       8       6       0       3       9       6       0       6      19\n5 Jusuf…      20       9       4      17      14      13       7       6      10\n6 Cody …       5       5       8      10       9       6       0       7       0\n7 Anfer…      11      18      12      17       5      19      17      15      16\n8 Larry…       2       8       5       8       3       8       7       0       2\n9 Nassi…       7      11       5       9       8       8       4       0       7\n# … with 1 more variable: Game10_Home <dbl>, and abbreviated variable names\n#   ¹​Game1_Home, ²​Game2_Home, ³​Game3_Away, ⁴​Game4_Home, ⁵​Game5_Home,\n#   ⁶​Game6_Away, ⁷​Game7_Away, ⁸​Game8_Away, ⁹​Game9_Home\n\n\n– Pivot the data so that you have columns for Player, Game, Points. Save this as a new data set called new.blazer.\n\nnew.blazer <- trailblazer |>\n  pivot_longer(cols = !Player,\n               names_to = \"Game\", \n               values_to = \"Points\")\n\n– Suppose now that you are asked to have two separate columns within these data. One column to represent Game, and one to represent Location. Make this happen below. Save your new data set as new.blazer\nHint: Run ?separate in the Console.\n\ntrailblazer |> \n  pivot_longer(cols = !Player,\n               names_to = \"Game\",\n               values_to = \"Points\") |>\n  separate(Game, sep = \"_\", into = c(\"Game\" , \"Location\"))\n\n# A tibble: 90 × 4\n   Player         Game   Location Points\n   <chr>          <chr>  <chr>     <dbl>\n 1 Damian Lillard Game1  Home         20\n 2 Damian Lillard Game2  Home         19\n 3 Damian Lillard Game3  Away         12\n 4 Damian Lillard Game4  Home         20\n 5 Damian Lillard Game5  Home         25\n 6 Damian Lillard Game6  Away         14\n 7 Damian Lillard Game7  Away         20\n 8 Damian Lillard Game8  Away         26\n 9 Damian Lillard Game9  Home          4\n10 Damian Lillard Game10 Home         25\n# … with 80 more rows"
  },
  {
    "objectID": "ae-sa/ae-07-sa.html",
    "href": "ae-sa/ae-07-sa.html",
    "title": "AE 07: Finishing Pivoting StatSci Majors",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "ae-sa/ae-07-sa.html#goal",
    "href": "ae-sa/ae-07-sa.html#goal",
    "title": "AE 07: Finishing Pivoting StatSci Majors",
    "section": "Goal",
    "text": "Goal\nOur ultimate goal in this application exercise is to make the following data visualization."
  },
  {
    "objectID": "ae-sa/ae-07-sa.html#data",
    "href": "ae-sa/ae-07-sa.html#data",
    "title": "AE 07: Finishing Pivoting StatSci Majors",
    "section": "Data",
    "text": "Data\nThe data come from the Office of the University Registrar. They make the data available as a table that you can download as a PDF, but I’ve put the data exported in a CSV file for you. Let’s load that in.\nThe first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major). The remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2021.\nTake a look at the origional data set…."
  },
  {
    "objectID": "ae-sa/ae-07-sa.html#data-in",
    "href": "ae-sa/ae-07-sa.html#data-in",
    "title": "AE 07: Finishing Pivoting StatSci Majors",
    "section": "Data In",
    "text": "Data In\n\nstatsci <- read_csv(\"data/statsci.csv\")\n\nRows: 4 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): degree\ndbl (12): id, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nslice(statsci)\n\n# A tibble: 4 × 13\n     id degree    `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019`\n  <dbl> <chr>      <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1     1 Statisti…     NA      1     NA     NA      4      4      1     NA     NA\n2     2 Statisti…      2      2      4      1      3      6      3      4      4\n3     3 Statisti…      2      6      1     NA      5      6      6      8      8\n4     4 Statisti…      5      9      4     13     10     17     24     21     26\n# … with 2 more variables: `2020` <dbl>, `2021` <dbl>\n\n\nLast class, we got this point where we making the following draft plot. Below, please talk through the code as a sentence to situate ourselves\n\n\n\n\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |> \n  ggplot(\n    aes(x = year, y = n, color = degree_type)\n  ) + \n  geom_point() + \n  geom_line()\n\n\n\n\n\n\nYour turn (4 minutes): What aspects of the plot need to be updated to go from the draft you created above to the Goal plot at the beginning of this application exercise.\n\nAxis, legend, color, labels\n\nDemo: Update x-axis scale such that the years displayed go from 2011 to 2021 in increments of 2 years. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011,2021,2))\n\n\n\nDemo: Update line colors using the following level / color assignments. Once again, do this by adding on to your pipeline from earlier. Hint: we can use scale_color_manual when we want to manually set colors!\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\n\n\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(values = c(\"BS\" = \"cadetblue4\", \"BS2\" = \"cadetblue3\", \"AB\" = \"lightgoldenrod4\", \"AB2\" = \"lightgoldenrod3\"))\n\nNow, let’s fix the labels and add theme_minimal to the plot!\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(x = \"Graduation year\", \n       y = \"Number of majors graduating\",\n       color = \"Degree type\", \n       title = \"Statistical Science majors over the years\",\n       subtitle = \"Academic year 2011-2021\",\n       caption = \"Source: Office of the University\") +\n  theme_minimal()\n\n\n\nDemo: Finally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Set fig-width: 7 and fig-height: 5 for your plot in the chunk options. The code below does this for you. Practice reading the code as a sentence below.\n\nHint: What function have we used to work with legends?\ntheme!\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2021\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = c(0.2,0.8),\n    legend.background = element_rect(\n      fill = \"white\" , color = \"gray\"\n    )\n  )"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html",
    "href": "ae-sa/ae-08-sa.html",
    "title": "Regression with a Single Predictor",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\nToday, we will revisit the penguins data set. If needed, please re-familiarize yourself by reading the following context and taking a glimpse at the data set before we get started.\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\n\nTake a glimpse of the data set below.\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nWe are going to investigate the relationship between a penguin’s flipper length and their body mass. Specifically, we are interested in the effect flipper length has on the body mass of penguins.\n\nBased on our research question, which variable is the response variable?\n\nbody mass in the response; flipper length is the explanatory\n\nNow, visualize the relationship between the two variables. Include the “line of best fit” in your plot. Recall from a a previous lab, we can fit this line using geom_smooth. If we want to fit a straight line, use the argument method = \"lm\". Turn the standard error bars off using se=F argument.\n\n\npenguins |>\n  ggplot(\n    aes(x = flipper_length_mm, y = body_mass_g)\n  ) + \n  geom_point() + \n  geom_smooth(method = \"lm\" , se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis line estimates the relationship between our two variables. Below, we will practice writing out population and estimated models."
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#model-these-data",
    "href": "ae-sa/ae-08-sa.html#model-these-data",
    "title": "Regression with a Single Predictor",
    "section": "Model these Data",
    "text": "Model these Data\n\nWrite the population model below that explains the relationship between body mass and flipper length.\n\nHint: You can type equations within dollar signs. LaTeX equations are authored using standard Pandoc markdown syntax (the editor will automatically recognize the syntax and treat the equation as math in the code chunks). It will appear as rendered math in your document.\nUseful tips:\n“;” is a space in Pandoc markdown\nMore tips below:\n\\(x^2 \\; superscript\\)\n\\(x_2 \\; subscript\\)\n\\(\\hat{x}\\; adds\\; hat\\; to\\; x\\)\n\\(\\beta \\; this\\; is\\; beta\\)\n\\(\\epsilon\\; this\\; is\\; epsilon\\)\nExample:\n\\(\\hat{x^n} + \\beta^n = z_n + \\epsilon_i\\)\n\\(body-mass_i = \\beta_o + \\beta_1*flipper-length_i +\\epsilon_i\\)\n\nNow, fit the linear regression model and display the results. Write the estimated model output below.\n\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm, data = penguins) |>\n  tidy()\n\n# A tibble: 2 × 5\n  term              estimate std.error statistic   p.value\n  <chr>                <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        -5781.     306.       -18.9 5.59e- 55\n2 flipper_length_mm     49.7      1.52      32.7 4.37e-107\n\n\n$ = -5872 + 50.2*flipper-length $"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#how-was-this-model-fit",
    "href": "ae-sa/ae-08-sa.html#how-was-this-model-fit",
    "title": "Regression with a Single Predictor",
    "section": "How was this model fit?",
    "text": "How was this model fit?\nSee the code below. Note: this code is beyond the scope of this course, although I bet we know most of it already!\n\npenguins <- na.omit(penguins)\n\nfit <- lm(body_mass_g ~ flipper_length_mm, data = penguins)\n\n\npenguins$predicted <- predict(fit)\npenguins$residuals <- residuals(fit)\n\npenguins |>\nggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +\n  geom_segment(aes(xend = flipper_length_mm, yend = predicted), alpha = .2) +\n\n  # > Color AND size adjustments made here...\n  geom_point(aes(color = abs(residuals), size = abs(residuals))) + # size also mapped\n  scale_color_continuous(low = \"black\", high = \"red\") +\n  guides(color = \"none\", size = \"none\") +  # Size legend also removed\n  # <\n\n  geom_point(aes(y = predicted), shape = 1) +\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#model-question",
    "href": "ae-sa/ae-08-sa.html#model-question",
    "title": "Regression with a Single Predictor",
    "section": "Model question",
    "text": "Model question\nPlease write the model equation below:\n$ = -5872 + 50.2*flipper-length $"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#interpretation",
    "href": "ae-sa/ae-08-sa.html#interpretation",
    "title": "Regression with a Single Predictor",
    "section": "Interpretation",
    "text": "Interpretation\n\nInterpret the slope and the intercept in the context of the data.\n\nHint: Think about what happens to y when we increase x by 1.\nFor a 1 mm increase in flipper length, we estimate on average a 50.2 g increase in body mass\nFor a 1 mm increase in flipper length, we estimate a mean increase of 50.2 g in body mass\nFor a penguin with 0 mm flipper length, we estimate on average a body mass of -5782g.\nDoes the intercept make sense? Why or why not? In statistics, what does predicting outside the bounds of our data called?\nExtrapolation"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#prediction",
    "href": "ae-sa/ae-08-sa.html#prediction",
    "title": "Regression with a Single Predictor",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the estimated mean body mass for a penguin with a flipper length of 210?\n\n\n-5872 + 50.2*210\n\n[1] 4670\n\n\n\nWhat is the estimated mean body mass for a penguin with a flipper length of 100?\n\n\n-5872 + 50.2*100\n\n[1] -852"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#how-can-we-make-these-predictions-in-r",
    "href": "ae-sa/ae-08-sa.html#how-can-we-make-these-predictions-in-r",
    "title": "Regression with a Single Predictor",
    "section": "How can we make these predictions in R?",
    "text": "How can we make these predictions in R?\n\nFit your model in R below\nName it model1 and make sure to not use the tidy() argument when fitting your model\nNext, we can use the predict function in R\n\nSteps 1 and 2\n\nmodel1 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\nStep 3\nFill in the code below\n\npredict(model1, data.frame(flipper_length_mm = 210))"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#correlation-and-r-squared",
    "href": "ae-sa/ae-08-sa.html#correlation-and-r-squared",
    "title": "Regression with a Single Predictor",
    "section": "Correlation and r-squared",
    "text": "Correlation and r-squared\nBelow, calculate both the correlation coefficient and r-squared value between flipper length and body mass. Interpret each in the context of the problem.\n\npenguins <- na.omit(penguins)\n\npenguins |>\n  select(flipper_length_mm, body_mass_g) |>\n  cor()\n\n                  flipper_length_mm body_mass_g\nflipper_length_mm         1.0000000   0.8729789\nbody_mass_g               0.8729789   1.0000000\n\n #go to slack and post how to na.rm with Cor\n\n\nglance(model1)$r.squared\n\n[1] 0.7620922"
  },
  {
    "objectID": "ae-sa/ae-08-sa.html#next-question",
    "href": "ae-sa/ae-08-sa.html#next-question",
    "title": "Regression with a Single Predictor",
    "section": "Next Question",
    "text": "Next Question\n\nNow, we will investigate another question. A different researcher wants to look at body weight of penguins based on the island they were recorded on. What’s different between this question and the last? Hint: Think about the variable type.\n\nisland is categorical\n\nMake a dot plot, using geom_point, with species on the x-axis to investigate this relationship below. Additionally, calculate the mean body mass by island below.\n\n\npenguins |>\n  ggplot(\n    aes(\n    x = island, y = body_mass_g\n  )) + \n  geom_point()\n\n\n\n\n\nNow, fit the linear regression model and display the results. Write the estimated model output below.\n\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ island, data = penguins) |>\n  tidy()\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  <chr>              <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        4719.      49.4     95.4  2.22e-242\n2 islandDream       -1000.      75.4    -13.3  1.74e- 32\n3 islandTorgersen   -1011.     105.      -9.67 1.23e- 19\n\n\nInterpretation …\nTo Start Class on Tuesday!"
  },
  {
    "objectID": "ae-sa/ae-09-sa.html",
    "href": "ae-sa/ae-09-sa.html",
    "title": "Regression with a Multiple Predictors",
    "section": "",
    "text": "Note - if you don’t have the plotly or widgetframe package, you can install these before running library by writing the following code in the console:\ninstall.packages(“plotly”) install.packages(“widgetframe”)\nThese packages are not necessary to finish the AE.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nlibrary(plotly)\nlibrary(widgetframe)"
  },
  {
    "objectID": "ae-sa/ae-09-sa.html#finishing-slr",
    "href": "ae-sa/ae-09-sa.html#finishing-slr",
    "title": "Regression with a Multiple Predictors",
    "section": "Finishing SLR",
    "text": "Finishing SLR\nNow, fit the linear regression model and display the results.\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ island, data = penguins) |>\n  tidy()\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  <chr>              <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21\n\n\nInterpret the intercept term in the context of the problem:\nFor a penguin on the Biscoe island, the estimated mean body mass is roughly 4716 g.\nInterpret the Dream coefficient in the context of the problem:\nFor a penguin on the Dream island, the estimated mean body mass is roughly 4716 - 1003 g. OR\nFor a penguin on the Dream island, the estimated mean body mass is roughly 1003 g less than the estimated mean body mass for a penguin on the Bisoce island."
  },
  {
    "objectID": "ae-sa/ae-09-sa.html#changing-the-intercept",
    "href": "ae-sa/ae-09-sa.html#changing-the-intercept",
    "title": "Regression with a Multiple Predictors",
    "section": "Changing the intercept",
    "text": "Changing the intercept\nOften times, we want to take control of what the intercept is. We can do this by changing the levels of the categorical variable prior to fitting the model using fct_relevel. Save over the original penguins data set for this example.\n\npenguin.new <- penguins |>\n  mutate(island = fct_relevel(island, levels = \"Dream\", \"Biscoe\", \"Torgersen\"))\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ island, data = penguin.new) |>\n  tidy()\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  <chr>              <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)      3713.        56.2   66.0    1.44e-195\n2 islandBiscoe     1003.        74.2   13.5    1.42e- 33\n3 islandTorgersen    -6.53     104.    -0.0627 9.50e-  1"
  },
  {
    "objectID": "ae-sa/ae-09-sa.html#multiple-linear-regression",
    "href": "ae-sa/ae-09-sa.html#multiple-linear-regression",
    "title": "Regression with a Multiple Predictors",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nAdditive model\nIn the last class, we modeled body mass by flipper length and also by island. Could it be possible that the estimated body mass of a penguin changes by both their flipper length AND by the island they are on?\nIn multiple linear regression, we will discuss two different types of models. Additive models and interaction models. What’s the difference?\nAdditive models: The relationship between x and y does not change based on z\nInteraction models: The relationship between x and y does change by z\nNow, fit an additive model to assess the relationship between our response variable body mass, and our explanatory variables flipper length and island. Produce the summary output. Write out the estimate regression equation below.\n\nmodel1 <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm + island, data = penguins)\n\n\\(\\widehat{body\\_mass} = -4625 + 44.5*flipper\\_length - 262*Dream - 185*Torgersen\\)\n\\(I_t {1 if Torgersen; 0 else}\\)\n\\(I_d {1 if Dream; 0 else}\\)\n– Interpret the slope coefficient for flipper length in the context of the problem\nHolding island constant, for a 1 mm increase in flipper length, we estimate on average a 44.54 g increase in body mass\n– Interpret the slope coefficient for Dream island in the context of the problem\nHolding flipper length constant, we estimate the mean body mass for penguins on the dream island to be -262.18g less than those on the Biscoe island.\n– Predict the body mass of a penguin with a flipper length of 200 on the Dream island\nNote: Above….name your model and do not pipe it into tidy() if you want to use the predict function. Next, fill in the code below.\n\npredict(model1, data.frame(flipper_length_mm = 200, island = \"Dream\"))\n\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1 4021."
  },
  {
    "objectID": "ae-sa/ae-09-sa.html#interaciton-model",
    "href": "ae-sa/ae-09-sa.html#interaciton-model",
    "title": "Regression with a Multiple Predictors",
    "section": "Interaciton Model",
    "text": "Interaciton Model\nWhat changes in the R code when fitting an interaction model instead of an additive model in R?\n+ to a *\n– Now fit the interaction model. Display the summary output and write out the estimate regression equation below.\n\nint_model <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm * island, data = penguins)\n\n\\(\\widehat{body\\_mass} = -5464 + 48.5*flipper + 3551*Dream + 3218*Torg -19.4*flipper*Dream - 17.4*flipper*Torg\\)\nWhat does it mean for island and flipper length to interact? How do we interpret an interaction effect?\nThis means that the relaionship between body mass and flipper length depends on the island the penguin was located on\nNow, name your interaction model int_model and remove the tidy() from the pipeline. Use this named model to make this prediction below.\n– Predict the body mass of a penguin with a flipper length of 200 on the Dream island\n\npredict(int_model, data.frame(flipper_length_mm = 200, island = \"Dream\"))\n\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1 3915."
  },
  {
    "objectID": "ae-sa/ae-09-sa.html#how-do-we-talk-about-interaction-terms",
    "href": "ae-sa/ae-09-sa.html#how-do-we-talk-about-interaction-terms",
    "title": "Regression with a Multiple Predictors",
    "section": "How do we talk about interaction terms?",
    "text": "How do we talk about interaction terms?\nNo general interpretation like with main effects\nDiscuss in general: The relationship between mean body mass and penguin’s flipper length changes based on island + describe the plot\nWe can then use these estimates for prediction (as seen above)"
  },
  {
    "objectID": "ae-sa/ae-09-sa.html#how-can-we-choose",
    "href": "ae-sa/ae-09-sa.html#how-can-we-choose",
    "title": "Regression with a Multiple Predictors",
    "section": "How can we choose?",
    "text": "How can we choose?\n– What is R-squared (reminder)? What is adjusted R-squared?\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables).\nHow can we calculate this in R?\nHint: We can use glance(model.name)$r.squared and glance(model.name)$adj.r.squared\n\nglance(model1)$r.squared\n\n[1] 0.7742334\n\nglance(int_model)$r.squared\n\n[1] 0.7857486\n\nglance(model1)$adj.r.squared\n\n[1] 0.7722296\n\nglance(int_model)$adj.r.squared\n\n[1] 0.7825604\n\n\nWhich model should we pick? Which measure did you use to justify your decision?\nWe can use adjusted R squared to provide evidence to choose the interaction model over the additive one."
  },
  {
    "objectID": "ae-sa/ae-09-sa.html#we-can-not-use-r-squared-to-compare-models-of-different-variables",
    "href": "ae-sa/ae-09-sa.html#we-can-not-use-r-squared-to-compare-models-of-different-variables",
    "title": "Regression with a Multiple Predictors",
    "section": "We can not use R-squared to compare models of different variables",
    "text": "We can not use R-squared to compare models of different variables\n\nset.seed(333)\n\npenguins <- penguins |>\n  mutate(random = rnorm(mean = 10, sd = 2, nrow(penguins)))\n\nNow, fit an additive model that estimates body mass by flipper length, island, AND by this random variable. What is the r-squared. How does that compare to the additive model with just flipper length and island?\n\nrandom_model <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm + island + random, data = penguins) \n\nglance(random_model)$r.squared\n\n[1] 0.7742907\n\nglance(model1)$r.squared\n\n[1] 0.7742334\n\n\nThe r-squared went up, despite adding a nonsense variable! We can not use this measure to select a model when the models have a different number of variables."
  },
  {
    "objectID": "ae-sa/ae-10-sa.html",
    "href": "ae-sa/ae-10-sa.html",
    "title": "Regression with MLR and Logistic Regression",
    "section": "",
    "text": "Note - if you don’t have the plotly or widgetframe package, you can install these before running library by writing the following code in the console:\ninstall.packages(“plotly”) install.packages(“widgetframe”)\nThese packages are not necessary to finish the AE.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nlibrary(plotly)\nlibrary(widgetframe)\nlibrary(ggridges)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae-sa/ae-10-sa.html#two-quantitative-explanatory-variables",
    "href": "ae-sa/ae-10-sa.html#two-quantitative-explanatory-variables",
    "title": "Regression with MLR and Logistic Regression",
    "section": "Two Quantitative Explanatory Variables",
    "text": "Two Quantitative Explanatory Variables\nHow does the picture change if our two explanatory variables are quantitative?\nIn this example, let’s explore body mass, and it’s relationship to bill length and flipper length.\n– Brainstorm, how could we visualize this?\nNote: This code is beyond the scope of this course!\n\nquanplot <- plot_ly(penguins, \n                    x = ~ flipper_length_mm, y = ~ body_mass_g, z = ~bill_length_mm,\n                    marker = list(size = 3, color = \"lightgray\" , alpha = 0.5, \n                                  line = list(color = \"gray\" , width = 2))) |>\n                      add_markers() |>\n                      plotly::layout(scene = list(\n                        xaxis = list(title = \"Flipper (mm)\"),\n                        yaxis = list(title = \"Bill (mm)\"), \n                        zaxis = list(title = \"Body Mass (g)\")\n                      )) |>\n                    config(displayModeBar = FALSE)\n                  frameWidget(quanplot)\n\nNow, fit the additive model in R below:\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm + bill_length_mm, data = penguins) |>\n  tidy()\n\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)       -5737.      308.      -18.6  7.80e-54\n2 flipper_length_mm    48.1       2.01     23.9  7.56e-75\n3 bill_length_mm        6.05      5.18      1.17 2.44e- 1\n\n\nHolding bill length constant, for a 1 mm increase in flipper length, we estimate on average a 48.1 g increase in body mass\nAnd finally, fit the interaction model in R below:\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm * bill_length_mm , data = penguins) |>\n  tidy()\n\n# A tibble: 4 × 5\n  term                             estimate std.error statistic  p.value\n  <chr>                               <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                       5091.    2925.        1.74  0.0827  \n2 flipper_length_mm                   -7.31    15.0      -0.486 0.627   \n3 bill_length_mm                    -229.      63.4      -3.61  0.000347\n4 flipper_length_mm:bill_length_mm     1.20     0.322     3.72  0.000232"
  },
  {
    "objectID": "ae-sa/ae-10-sa.html#exploratory-data-analysis",
    "href": "ae-sa/ae-10-sa.html#exploratory-data-analysis",
    "title": "Regression with MLR and Logistic Regression",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nLet’s start by taking a look at our data. Create an density plot to investigate the relationship between spam and exclaim_mess. Additionally, calculate the mean number of exclamation points for both spam and non-spam emails.\n\nemail |>\n  ggplot(\n    aes(x = exclaim_mess , fill = spam)\n  ) + \n  geom_density()\n\n\n\nemail |> \n  group_by(spam) |>\n  summarize(exmean = mean(exclaim_mess))\n\n# A tibble: 2 × 2\n  spam  exmean\n  <fct>  <dbl>\n1 0       4.04\n2 1       1.27"
  },
  {
    "objectID": "ae-sa/ae-10-sa.html#lets-try-a-linear-model-but-we-know-it-wont-work.",
    "href": "ae-sa/ae-10-sa.html#lets-try-a-linear-model-but-we-know-it-wont-work.",
    "title": "Regression with MLR and Logistic Regression",
    "section": "Let’s try a linear model (but we know it won’t work….)",
    "text": "Let’s try a linear model (but we know it won’t work….)\nSuppose we try using a linear model to describe the relationship between the number of exclamation points and whether an email is spam. Write up a linear model that models spam by exclamation marks.\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(spam ~ exclaim_mess , data = email) |>\n  tidy()\n\nIt won’t run!\nA visualization of a linear model is below.\n\nemail |>\n  ggplot() + \n  geom_jitter(aes(x = exclaim_mess, y = spam, color = spam), alpha = 0.5) + \n  geom_smooth(aes(x = exclaim_mess, y = as.numeric(spam)), method = \"lm\", se = FALSE, color = \"black\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nIs the linear model a good fit for the data? Why or why not?\n\nNo. That line doesn’t make sense\nHow do you build a model to fit a binary response variable (a categorical response variable with 2 outcomes)?"
  },
  {
    "objectID": "ae-sa/ae-10-sa.html#exercise-1",
    "href": "ae-sa/ae-10-sa.html#exercise-1",
    "title": "Regression with MLR and Logistic Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nBefore we fit a model, we need to understand what R thinks is a success….\nAs a factor: ‘success’ is interpreted as:\n\nthe factor not having the first level (and hence usually of having the second level). added note: this usually means the first level alphabetically, since this is how R defines factors by default.\n\nSo, let’s assume you are in the situation where your response variable is “Yes” and “No”. The default will be to treat “No” as a failure (because alphabetical), but you can treat “No” as the success by making it the second level using fct_relevel!\n\nAs a numerical vector with values between ‘0’ and ‘1’, interpreted as the proportion of successful cases (with the total number of cases given by the ‘weights’). Or, R treats the value of 1 as a success.\n\n\nLet’s fit the logistic regression model using the number of exclamation points to predict the probability an email is spam.\n\nThings to note: We are no longer doing linear regression (we are doing logistic regression); We are not fitting a linear model (we are fitting a generalized linear model); we need to specify family = binomial in the fit function.\nName this model spam_model\n\nspam_model <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess , data = email, family = \"binomial\")\n\nspam_model |>\n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    -1.91     0.0640    -29.8  9.82e-196\n2 exclaim_mess   -0.168    0.0240     -7.02 2.21e- 12\n\n\n\nHow does the code above differ from previous code we’ve used to fit regression models?\n\n**logistc_reg(); “glm” , family = “binomial”*\n\nNow, compare your summary output to the estimated model below.\n\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -1.9114 - 0.1684 \\times exclaim\\_mess\\]\nInterpretation\nWhat does -0.1684 mean in this context?\nFor an additional exclaim_mess, we estimate the log odds of a spam email to decrease by 0.1684"
  },
  {
    "objectID": "ae-sa/ae-10-sa.html#exercise-2",
    "href": "ae-sa/ae-10-sa.html#exercise-2",
    "title": "Regression with MLR and Logistic Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhat is the probability the email is spam if it contains 10 exclamation points?\nUse R as a calculator to calculate the predicted probability (do not use predict)\nFirst, calculate the log odds by plugging in 10.\n\n-1.91 - 0.168*10\n\n[1] -3.59\n\n\nNow, exponentiate!\n\nexp(-3.59) / (1+exp(-3.59))\n\n[1] 0.02685712\n\n\nThe predicted probability of a spam email when the number of exclamation points equals 10 is 0.027\nWe can use the predict function in R to produce the probability as well.\nNote, in logistic, we have to pull out the model estimates using $fit. The type=“response” option tells R to output probabilities of the form P(Y = 1|X), as opposed to other information such as the logit.\n\nnew_email <- tibble(exclaim_mess = 2)\n\npredict(spam_model$fit, new_email) # log-odds\n\n        1 \n-2.248108 \n\nround(predict(spam_model$fit, new_email, type = \"response\"),3) # probability\n\n    1 \n0.096"
  },
  {
    "objectID": "ae-sa/ae-10-sa.html#exercise-3---classification",
    "href": "ae-sa/ae-10-sa.html#exercise-3---classification",
    "title": "Regression with MLR and Logistic Regression",
    "section": "Exercise 3 - Classification",
    "text": "Exercise 3 - Classification\nWe have the probability an email is spam, but ultimately we want to use the probability to classify an email as spam or not spam. Therefore, we need to set a decision-making threshold, such that an email is classified as spam if the predicted probability is greater than the threshold and not spam otherwise.\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check).\nWhat are some tradeoffs you would consider as you set the decision-making threshold? Discuss with your neighbor.\nAWV: Think about benefits and consequences of making a threshold to low vs to high in this context…. what about in a situation more serious?\n\nemail <- email |>\n  mutate(pred_prob = predict(spam_model$fit, type = \"response\"))\nggplot(data = email) + \n  geom_point(aes(x = exclaim_mess, y = as.numeric(spam) -1, \n                        color = spam)) + \n  geom_line(aes(x = exclaim_mess, y = pred_prob)) + \n  labs(x = \"Number of exclamation points\", \n       y = \"Predicted probability an email is spam\", \n       color = \"Is email spam?\"\n       )\n\n\n\n\nNext time, we will discuss how to evaluate these models with testing + training data sets!"
  },
  {
    "objectID": "ae-sa/ae-11-sa.html",
    "href": "ae-sa/ae-11-sa.html",
    "title": "Prediction",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tidyr' was built under R version 4.2.2\n\n\nWarning: package 'readr' was built under R version 4.2.2\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\nlibrary(tidymodels)\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.2.2\n\nlibrary(patchwork)\nlibrary(palmerpenguins)\nBy the end of today, you will…\nWe will again be working with the email data set. Please re-familiarize yourself with these data below:\nMuch like in the multiple linear regression case, we can have multiple predictors to model our categorical response. See example below:\nBased on this output, is it more or less likely an email is spam if the email contains the phrase “winner”, after holding the number of exclamation points constant?\nMore likely. 1.88 is positive\nWhat is the predicted probability of an email being spam if there is only 1 exclamation point, and the email contains the phrase winner?\nHow much does the probability increase/decrease if the email does not contain the phrase “winner”?\n(5-min) The person responsible for this model claims that this is the best model to classify emails as spam. Below, calculate the AIC for their model. Then, create a model that is “better” based on AIC evidence."
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#testing-vs-training",
    "href": "ae-sa/ae-11-sa.html#testing-vs-training",
    "title": "Prediction",
    "section": "Testing vs Training",
    "text": "Testing vs Training\nLet’s build a testing and training data set using the following code.\n– Go through line by line and comment what the code is doing…\nOnce complete, take a glimpse at each new data set.\n\nset.seed(0610) \n\nemail_split <- initial_split(email, prop = 0.80) \n\ntrain_data <- training(email_split)\ntest_data <- testing(email_split)\n\nglimpse(test_data)\n\nRows: 778\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n$ from         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <dbl> 0, 2, 0, 0, 2, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 1, 0, 0, 2, …\n$ sent_email   <dbl> 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, …\n$ time         <dttm> 2012-01-01 10:00:01, 2012-01-01 23:32:53, 2012-01-02 01:…\n$ image        <fct> 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 2, 0, 9, 0, 0, 0, 2, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ winner       <fct> no, no, no, no, no, no, no, no, yes, no, no, no, no, no, …\n$ inherit      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ num_char     <dbl> 1.231, 19.693, 0.596, 11.453, 7.813, 1.566, 15.420, 7.844…\n$ line_breaks  <dbl> 29, 330, 33, 344, 97, 39, 595, 142, 134, 248, 279, 68, 38…\n$ format       <dbl> 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, …\n$ re_subj      <dbl> 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ urgent_subj  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 1, 4, 2, 4, 1, 3, 9, 6, 10, 0, 2, 16, 0, 1, 4, 4, 0, 8, 4…\n$ number       <chr> \"none\", \"big\", \"small\", \"big\", \"small\", \"small\", \"big\", \"…\n\n\nNow that our testing and training data sets have been built, let’s practice picking a model!\n\nRefit the first model with the training data. Next, fit the other additive generalized linear model below (you have fit email_fit above). Name these models email_fit and email_fit2\n\n\nemail_fit <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + winner, data = train_data, family = \"binomial\")\n\nemail_fit2 <- logistic_reg() |>\n  set_engine(\"glm\") |>\n  fit(spam ~ exclaim_mess + image , data = train_data, family = \"binomial\")"
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#prediction-1",
    "href": "ae-sa/ae-11-sa.html#prediction-1",
    "title": "Prediction",
    "section": "Prediction",
    "text": "Prediction\nNow, let’s evaluate our models using our test data using the following code below. Comment on what the code is doing…\n\nemail_pred <- predict(email_fit, test_data, type = \"prob\") |>  \n  bind_cols(test_data |> select(spam))"
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#how-can-we-plot-this",
    "href": "ae-sa/ae-11-sa.html#how-can-we-plot-this",
    "title": "Prediction",
    "section": "How can we plot this?",
    "text": "How can we plot this?\nMake an Receiver operating characteristic (ROC) curve (plot true positive rate vs false positive rate)\n\nemail_pred |>\n  roc_curve(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success?\n  ) |>\n  autoplot()\n\n\n\n\nWhat is this ROC curve telling us? How was the ROC curve created?\nThe relationship at different cutoffs between true positive and false positives\n\n## all of the thresholds and predictions are in these data here\n\nemail_pred |>\n  roc_curve(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success?\n  ) \n\n# A tibble: 47 × 3\n      .threshold specificity sensitivity\n           <dbl>       <dbl>       <dbl>\n 1 -Inf              0             1    \n 2    0.00000952     0             1    \n 3    0.0000144      0.00280       1    \n 4    0.0000217      0.00420       1    \n 5    0.0000494      0.00420       0.984\n 6    0.0000917      0.00560       0.984\n 7    0.000138       0.00700       0.984\n 8    0.000209       0.00840       0.984\n 9    0.000257       0.0126        0.984\n10    0.000315       0.0182        0.984\n# … with 37 more rows\n\nemail_pred |>\n  arrange(.pred_1)\n\n# A tibble: 778 × 3\n   .pred_0    .pred_1 spam \n     <dbl>      <dbl> <fct>\n 1    1.00 0.00000952 0    \n 2    1.00 0.00000952 0    \n 3    1.00 0.0000144  0    \n 4    1.00 0.0000217  1    \n 5    1.00 0.0000494  0    \n 6    1.00 0.0000917  0    \n 7    1.00 0.000138   0    \n 8    1.00 0.000209   0    \n 9    1.00 0.000209   0    \n10    1.00 0.000209   0    \n# … with 768 more rows"
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#area-under-the-curve",
    "href": "ae-sa/ae-11-sa.html#area-under-the-curve",
    "title": "Prediction",
    "section": "Area under the curve",
    "text": "Area under the curve\nWe can calculate the area under the curve using the following code:\n\nemail_pred |>\n  roc_auc(\n    truth = spam, \n    .pred_1, \n    event_level = \"second\" #which level is a success\n  ) \n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.663\n\n\nWhat is the AUC?\n0.663\nThere are two things we can do with this number…\n– Is this number > 0.5?\n– How does this number compare to another AUC calculation?"
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#what-if-we-dont-have-a-testing-data-set",
    "href": "ae-sa/ae-11-sa.html#what-if-we-dont-have-a-testing-data-set",
    "title": "Prediction",
    "section": "What if we don’t have a testing data set?",
    "text": "What if we don’t have a testing data set?\n\n\n\n\nThese are the data our model were trained on. Not optimal for assessing performance but it is something.\nEven if we don’t have a test data set, we could still create a new column of predictions like before:\nContext of Penguins data set\n\n# predict based on new data\n\nmyPredictiveModel <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm, data = penguins)\n\npredict_peng <- penguins |>\n  mutate(myPrediction = predict(myPredictiveModel, penguins)$.pred)\n\nFrom here we can plot \\(\\hat{y}\\) vs \\(y\\):\n\npredict_peng |>\n  ggplot(aes(x = body_mass_g, y = myPrediction)) +\n  geom_point() +\n  labs(x = \"True Body Mass\", y = \"Predicted Body Mass\", title = \"Predicted vs True Body Mass\") +\n  geom_abline(slope = 1, intercept = 0, color = \"steelblue\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#assumptions-of-linear-regression",
    "href": "ae-sa/ae-11-sa.html#assumptions-of-linear-regression",
    "title": "Prediction",
    "section": "Assumptions of Linear Regression",
    "text": "Assumptions of Linear Regression\nAlternatively, we could create a residual plot. Residual plots can be used to assess whether a linear model is appropriate.\nA common assumption of linear regression models is that the error term, \\(\\epsilon\\), has constant variance everywhere.\n\nIf the linear model is appropriate, a residual plot should show this.\nPatterned or non-constant residual spread may sometimes be indicative a model is missing predictors or missing interactions."
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#residuals",
    "href": "ae-sa/ae-11-sa.html#residuals",
    "title": "Prediction",
    "section": "Residuals",
    "text": "Residuals\nCreate a new column residuals in predict_peng and save your data frame as predict_peng_2\n\npredict_peng_2 <- predict_peng |>\n  mutate(residuals = body_mass_g - myPrediction)"
  },
  {
    "objectID": "ae-sa/ae-11-sa.html#the-plot",
    "href": "ae-sa/ae-11-sa.html#the-plot",
    "title": "Prediction",
    "section": "The Plot",
    "text": "The Plot\n\npredict_peng_2 |>\n  ggplot(aes(x = myPrediction, y = residuals)) + \n  geom_point() +\n  geom_hline(yintercept = 0) +\n  labs(x = \"Predicted body_mass\", y = \"Residual\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNote: If you encounter a residual plot where the points in the plot have a curved pattern, it likely means that the regression model you have specified for the data is not correct."
  },
  {
    "objectID": "ae-sa/ae-12-sa.html",
    "href": "ae-sa/ae-12-sa.html",
    "title": "Intro to Inference: Bootstrap + Hypothesis Testing",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   0.3.5\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tidyr' was built under R version 4.2.2\n\n\nWarning: package 'readr' was built under R version 4.2.2\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.1     ✔ rsample      1.1.0\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.3     ✔ workflows    1.1.0\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.3     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "ae-sa/ae-12-sa.html#bumba-or-kiki",
    "href": "ae-sa/ae-12-sa.html#bumba-or-kiki",
    "title": "Intro to Inference: Bootstrap + Hypothesis Testing",
    "section": "Bumba or Kiki",
    "text": "Bumba or Kiki\nHow well can humans distinguish one “Martian” letter from another?\nIn today’s activity, we’ll find out. When shown the two Martian letters, kiki and bumba, please think TO YOURSELF about which letter is kiki. When asked, reveal your answer.\nOnce it’s revealed which option is correct, please write our sample statistic below:\n\\(\\hat{p}\\) = 13/14 or 0.929 the SAMPLE proportion of students who correctly identified Bumba\nLet’s write out the null and alternative hypotheses below. This is new! please take notes on all of this information as we go through it.\n\\(\\pi\\) = the TRUE proportion of students who correctly identified Bumba\n\\(H_o\\): \\(\\pi\\) = 0.5\n\\(H_a\\): \\(\\pi\\) > 0.5\nNow, let’s quickly make a data frame of the data we just collected as a class. Replace the … with the number of correct and incorrect guesses.\n\nclass_data <- tibble(\n  correct_guess = c((rep(\"Correct\" , 13)), rep(\"Incorrect\" , 1))\n\n)\n\nNow let’s simulate our null distribution by filling in the blanks. Below, detail how this distribution is created.\n\nset.seed(333)\n\nnull_dist <- class_data |>\n  specify(response = correct_guess, success = \"Correct\") |>\n  hypothesize(null = \"point\", p = 0.5) |>\n  generate(reps = 1000, type = \"draw\") |>\n  calculate(stat = \"prop\")\n\nHelpful Hint: Remember that you can use ? next to the function name to pull up the help file!\n– Assume pi = .5\n– Take a random sample with replacement n = 14 times\n– Calculate the new sample proportion\n– Do that entire process 1000 (or something large)\n– Plot it! Plot our null distribution\nCalculate and visualize the distribution below. Using this distribution, we are going to calculate a p-value.\nWhat is a p-value?\nA probability of observing our observed statistic, or something “more extreme” given the null hypothesis is true\nHow is it used to make decisions?\nWe see how small/large it is. We can compare it to a significance level (alpha).\n\nvisualize(null_dist) +\n  shade_p_value(0.929 , direction = \"right\")\n\nnull_dist |>\n  get_p_value(0.929 , direction = \"right\")\n\nBased on our p-value, let’s write an appropriate decision, conclusion, and interpretation of a p-value in the context of the problem."
  },
  {
    "objectID": "ae-sa/ae-12-sa.html#significance-level",
    "href": "ae-sa/ae-12-sa.html#significance-level",
    "title": "Intro to Inference: Bootstrap + Hypothesis Testing",
    "section": "Significance level",
    "text": "Significance level\nWhat is it?\n\\(\\alpha\\) = a measure of the strength of the evidence that must be present in your sample before rejecting the null and concluding your alternative hypothesis. This is normally 0.05, but can be set by the researcher prior to the study.\n0.001 < 0.05\nDecision: We have evidence to reject the null hypothesis that the true (population) proportion of students who can correctly identify bumba is equal to .5.\n– Always in the context of the null hypothesis\nConclusion:\nWe have evidence to conclude that the true proportion of students who correctly identify bumba is larger than .5.\n– Always in the context of the alternative hypothesis\nInterpretation: The probability of observing 13 out of 14 students correctly identifying bumba, or something larger, given that the true proportion of students who can correctly identify bumba is equal to 0.5 is 0.001.\nSo, can we read Martian?"
  },
  {
    "objectID": "ae-sa/ae-12-sa.html#ted-talk",
    "href": "ae-sa/ae-12-sa.html#ted-talk",
    "title": "Intro to Inference: Bootstrap + Hypothesis Testing",
    "section": "Ted Talk",
    "text": "Ted Talk\nhttp://www.ted.com/talks/vilayanur_ramachandran_on_your_mind"
  },
  {
    "objectID": "ae-sa/ae-12-sa.html#two-categorical-variables-case-study-cpr-and-blood-thinner",
    "href": "ae-sa/ae-12-sa.html#two-categorical-variables-case-study-cpr-and-blood-thinner",
    "title": "Intro to Inference: Bootstrap + Hypothesis Testing",
    "section": "Two Categorical Variables: Case study: CPR and blood thinner",
    "text": "Two Categorical Variables: Case study: CPR and blood thinner\nCardiopulmonary resuscitation (CPR) is a procedure used on individuals suffering a heart attack when other emergency resources are unavailable. This procedure is helpful in providing some blood circulation to keep a person alive, but CPR chest compressions can also cause internal injuries. Internal bleeding and other injuries that can result from CPR complicate additional treatment efforts. For instance, blood thinners may be used to help release a clot that is causing the heart attack once a patient arrives in the hospital. However, blood thinners negatively affect internal injuries.\nHere we consider an experiment with patients who underwent CPR for a heart attack and were subsequently admitted to a hospital. Each patient was randomly assigned to either receive a blood thinner (treatment group) or not receive a blood thinner (control group). The outcome variable of interest was whether the patient survived for at least 24 hours. We are interested in if the proportion of patients who died were different between those who were given blood thinners or not. Note: We will considered “died” as a “success”\n\ndata(cpr)\n\nNow, write out your null and alternative hypothesis in proper notation (control - treatment).\n\\(H_0\\): \\(\\pi_c - \\pi_t\\) = 0\n\\(H_a\\): \\(\\pi_c - \\pi_t\\) \\(\\neq\\) 0\nCalculate your sample statistic below. Use proper notation (control - treatment). We will considered “died” as a “success” - what we are taking the proportion of, for the remainder of this activity.\n\ncpr |> \n  group_by(group, outcome) |>\n  summarize(count = n())\n\n`summarise()` has grouped output by 'group'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   group [2]\n  group     outcome  count\n  <fct>     <fct>    <int>\n1 control   died        39\n2 control   survived    11\n3 treatment died        26\n4 treatment survived    14\n\nestimate <- .78 - .65\n\n(Note: Normally, we calculate EDA with summary statistics, but to save time, we are going to skip this part)"
  },
  {
    "objectID": "ae-sa/ae-12-sa.html#simulate",
    "href": "ae-sa/ae-12-sa.html#simulate",
    "title": "Intro to Inference: Bootstrap + Hypothesis Testing",
    "section": "Simulate",
    "text": "Simulate\nStart next class here!"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html",
    "href": "ae-sa/ae-6-sa.html",
    "title": "AE 06: Suggested Answers",
    "section": "",
    "text": "The questions are left unanswered so you can practice. The solutions are at the end of the document.\nIn this activity, we will go over how to identify and fix common coding errors. This demonstration will use the mtcars data set. In each of these code chunks, you will either need to add or alter code in order to get it running. Please take notes and treat this AE as a “common errors debugging sheet” to use in the future. There will only be one error per code chunk.\n\nFirst, let’s make a quick exploratory plot to assess these data.\n\n\nmtcars |> \n  ggplot(\n    aes(x = mpg, y = wt)\n  ) + \n  geom_point()\n\nError -\nFix -\n\n\n\n\nmtcars |>\n  ggplot(\n    aes(x = mpg, y = gears)\n  ) + \n  geom_point()\n\nError -\nFix -\n\nmtcars |>\n  ggplot(\n    aes(x = mpg, y = wt) + \n  geom_point()\n\nError -\nFix -\n\nmtcars |>\n  ggplot(\n    aes(x = mpg, y = gear)\n  ) + \n  geom_bar()\n\nError -\nFix -\n\nmtcars |>\n  filter(mpg > 17)\n\nmtcars.new |>\n  ggplot(\n    aes(x = mpg, y = wt)\n  ) + \n  geom_point()\n\nError -\nFix -\n\nmtcars \n  |>\n  ggplot(\n    aes(x = mpg, y = wt)\n  ) + \n  geom_point()\n\nError -\nFix -\n\np <- mtcars |>\n  mutate(cyl = factor(cyl)) |>\n  ggplot(\n    aes(x = mpg, y = wt, color = cyl)\n  ) + \n  geom_point() \n  \np + scale_color_viridis_c()\n\nError -\nFix -\n\nmtcars |>\n  mutate(cyl = factor(cyl)) |>\n  ggplot(\n    aes(x = mpg, y = wt color = cyl)\n  ) + \n  geom_point() \n\nError -\nFix -"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#hw-1-demo",
    "href": "ae-sa/ae-6-sa.html#hw-1-demo",
    "title": "AE 06: Suggested Answers",
    "section": "HW-1 Demo",
    "text": "HW-1 Demo\nThe following code has multiple errors. Let’s fix the code to the point where we make the following graph:\n\nStrategies:\n\nDon’t diagnose all errors at once\nGo line by line\n\nHint: There are four total errors in the code below.\n\nlibrary(openintro)\n \nduke_forest |>\n  mutate(garage = if_else(str_detect(\"Garage\"), \"Garage\", \"No garage\")) |>\n  ggplot(aes(x = \"price\", fill = garage)) +\n  geom_histogram() +\n  facet_wrap(garage, ncol = 1) +\n  labs(\n    x = Price in $,\n    y = \"\",\n    title = \"Histogram of Price of Homes by Garage or not\",\n    fill = \"Garage or not\"\n  )"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#answers",
    "href": "ae-sa/ae-6-sa.html#answers",
    "title": "AE 06: Suggested Answers",
    "section": "Answers",
    "text": "Answers\n\nNeed to library tidyverse\nVariable spelled incorrectly\nNeed to match up ()\nDoes not take argument x and y\nMust define new data set\nDon’t have pipe on own line\n_c is for continous variable. We need _d\nMissing ,\nstr_detect is missing parking variable. Need to specify which variable to search in Do not need quotes on variable name Need quotes on x axis facet_wrap needs ~ before variable"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#pivoting-statsci-majors",
    "href": "ae-sa/ae-6-sa.html#pivoting-statsci-majors",
    "title": "AE 06: Suggested Answers",
    "section": "Pivoting StatSci Majors",
    "text": "Pivoting StatSci Majors"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#packages",
    "href": "ae-sa/ae-6-sa.html#packages",
    "title": "AE 06: Suggested Answers",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#goal",
    "href": "ae-sa/ae-6-sa.html#goal",
    "title": "AE 06: Suggested Answers",
    "section": "Goal",
    "text": "Goal\nOur ultimate goal in this application exercise is to make the following data visualization."
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#data",
    "href": "ae-sa/ae-6-sa.html#data",
    "title": "AE 06: Suggested Answers",
    "section": "Data",
    "text": "Data\nThe data come from the Office of the University Registrar. They make the data available as a table that you can download as a PDF, but I’ve put the data exported in a CSV file for you. Let’s load that in.\nThe first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major). The remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2021.\n\n\nYour turn (3 minutes): Take a close look at the plot and describe what it shows in 2-3 sentences.\n\nAdd response"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#data-in",
    "href": "ae-sa/ae-6-sa.html#data-in",
    "title": "AE 06: Suggested Answers",
    "section": "Data In",
    "text": "Data In\n\nstatsci <- read_csv(\"data/statsci.csv\")\n\nRows: 4 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): degree\ndbl (12): id, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd let’s take a look at the data.\n\nglimpse(statsci)\n\nRows: 4\nColumns: 13\n$ id     <dbl> 1, 2, 3, 4\n$ degree <chr> \"Statistical Science (AB2)\", \"Statistical Science (AB)\", \"Stati…\n$ `2011` <dbl> NA, 2, 2, 5\n$ `2012` <dbl> 1, 2, 6, 9\n$ `2013` <dbl> NA, 4, 1, 4\n$ `2014` <dbl> NA, 1, NA, 13\n$ `2015` <dbl> 4, 3, 5, 10\n$ `2016` <dbl> 4, 6, 6, 17\n$ `2017` <dbl> 1, 3, 6, 24\n$ `2018` <dbl> NA, 4, 8, 21\n$ `2019` <dbl> NA, 4, 8, 26\n$ `2020` <dbl> 1, 1, 17, 27\n$ `2021` <dbl> 2, NA, 16, 35\n\nslice(statsci)\n\n# A tibble: 4 × 13\n     id degree    `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018` `2019`\n  <dbl> <chr>      <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1     1 Statisti…     NA      1     NA     NA      4      4      1     NA     NA\n2     2 Statisti…      2      2      4      1      3      6      3      4      4\n3     3 Statisti…      2      6      1     NA      5      6      6      8      8\n4     4 Statisti…      5      9      4     13     10     17     24     21     26\n# … with 2 more variables: `2020` <dbl>, `2021` <dbl>\n\n\nWrite a sentence using inline code that shares the number or rows and columns in these data.\nThese data have 4 rows and 13 columns.\n\n\nYour turn (4 minutes): Take a look at the plot we aim to make and sketch / think about the data frame we need to make the plot. Determine what each row and each column of the data frame should be. Hint: We need data to be in columns to map to aesthetic elements of the plot.\n\nAdd response"
  },
  {
    "objectID": "ae-sa/ae-6-sa.html#pivoting",
    "href": "ae-sa/ae-6-sa.html#pivoting",
    "title": "AE 06: Suggested Answers",
    "section": "Pivoting",
    "text": "Pivoting\n\n\nDemo: Pivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\nExplain why the following code below accomplishes the question above.\n\nstatsci |>\n  pivot_longer(\n    cols = !c(degree,id),\n    names_to = \"year\",\n    values_to = \"n\"\n  ) \n\n# A tibble: 44 × 4\n      id degree                    year      n\n   <dbl> <chr>                     <chr> <dbl>\n 1     1 Statistical Science (AB2) 2011     NA\n 2     1 Statistical Science (AB2) 2012      1\n 3     1 Statistical Science (AB2) 2013     NA\n 4     1 Statistical Science (AB2) 2014     NA\n 5     1 Statistical Science (AB2) 2015      4\n 6     1 Statistical Science (AB2) 2016      4\n 7     1 Statistical Science (AB2) 2017      1\n 8     1 Statistical Science (AB2) 2018     NA\n 9     1 Statistical Science (AB2) 2019     NA\n10     1 Statistical Science (AB2) 2020      1\n# … with 34 more rows\n\n\n\n\nQuestion: What is the type of the year variable? Why? What should it be?\n\nIt’s a (categorical/quantitative) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be (categorical/quantitative).\n\nDemo: Start over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame. How do we typically change data types? We can also do it within pivot. How does this code differ from above?\n\nAdd response\n\nstatsci |>\n  pivot_longer(\n    cols = -c(degree,id),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  )  \n\n# A tibble: 44 × 4\n      id degree                     year     n\n   <dbl> <chr>                     <dbl> <dbl>\n 1     1 Statistical Science (AB2)  2011    NA\n 2     1 Statistical Science (AB2)  2012     1\n 3     1 Statistical Science (AB2)  2013    NA\n 4     1 Statistical Science (AB2)  2014    NA\n 5     1 Statistical Science (AB2)  2015     4\n 6     1 Statistical Science (AB2)  2016     4\n 7     1 Statistical Science (AB2)  2017     1\n 8     1 Statistical Science (AB2)  2018    NA\n 9     1 Statistical Science (AB2)  2019    NA\n10     1 Statistical Science (AB2)  2020     1\n# … with 34 more rows\n\n\n\n\nDemo: Add on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n))\n\n# A tibble: 44 × 4\n      id degree                     year     n\n   <dbl> <chr>                     <dbl> <dbl>\n 1     1 Statistical Science (AB2)  2011     0\n 2     1 Statistical Science (AB2)  2012     1\n 3     1 Statistical Science (AB2)  2013     0\n 4     1 Statistical Science (AB2)  2014     0\n 5     1 Statistical Science (AB2)  2015     4\n 6     1 Statistical Science (AB2)  2016     4\n 7     1 Statistical Science (AB2)  2017     1\n 8     1 Statistical Science (AB2)  2018     0\n 9     1 Statistical Science (AB2)  2019     0\n10     1 Statistical Science (AB2)  2020     1\n# … with 34 more rows\n\n\nNote: Once you have the correct code, change eval: false to eval: true OR delete the code altogether.\n\n\nDemo: In our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree.\n\n– Use separate to separate the degree_type column – Comment on what str_remove is doing – Comment on what fct_relevel is doing\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \"\\\\(\" , into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    )\n\n# A tibble: 44 × 5\n      id major                  degree_type  year     n\n   <dbl> <chr>                  <fct>       <dbl> <dbl>\n 1     1 \"Statistical Science \" AB2          2011     0\n 2     1 \"Statistical Science \" AB2          2012     1\n 3     1 \"Statistical Science \" AB2          2013     0\n 4     1 \"Statistical Science \" AB2          2014     0\n 5     1 \"Statistical Science \" AB2          2015     4\n 6     1 \"Statistical Science \" AB2          2016     4\n 7     1 \"Statistical Science \" AB2          2017     1\n 8     1 \"Statistical Science \" AB2          2018     0\n 9     1 \"Statistical Science \" AB2          2019     0\n10     1 \"Statistical Science \" AB2          2020     1\n# … with 34 more rows\n\n\n\n\nYour turn (5 minutes): Now we start making our plot, but let’s not get too fancy right away. Create the following plot, which will serve as the “first draft” on the way to our Goal. Do this by adding on to your pipeline from earlier.\n\n\n\n\n\n\nstatsci |>\n  pivot_longer(\n    cols = !c(id,degree),\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |> \n  ggplot(\n    aes(x = year, y = n, color = degree_type)\n  ) + \n  geom_point() + \n  geom_line()"
  },
  {
    "objectID": "ae-sa/merge.html",
    "href": "ae-sa/merge.html",
    "title": "ae-07 - Merge Conflicts and Data Science Ethics",
    "section": "",
    "text": "Collaborating on GitHub and resolving merge conflicts\n\n\n\n\n\n\n\nImportant\n\n\n\nPull up the merge.qmd to complete this short activity"
  },
  {
    "objectID": "ae-sa/merge.html#setup",
    "href": "ae-sa/merge.html#setup",
    "title": "ae-07 - Merge Conflicts and Data Science Ethics",
    "section": "Setup",
    "text": "Setup\n\nClone the repo and open the .qmd file.\nAssign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers."
  },
  {
    "objectID": "ae-sa/merge.html#lets-cause-a-merge-conflict",
    "href": "ae-sa/merge.html#lets-cause-a-merge-conflict",
    "title": "ae-07 - Merge Conflicts and Data Science Ethics",
    "section": "Let’s cause a merge conflict!",
    "text": "Let’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercises, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting: everyone should have the repo cloned, open the merge.qmd document, and know which role number(s) they are.\nEveryone:\n\nIn order to resolve merge conflicts using the instructions below, git needs to have the correct settings.\nTo ensure this is true, copy and paste git config pull.rebase false into your terminal and press enter. (Look for the tab next to the console, and ask if you can’t find it.)\nNote that if a merge conflict comes up in a later assignment, you may need to do this step again before resolving it. If that’s the case, you’ll likely get a warning suggesting it when you try to pull and there’s a conflict.\n\n🛑 Make sure everyone has completed this step before moving on.\nRole 1:\n\nChange “TEAM NAME” in the YAML to your actual team name.\nrender, commit, push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nChange “TEAM NAME” to some other word.\nRender, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict.\nClear the merge conflict by editing the document to choose Role 2’s change.\nRender.\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\ncommit and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 3:\n\nAdd a code chunk for Exercise 1 and give it a label.\nRender, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 4:\n\nAdd a code chunk to Exercise 1 and give it a different label.\nRender, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. render, and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nEveryone: Pull, and observe the changes in your document."
  },
  {
    "objectID": "ae-sa/merge.html#merge-conflicts-are-not-always-bad",
    "href": "ae-sa/merge.html#merge-conflicts-are-not-always-bad",
    "title": "ae-07 - Merge Conflicts and Data Science Ethics",
    "section": "Merge Conflicts are not always bad!",
    "text": "Merge Conflicts are not always bad!\nMerge conflicts are a part of group work. If you don’t work on the same lines, merge conflicts can be a good thing.\nRole 1:\n\nIn Exercise 2, write 2 + 2 in the code chunk\nRender, commit, push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nIn Exercise 3, write 3 + 5 in the code chunk\nRender, commit, push.\nNow pull. What happened?\nThe pdf did not auto merge! Render again, commit, and push.\n\nRole 1:\n\nNow pull. What happened?"
  },
  {
    "objectID": "ae-sa/merge.html#tips-for-collaborating-via-github",
    "href": "ae-sa/merge.html#tips-for-collaborating-via-github",
    "title": "ae-07 - Merge Conflicts and Data Science Ethics",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger."
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "If this is your first time accessing the containers, click on reserve STA198-199 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA198-199 under My reservations to access the RStudio instance you’ll use for the course."
  },
  {
    "objectID": "computing-cheatsheets.html",
    "href": "computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://www.rstudio.com/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references."
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers)."
  },
  {
    "objectID": "computing-troubleshooting.html#tips-for-not-rendering",
    "href": "computing-troubleshooting.html#tips-for-not-rendering",
    "title": "Computing troubleshooting",
    "section": "Tips for not rendering",
    "text": "Tips for not rendering\nThese are questions to ask yourself / check if you are having trouble rendering your document.\n– Are my code chunk labels weird? To create a code chunk label, you need the following #| label: at the start of your code chunk. If you have spaces in the name you put, or if you are using special characters, you may not be able to render your document. Note: if you want to make a comment, use # only.\n– Does your code run? If you have errors in your code, you will also have errors when rendering the document.\n– Did you put View() in a code chunk? We don’t use View often, but we need to be aware that any function that calls for an external viewer will break the render."
  },
  {
    "objectID": "computing-troubleshooting.html#tips-for-not-seeing-my-changes-in-git",
    "href": "computing-troubleshooting.html#tips-for-not-seeing-my-changes-in-git",
    "title": "Computing troubleshooting",
    "section": "Tips for not seeing my changes in Git",
    "text": "Tips for not seeing my changes in Git\n– Are you in the right project? You can see the project you are working in in the top right corner of your screen. This MUST be the project that you cloned for the exam / assignment / lab. Do not use the files tab to go search for a file outside of your project repo."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder)."
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.2.1: https://cran.r-project.org/\nDownload and install the preview build of RStudio: https://www.rstudio.com/products/rstudio/download/preview/\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\nCourse GitHub organization\n🔗 on Duke Container Manager\n🔗 on GitHub\n        |\n\n\n\n\n\n\n\nGradescope\n🔗 on Sakai |\n\n\n\nGradebook\n🔗 on Sakai |\n\n\n\nOffice hours\n🔗 on Google docs | |\n\n\n\nTexbooks\n🔗 R for Data Science | | 🔗 Introduction to Modern Statistics |\n\n\n\nPackage documentation\n🔗 ggplot2: ggplot2.tidyverse.org\n🔗 dplyr: dplyr.tidyverse.org\n🔗 tidyr: tidyr.tidyverse.org\n🔗 forcats: forcats.tidyverse.org\n🔗 stringr: stringr.tidyverse.org\n🔗 lubridate: lubridate.tidyverse.org\n🔗 readr: readr.tidyverse.org\n🔗 readxl: readxl.tidyverse.org"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Intro to data science and statistical thinking. Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language. No statistical or computing background is necessary. Not open to students who have taken a 100-level Statistical Science course, Statistical Science 210, or a Statistical Science course numbered 300 or above."
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nPerkins LINK 087 (Classroom 3)\nM, Tu & Th 12:30 - 2:35 pm\n\n\nLab 01\nPerkins Link 087 (Classroom 3)\nM & Th 3:30 - 4:45 am"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#slack",
    "href": "course-support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course Slack is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on Slack before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nCourse content questions should be going to Slack. My email should mainly be used for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Elijah Meyer at elijah.meyer@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 199” in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 24 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nCAPS: Duke Counseling & Pyschological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: http://studentaffairs.duke.edu/dukereach.\nTimelyCare: (formerly known as Blue Devils Care) An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling: https://bluedevilscare.duke.edu.\nTwo-Click Support: Duke Student Government and DukeReach partnership that connects students to help in just two clicks: https://bit.ly/TwoClickSupport."
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office (whether or not you are on aid). They have loans and resources for connecting students with programs on campus that might be able to help alleviate these costs.\nDukeLIFE offers course materials assistance for eligible students. Please note that students who are eligible for DukeLIFE benefits are notified prior to the start of the semester; program resources are limited."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission will take place on GitHub and conversation on Slack.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-syllabus.html#office-hours",
    "href": "course-syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office hours",
    "text": "Office hours\nClick here for the instructor and TA office hours locations and Zoom links. You are welcomed to attend the office hours for any STA 199 TA, regardless of section."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nAll books are freely available online.\n\n\n\nR for Data Science, 2e\nGrolemund, Wickham\nO’Reilly, 2nd edition, 2022\nHard copy only available of 1st edition\n\n\nIntroduction to Modern Statistics\nÇetinkaya-Rundel, Hardin\nOpenIntro Inc., 1st Edition, 2021\nHard copy available on Amazon"
  },
  {
    "objectID": "course-syllabus.html#course-learning-objectives",
    "href": "course-syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will…\n\nlearn to explore, visualize, and analyze data in a reproducible and shareable manner\ngain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization\nwork on problems and case studies inspired by and based on real-world questions and data\nlearn to effectively communicate results through written assignments and project presentation"
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website.\nAnnouncements will be emailed through Sakai Announcements periodically. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\n\nCheck out the Help tab for more resources.\n\n\nEmail\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 199” in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-syllabus.html#activities-assessment",
    "href": "course-syllabus.html#activities-assessment",
    "title": "Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. They are designed to follow the Prepare, Practice, Perform format.\n\nPrepare: Includes short videos, reading assignments, and lectures to introduce new concepts and ensure a basic comprehension of the material. The goal is to help you prepare for the in-class activities during lecture.\nPractice: Includes in-class application exercises where you will begin to the concepts and methods introduced in the prepare assignment. the activities will graded for completion, as they are designed for you to gain experience with the statistical and computing techniques before working on graded assignments.\nPerform: Includes labs, homework, exams, and the project. These assignments build upon the prepare and practice assignments and are the opportunity for you to demonstrate your understanding of the course material and how it is applied to analyze real-world data.\n\n\nLectures (Prepare)\nPart of the class time will be lectures that introduce new concepts or review topics from the preparation videos. Lectures will not repeat everything in the videos, they will instead highlight important and known to be complex concepts and will be supplemented with live coding activities. You are expected to attend every lecture. Lectures will be recorded and made available to students with an excused absence upon request.\n\n\nApplication exercises (Practice)\nA majority of the in-class lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the prepare assignment. The AEs done in class (M, Tu, Th) are due at the end of the day on the following Friday by 11:59p ET.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\nIn addition to AEs will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\n\n\nLabs (Perform)\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository on the course’s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework (Perform)\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams (Perform)\nThere will be two, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analysis and computational tasks related to the content in the prepare, practice, and perform assignments. More details about the content and structure of the exams will be discussed during the semester.\n\n\nProject (Perform)\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester.\n\n\nTeam work policy\nThe final project and several labs will be completed in teams. GitHub commits will be used to measure individual contribution to the assignment. All group members are expected to participate equally. Commit history may be used to give individual team members different grades. Your grade may differ from the rest of your group."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nLabs\n15%\n\n\nProject\n15%\n\n\nExam 01\n18%\n\n\nExam 02\n18%\n\n\nApplication Exercises\n4%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nYou may discuss individual homework and lab assignments with other students; however, you may not directly share (or copy) code or write up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write up with another team. Unauthorized sharing (or copying) of the code or write up will be considered a violation for all students involved.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\n\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action.\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\n\nLate work\n\nHomework and labs may be submitted up to 1 day (24 hours) late. There will be a 10% deduction for a late assignment.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nExams cannot be turned in late and can only be excused under exceptional circumstances.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nThe Duke policy for illness requires a short-term illness report or a letter from the Dean; except in emergencies, all other absenteeism must be approved in advance (e.g., an athlete who must miss class may be excused by prior arrangement for specific days). Please email Ed if you fall into this situation. For emergencies, email notification is needed at the first reasonable time. Please note that accommodations are not retroactive.\nA last-minute technical issue, being gone for vacation, or forgetting a deadline is not an extenuating circumstances.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let Dr. Elijah Meyer know if you need help contacting your academic dean.\n\n\nRegrade requests\nEvery effort will be made to mark your work accurately. We are on your side, and want you to receive every point you have worked to earn. However, sometimes grading mistakes happen. If you believe that an error has been made, return the paper to the instructor within four days, stating your claim in writing.\nThe following claims will be considered for re-grading:\n– points are not totaled correctly;\n– the grader did not see a correct answer that is on your paper;\n– your answer is the same as the correct answer, but in a different form (e.g., you wrote a correct answer as 1/3 and the grader was looking for .333);\n– your answer to a free response question is essentially correct but stated slightly differently than the grader’s expectation.\nThe following claims will not be considered for re-grading:\n– arguments about the number of points lost;\n– arguments about question wording.\nConsidering re-grades consumes time and resources that TAs and the instructor would rather spend helping you understand material. Please bring only claims of type (i), (ii), (iii), or (iv) to our attention.\nNo grades will be changed after the project presentations.\n\n\nClass recording requests\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week. To request a particular lecture’s video, please email me (your professor). Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded and provided in the email.\n\n\nAttendance policy\n\nCOVID Symptoms, Exposure, or Infection: Student health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919-681-9355). Learn more about current university policy related to COVID-19 at https://coronavirus.duke.edu. To keep the university community’s safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\nInclement weather: In the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work.  Asynchronous catch-up methods may apply.\nReligious accommodations: Students are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: https://trinity.duke.edu/undergraduate/academic-policies/religious-holidays."
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nMay 17th: Classes begin.\nMay 19th: Drop/Add for Term 1 ends at 11:59 p.m.\nMay 29th: Memorial Day. No classes are held.\nJune 14th: Last day to withdraw with “W” from Term 1 classes for a compelling reason. Last day for students to request S/U grading basis (they should contact their Academic Dean).\nJune 19th: Juneteenth holiday: No classes.\nJune 26th: Last Day of Class.\nJune 28-29: Final exams.\n\nFor more important dates, see the full Duke Academic Calendar."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Elijah Meyer - Hello! I’m very excited to work with you all this semester. I’ve earned a Master’s degree in statistics and a Ph.D. in statistics with a focus in education from Montana State University. I have taught at STA199 at Duke University during the F22 and S23 semesters. My early research is in sports statistics, with an emphasis on spatial data visualizations to enhance sports strategy. My Ph.D. work is in how to best support graduate student instructors and early career teachers to use active learning in their classrooms. Currently, my research focus is around creating a dynamic interactive shiny application in R to better students’ understanding of statistics and data science. Other endeavors include creating an online data science course Coursera.\nPrior to my time at Duke, I’ve taught multiple sections of Introductory and Intermediate Statistics at Montana State, developed their Intermediate Statistics online course, and helped integrate R into the Introductory Statistics curricula. I prioritize community, communication, and respect in my classroom. I want to provide a space where we can freely talk about the material, embrace mistakes, and learn together throughout the semester.\nWhen I’m not in the books, I enjoy playing disc golf, tennis, basketball, and anything else that gets me outside and active. I’m looking forward to meeting you all and having a great semester!\n\n\n\nOffice hours\nLocation\n\n\n\n\nTue: 3:00PM - 4:00PM & Th: 10:00AM - 12:00PM OR by appointment\nOld Chemistry Building 208 / Zoom (Password: 5MYp7A)"
  },
  {
    "objectID": "course-team.html#lab-group-information",
    "href": "course-team.html#lab-group-information",
    "title": "Teaching team",
    "section": "Lab Group Information",
    "text": "Lab Group Information\nYou can find your group here"
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\n\n\nName\nRole\nLab section\nOffice hours\n\n\n\n\nPritam Dey \npritam.dey@duke.edu\nLab Leader\nM & Th 3:30PM - 4:45PM: Perkins LINK 087 (Classroom 3)\nWed: 12:00PM - 2:00PM  In-person only: Old chem 203B"
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - Data visualization",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Monday, May 29th at 11:59pm."
  },
  {
    "objectID": "hw/hw-1.html#packages",
    "href": "hw/hw-1.html#packages",
    "title": "HW 1 - Data visualization",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "hw/hw-1.html#guidelines-tips",
    "href": "hw/hw-1.html#guidelines-tips",
    "title": "HW 1 - Data visualization",
    "section": "Guidelines + tips",
    "text": "Guidelines + tips\nAs we’ve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete this homework and other assignments in this course. There will be periodic reminders in this assignment to remind you to knit, commit, and push your changes to GithHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\nNote\n\n\n\nNote: Do not let R output answer the question for you unless the question specifically asks for just a plot. For example, if the question asks for the number of columns in the data set, please type out the number of columns. You are subject to lose points if you do not."
  },
  {
    "objectID": "hw/hw-1.html#data-1-duke-forest-houses",
    "href": "hw/hw-1.html#data-1-duke-forest-houses",
    "title": "HW 1 - Data visualization",
    "section": "Data 1: Duke Forest houses",
    "text": "Data 1: Duke Forest houses\n\n\n\n\n\n\nNote\n\n\n\nUse the duke_forest dataset for Exercises 1 and 2.\n\n\nFor the following two exercises you will work with data on houses that were sold in the Duke Forest neighborhood of Durham, NC in November 2020. The duke_forest dataset comes from the openintro package. You can see a list of the variables on the package website or by running ?duke_forest in your console."
  },
  {
    "objectID": "hw/hw-1.html#exercise-1",
    "href": "hw/hw-1.html#exercise-1",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you’re helping some family friends who are looking to buy a house in Duke Forest. As they browse Zillow listings, they realize some houses have garages and others don’t, and they wonder: Does having a garage make a difference?\nLuckily, you can help them answer this question with data visualization!\n\nMake histograms of the prices of houses in Duke Forest based on whether they have a garage.\n\nIn order to do this, you will first need to create a new variable called garage (with levels \"Garage\" and \"No garage\"). Below is the code for creating this new variable. Here, we mutate() the duke_forest data frame to add a new variable called garage which takes the value \"Garage\" if the text string \"Garage\" is detected in the parking variable and takes the test string \"No garage\" if not.\n\n\n\n\nduke_forest |>\n  mutate(garage = if_else(str_detect(parking, \"Garage\"),   \"Garage\", \"No garage\"))\n\n\nThen, facet by garage and use different colors for the two facets.\nChoose an appropriate binwidth and decide whether a legend is needed, and turn it off if not.\nInclude informative title and axis labels.\nFinally, include a brief (2-3 sentence) narrative comparing the distributions of prices of Duke Forest houses that do and don’t have garages. Your narrative should touch on whether having a garage “makes a difference” in terms of the price of the house.\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-1.html#exercise-2",
    "href": "hw/hw-1.html#exercise-2",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 2",
    "text": "Exercise 2\nIt’s expected that within any given marker larger houses will be priced higher. It’s also expected that the age of the house will have an effect on the price. However in some markets new houses might be more expensive while in others new construction might mean “no character” and hence be less expensive. So your family friends ask: “In Duke Forest, do houses that are bigger and more expensive tend to be newer ones than those that are smaller and cheaper?”\nOnce again, data visualization skills to the rescue!\n\nCreate a scatter plot to exploring the relationship between price and area, conditioning for year_built.\nUse geom_smooth() with the argument se = FALSE to add a smooth curve fit to the data and color the points by year_built.\nInclude informative title, axis, and legend labels.\nDiscuss each of the following claims (1-2 sentences per claim). Your discussion should touch on specific things you observe in your plot as evidence for or against the claims.\n\nClaim 1: Larger houses are priced higher.\nClaim 2: Newer houses are priced higher.\nClaim 3: Bigger and more expensive houses tend to be newer ones than smaller and cheaper ones.\n\n\n\n\nNow is a good time to render, commit, and push.\nMake sure that you commit and push ALL changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#data-2-brfss",
    "href": "hw/hw-1.html#data-2-brfss",
    "title": "HW 1 - Data visualization",
    "section": "Data 2: BRFSS",
    "text": "Data 2: BRFSS\n\n\n\n\n\n\nNote\n\n\n\nUse this dataset for Exercises 3 through 5.\n\n\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) is the nation’s premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Established in 1984 with 15 states, BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world.\nSource: cdc.gov/brfss\n\nIn the following exercises we will work with data from the 2020 BRFSS survey. The originally come from here, though we will work with a random sample of responses and a small number of variables from the data provided. These have already been sampled for you and the dataset you’ll use can be found in the data folder of your repo. It’s called brfss.csv.\n\nbrfss <- read_csv(\"data/brfss.csv\")"
  },
  {
    "objectID": "hw/hw-1.html#exercise-3",
    "href": "hw/hw-1.html#exercise-3",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nHow many rows are in the brfss dataset? What does each row represent?\nHow many columns are in the brfss dataset? Indicate the type of each variable.\nInclude the code and resulting output used to support your answer.\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-4",
    "href": "hw/hw-1.html#exercise-4",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 4",
    "text": "Exercise 4\nDo people who smoke more tend to have worse health conditions?\n\nUse a segmented bar chart to visualize the relationship between smoking (smoke_freq) and general health (general_health). Decide on which variable to represent with bars and which variable to fill the color of the bars by.\nPay attention to the order of the bars and, if need be, use the fct_relevel function to reorder the levels of the variables.\n\nBelow is sample code for releveling general_health. Here we first convert general_health to a factor (how R stores categorical data) and then order the levels from Excellent to Poor.\n\n\n\n\nbrfss |>\n  mutate(\n    general_health = as.factor(general_health),\n    general_health = fct_relevel(general_health, \"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\")\n  )\n\n\nInclude informative title, axis, and legend labels.\nComment on the motivating question based on evidence from the visualization: Do people who smoke more tend to have worse health conditions?\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-5",
    "href": "hw/hw-1.html#exercise-5",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 5",
    "text": "Exercise 5\nHow are sleep and general health associated?\n\nCreate a visualization displaying the relationship between sleep and general_health.\nInclude informative title and axis labels.\nModify your plot to use a different theme than the default.\nComment on the motivating question based on evidence from the visualization: How are sleep and general health associated?\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-6",
    "href": "hw/hw-1.html#exercise-6",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nFill in the blanks:\n\nThe gg in the name of the package ggplot2 stands for … .\nIf you map the same continuous variable to both x and y aesthetics in a scatterplot, you get a straight … line. (Choose between “vertical”, “horizontal”, or “diagonal”.)\n\n\nCode style: Fix up the code style by spaces and line breaks where needed. Briefly describe your fixes. (Hint: You can refer to the Tidyverse style guide.)\n\n\nggplot(data=mpg,mapping=aes(x=drv,fill=class))+geom_bar() +scale_fill_viridis_d()\n\n\nRead ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol arguments?\n\n\n Render, commit, and push one last time.\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#submission",
    "href": "hw/hw-1.html#submission",
    "title": "HW 1 - Data visualization",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nDo not select any pages of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-1.html#grading",
    "href": "hw/hw-1.html#grading",
    "title": "HW 1 - Data visualization",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 7 points\nExercise 2: 9 points\nExercise 3: 5 points\nExercise 4: 9 points\nExercise 5: 7 points\nExercise 6: 8 points\nWorkflow + formatting: 5 points\nTotal: 50 points\n\n\n\n\n\n\n\nNote\n\n\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow. This includes:\n\nlinking all pages appropriately on Gradescope\nputting your name in the YAML at the top of the document\ncommitting the submitted version of your .qmd to GitHub\nAre you under the 80 character code limit? (You shouldn’t have to scroll to see all your code). Pipes %>%, |> and ggplot layers + should be followed by a new line\nYou should be consistent with stylistic choices, e.g. only use 1 of = vs <- and %>% vs |>\n\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not."
  },
  {
    "objectID": "hw/hw-2.html",
    "href": "hw/hw-2.html",
    "title": "HW 2 - Data wrangling",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Wednesday, May 31st at 11:59pm.\nThe first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "hw/hw-2.html#workflow-formatting",
    "href": "hw/hw-2.html#workflow-formatting",
    "title": "HW 2 - Data wrangling",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse code style guidelines.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-2.html#packages",
    "href": "hw/hw-2.html#packages",
    "title": "HW 2 - Data wrangling",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization and the scales package for better formatting of labels on visualizations.\n\nlibrary(tidyverse)\nlibrary(scales)"
  },
  {
    "objectID": "hw/hw-2.html#data",
    "href": "hw/hw-2.html#data",
    "title": "HW 2 - Data wrangling",
    "section": "Data",
    "text": "Data\nThe data originally come from the fivethirtyeight package but we’ll use versions of the data that have been slightly modified to better suit this assignment. You can load the two datasets we’ll be using for this analysis with the following:\n\nmajor_income_undergrad <- read_csv(\"data/major_income_undergrad.csv\")\nmajor_income_grad <- read_csv(\"data/major_income_grad.csv\")\n\nYou can also take a quick peek at your data frames and view their dimensions with the glimpse function.\n\nglimpse(major_income_undergrad)\n\nRows: 172\nColumns: 12\n$ major_code                            <dbl> 5601, 6004, 6211, 2201, 2001, 32…\n$ major                                 <chr> \"Construction Services\", \"Commer…\n$ major_category                        <chr> \"Industrial Arts & Consumer Serv…\n$ undergrad_total                       <dbl> 86062, 461977, 179335, 37575, 53…\n$ undergrad_employed                    <dbl> 73607, 347166, 145597, 29738, 43…\n$ undergrad_employed_fulltime_yearround <dbl> 62435, 250596, 113579, 23249, 34…\n$ undergrad_unemployed                  <dbl> 3928, 25484, 7409, 1661, 3389, 5…\n$ undergrad_unemployment_rate           <dbl> 0.05066099, 0.06838588, 0.048422…\n$ undergrad_p25th                       <dbl> 47000, 34000, 35000, 29000, 3600…\n$ undergrad_median                      <dbl> 65000, 48000, 50000, 41600, 5200…\n$ undergrad_p75th                       <dbl> 98000, 71000, 75000, 60000, 7800…\n$ undergrad_sharewomen                  <dbl> 0.09071251, 0.69036529, 0.651659…\n\nglimpse(major_income_grad)\n\nRows: 172\nColumns: 11\n$ major_code                       <dbl> 5601, 6004, 6211, 2201, 2001, 6206, 1…\n$ major                            <chr> \"Construction Services\", \"Commercial …\n$ major_category                   <chr> \"Industrial Arts & Consumer Services\"…\n$ grad_total                       <dbl> 9173, 53864, 24417, 5411, 9109, 19099…\n$ grad_employed                    <dbl> 7098, 40492, 18368, 3590, 7512, 15157…\n$ grad_employed_fulltime_yearround <dbl> 6511, 29553, 14784, 2701, 5622, 12304…\n$ grad_unemployed                  <dbl> 681, 2482, 1465, 316, 466, 8324, 473,…\n$ grad_unemployment_rate           <dbl> 0.08754339, 0.05775585, 0.07386679, 0…\n$ grad_p25th                       <dbl> 110000, 89000, 100000, 85000, 83700, …\n$ grad_median                      <dbl> 75000, 60000, 65000, 47000, 57000, 80…\n$ grad_p75th                       <dbl> 53000, 40000, 45000, 24500, 40600, 50…\n\n\nThese two datasets have a trove of information. Three variables are common to both datasets:\n\n\nmajor_code: Major code, FO1DP in ACS PUMS\n\nmajor: Major description\n\nmajor_category: Category of major from Carnevale et al\n\nThe remaining variables start with either grad_ or undergrad_ suffix, depending on which dataset they are in. The descriptions of these variables is as follows.\n\n\n*_total: Total number of people with major\n\n*_sample_size: Sample size (unweighted) of full-time, year-round ONLY (used for earnings)\n\n*_employed: Number employed (ESR == 1 or 2)\n\n*_employed_fulltime_yearround: Employed at least 50 weeks (WKW == 1) and at least 35 hours (WKHP >= 35)\n\n*_unemployed: Number unemployed (ESR == 3)\n\n*_unemployment_rate: Unemployed / (Unemployed + Employed)\n\n*_p25th: 25th percentile of earnings\n\n*_median: Median earnings of full-time, year-round workers\n\n*_p75th: 75th percentile of earnings\n\nFinally, undergrad_sharewomen is the proportion of women with the major, and we only have this information for undergraduates.\nLet’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nHow much are college graduates making?\nHow do incomes of those with a graduate degree compare to those with an undergraduate degree?\n\nIn the following exercises we aim to answer these questions."
  },
  {
    "objectID": "hw/hw-2.html#exercise-1",
    "href": "hw/hw-2.html#exercise-1",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhich majors have the lowest unemployment rate? Answer the question using a single data wrangling pipeline and focusing on undergraduates (major_income_undergrad). The output should be a tibble with the columns major, and unemployment_rate, with the major with the lowest unemployment rate on top, and displaying the majors with the lowest 5 unemployment rates. Include a sentence listing the majors and the unemployment rates (as percentages)."
  },
  {
    "objectID": "hw/hw-2.html#exercise-2",
    "href": "hw/hw-2.html#exercise-2",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhich majors have the highest percentage of women? Answer the question using a single data wrangling pipeline and focusing on undergraduates (major_income_undergrad). The output should be a tibble with the columns major, and undergrad_sharewomen, with the major with the highest proportion of women on top, and displaying the majors with the highest 5 proportions of women. Include a sentence listing the majors and the percentage of women with the major.\n\n\n\n\nRender, commit (with a descriptive and concise commit message), and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-3",
    "href": "hw/hw-2.html#exercise-3",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 3",
    "text": "Exercise 3\nHow much are college graduates making? For this exercise, focus on undergraduates (major_income_undergrad).\n\n\nPlot the distribution of all median incomes using a histogram with an appropriate binwidth.\n\n\n\n\n\nCalculate the mean and median for median income. Based on the shape of the histogram, determine which of these summary statistics is useful for describing the distribution.\n\n\n\n\nDescribe the distribution of median incomes of college graduates across various majors based on your histogram from part (a) and incorporating the statistic you chose in part (b) to help your narrative. Hint: Mention shape, center, spread, any unusual observations.\n\n\nNow is a good time to render, commit (with a descriptive and concise commit message), and push again. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-4",
    "href": "hw/hw-2.html#exercise-4",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 4",
    "text": "Exercise 4\nHow do the distributions of median income compare across major categories? For this exercise, focus on undergraduates (major_income_undergrad).\n\n\nCalculate a the minimum, median, and maximum median income per major category as well as the number of majors in each category. Your summary statistics should be in decreasing order of median median income.\n\n\n\n\n\nCreate box plots of the distribution of median income by major category.\n\nThe variable major_category should be on the y-axis and undergrad_median on the x-axis.\nThe order of the boxes in your plot should match the order in your summary table from part (a).\nUse color to enhance your plot, and turn off any legends providing redundant information."
  },
  {
    "objectID": "hw/hw-2.html#submission",
    "href": "hw/hw-2.html#submission",
    "title": "HW 2 - Data wrangling",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-2.html#grading",
    "href": "hw/hw-2.html#grading",
    "title": "HW 2 - Data wrangling",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 10 points\nExercise 2: 10 points\nExercise 3: 10 points\nExercise 4: 15 points\nWorkflow + formatting: 5 points\nTotal: 50 points"
  },
  {
    "objectID": "hw/hw-3.html",
    "href": "hw/hw-3.html",
    "title": "HW 3 - Do you even lift?",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Tuesday, June 13th at 11:59pm."
  },
  {
    "objectID": "hw/hw-3.html#getting-started",
    "href": "hw/hw-3.html#getting-started",
    "title": "HW 3 - Do you even lift?",
    "section": "Getting Started",
    "text": "Getting Started\n\nGo to the Github Organization page and open your hw3-username repo\nClone the repository, open a new project in RStudio. It contains the starter documents you need to complete the homework assignment."
  },
  {
    "objectID": "hw/hw-3.html#exercises",
    "href": "hw/hw-3.html#exercises",
    "title": "HW 3 - Do you even lift?",
    "section": "Exercises",
    "text": "Exercises\nFor all of the following exercises, you should include units on axes labels, e.g. “Bench press (lbs)” or “Bench press (kg)”. “Age (years)” etc. This is good practice.\n\nLet’s begin by taking a look at the squat powerlifting records. To begin, remove any observations that are negative for squat. Next, create a new column called best3_squat_lbs that converts the record from kg to lbs (you may have to google the conversion). Save your data frame as ipf_squat.\n\n\nUsing ipf_squat, create a scatter plot to investigate the relationship between squat (in lbs) and age. Age should be on the x-axis. Add a linear best fit line. Remove the standard error. Be sure to label all axes and give the plot a title. Comment on what you observe.\n\n\nWrite down the population linear model to predict lift squat lbs from age using proper notation. Note: if you use generic \\(x\\) and \\(y\\), define each after your model? Next, fit the estimated linear model. Use the ipf_squat data frame. Using the output, write out the estimated linear regression model. This is called the “fitted” (estimated) linear model. Interpret each estimate of \\(\\beta\\). Is the intercept interpretation reasonable? Why or why not?\nBuilding on your ipf_squat data frame, create a new column called age2 that takes the age of each lifter and squares it. Save your data frame with an appropriate name. Next, plot squat in lbs vs age2 and add a linear best fit line. Do you notice any difference in how well this model fits the data compared to your previous model? Justify your answer.\nOne metric to assess the fit of a model is the correlation squared, also known as \\(R^2\\). Fit the age\\(^2\\) model and save the object as age2Fit. Subsequently report the \\(R^2\\). Compare \\(R^2\\) of the age\\(^2\\) model to the model from exercise 2. Which model do you prefer based on these values?\n\n\nIf you were to add body weight as a second predictor to the age\\(^2\\) model, would \\(R^2\\) increase or decrease? Explain.\n\n\nStarting with the original ipf dataframe, filter and mutate the data as we did in exercise 1, but this time filtering for best3bench_kg \\(>0\\) and creating a best3_bench_lbs variable, a bodyweight_lbs variable, and a sex variable that is a factor rather than a character.\n\nBefore fitting the model, please explain the following: What does it mean for bodyweight and sex to interact when modeling bench press? Hint: use the definition.\nNow, fit an interaction effects model with bodywieght (in lbs) and sex as predictors of best bench press (in lbs). Write down the fitted model equation using proper notation.\n\nPlot the model from exercise 5. Bodyweight should be on the x-axis. Add a linear best fit line. Be sure to label all axes and give the plot a title. Comment on what you observe.\nDo lifters who fail a drug test perform better or worse at bench press than other lifters? Does this vary across sexes? We’ll answer this question in two parts. First, remove all observations from the ipf data frame that have NA listed under bench press. In the same pipeline, create a new column called doping_status that takes value doping if the lifter failed a drug test and not doping otherwise. Save this data frame as ipf_dope.\n\n\n\n\n\n\n\nHint\n\n\n\nCheck the data dictionary at the top to figure out what variables will help you build the doping_status column.\n\n\n\nUsing ipf_dope from the previous exercise, compute the 5%, 50%, 95% quantiles for bench press across all combinations of sex and doping_status, i.e., male and doping, male and not doping, female and doping, female and not doping. You can use either bench press in kg or lbs here. With this information, answer the question “Do lifters who fail a drug test perform better or worse at bench press than other lifters?”\n\nHint: You can use the quantile function in R to calculate quantiles."
  },
  {
    "objectID": "hw/hw-3.html#reminder",
    "href": "hw/hw-3.html#reminder",
    "title": "HW 3 - Do you even lift?",
    "section": "Reminder:",
    "text": "Reminder:\n\nAll plots should follow the best visualization practices: include an informed title, label axes, and carefully consider aesthetic choices.\nAll code should follow the tidyverse style guidelines, including not exceeding the 80 character limit."
  },
  {
    "objectID": "hw/hw-3.html#submission",
    "href": "hw/hw-3.html#submission",
    "title": "HW 3 - Do you even lift?",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nDo not select any pages of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-3.html#rubric",
    "href": "hw/hw-3.html#rubric",
    "title": "HW 3 - Do you even lift?",
    "section": "Rubric",
    "text": "Rubric\n\nEx 1: 6 pts.\nEx 2: 6 pts.\nEx 3: 5 pts.\nEx 4: 5 pts.\nEx 5: 10 pts.\nEx 6: 5 pts.\nEx 7: 3 pts\nEx 8: 5 pts\nWorkflow and formatting - 5 pts\n\n\n\n\n\n\n\nNote\n\n\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow. This includes:\n\nlinking all pages appropriately on Gradescope\nputting your name in the YAML at the top of the document\ncommitting the submitted version of your .qmd to GitHub\nAre you under the 80 character code limit? (You shouldn’t have to scroll to see all your code).\nPipes %>%, |> and ggplot layers + should be followed by a new line\nYou should be consistent with stylistic choices, e.g. only use 1 of = vs <- and %>% vs |>\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199: Introduction to Data Science",
    "section": "",
    "text": "week\n      dow\n      date\n      what\n      topic\n      prepare\n      class_slides\n      lab_slides\n      ae_sa\n      hw\n      hw_sa\n      lab\n      lab_sa\n      exam\n      project\n      notes\n    \n\n\n1\nM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\n17 May\nLec-1\nWelcome to R & GitHub; \nExpectations; Tips to be Successful\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n18 May\nLec-2; Lab-0\nExploratory data analysis I | Connecting R with Git Lab\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\n22 May\nLec-3; Lab-1\nExploratory data analysis II + Intro to Data Wrangling | Data Visualization\n\n\n\n\n\n\n\n\n\n\nHW 1 Release; Lab-0 Due\n\n\n\nTu\n23 May\nLec-4\nData wrangling I\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n25 May\nLec-5; Lab-2\nData wrangling II + Tidying Data | Group Formation + Data Wrangling\n\n\n\n\n\n\n\n\n\n\nLab-1 Due\n\n\n3\nM\n29 May\nHoliday\nMemorial holiday: No classes are held\n\n\n\n\n\n\n\n\n\n\nHW 1 Due; HW 2 Release\n\n\n\nTu\n30 May\nLec-7\nggplot practice + debugging practice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n1 June\nLec-8; Lab-3; Exam-1\nMerge conflicts + The Language of Models; Project Work Day\n\n\n\n\n\n\n\n\n\n\nHW 2 Due; Release Exam 1\n\n\n4\nM\n5 June\nLec-9; Lab-4\nResearch Questions + Simple Linear Regression\n\n\n\n\n\n\n\n\n\n\nExam-1 Due\n\n\n\nTu\n6 June\nLec-10\nMultiple Linear Regression I\n\n\n\n\n\n\n\n\n\n\nHW 3 Release; Start Project\n\n\n\nTh\n8 June\nLec-11;\nFinish MLR + Logistic Regression; Project Work Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\nM\n12 June\nLec-12; Lab-5\nLogistic Regression II\n\n\n\n\n\n\n\n\n\n\nProject Checkpoint 1 Due\n\n\n\nTu\n13 June\nLec-13;\nBootstrap Hypothesis Testing\n\n\n\n\n\n\n\n\n\n\nHW 3 Due\n\n\n\nTh\n15 June\nLec-14; Lab-7; Exam-2\nBootstrap Hypothesis Testing II\n\n\n\n\n\n\n\n\n\n\nLab 5 Due; Release Exam-2\n\n\n6\nM\n19 June\nHoliday\nJuneteenth holiday. No classes are held\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\n20 June\nLec-16\nConfidence Intervals; Project Work Day\n\n\n\n\n\n\n\n\n\n\nExam-2 Due; HW 4 Release\n\n\n\nTh\n22 June\nLec-17; Lab-8\nCLT; Project Work Day\n\n\n\n\n\n\n\n\n\n\nProject Checkpoint 2 (Draft) Due\n\n\n7\nM\n26 June\nLec-18\nData Ethics + Special Topics (R-Shiny)\n\n\n\n\n\n\n\n\n\n\nHW 4 Due\n\n\n\nTu\n27 June\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n29 June\n\n\n\n\n\n\n\n\n\n\n\n\nProject Presentation"
  },
  {
    "objectID": "labs/lab-0.html",
    "href": "labs/lab-0.html",
    "title": "Lab 0 - Hello R!",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due May 22nd at Noon\nThis lab will introduce you to the course computing workflow. The main goal is to demo R and RStudio outside of lecture in a more independent setting. Note This lab is meant to reinforce what you have learned the last two lectures. Coding is a new language and is not learned in a single day.\nAn additional goal is to reinforce Git and GitHub, the collaboration and version control system that we will be using throughout the course.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nTo make versioning simpler, this and the next lab are solo labs. In the future, you’ll learn about collaborating on GitHub and producing a single lab report for your lab team, but for now, concentrate on getting the basics down.\nBy the end of the lab, you will…"
  },
  {
    "objectID": "labs/lab-0.html#log-in-to-rstudio",
    "href": "labs/lab-0.html#log-in-to-rstudio",
    "title": "Lab 0 - Hello R!",
    "section": "Log in to RStudio",
    "text": "Log in to RStudio\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 to log into the Docker container. You should now see the RStudio environment.\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you haven’t yet done so, you will need to reserve a container for STA198-199 first."
  },
  {
    "objectID": "labs/lab-0.html#set-up-your-ssh-key",
    "href": "labs/lab-0.html#set-up-your-ssh-key",
    "title": "Lab 0 - Hello R!",
    "section": "Set up your SSH key",
    "text": "Set up your SSH key\nYou will authenticate GitHub using SSH. Below are an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nType credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” You should click 1 for yes.\nYou will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta199).\n\nYou can find more detailed instructions here if you’re interested."
  },
  {
    "objectID": "labs/lab-0.html#configure-git",
    "href": "labs/lab-0.html#configure-git",
    "title": "Lab 0 - Hello R!",
    "section": "Configure Git",
    "text": "Configure Git\nThere is one more thing we need to do before getting started on the assignment. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package. (And we also need to install a package called gert just for this step.)\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\ndevtools::install_github(\"r-lib/gert\")\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\"\n  )\n\nFor example, mine would be\n\ndevtools::install_github(\"r-lib/gert\")\n\nusethis::use_git_config(\n  user.name = \"Elijah Meyer\", \n  user.email = \"elijah.meyer@duke.edu\"\n  )\n\nYou are now ready interact with GitHub via RStudio!"
  },
  {
    "objectID": "labs/lab-0.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-0.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 0 - Hello R!",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta199-summer-1 organization on GitHub. Click on the repo with the prefix lab-0. It contains the starter documents you need to complete the lab.\nIf you do not see your lab0 repo, you need to fill out the Getting to know you survey on Sakai. Next, go to https://github.com/ElijahMeyer3/lab-0-public to find your lab-0 repo and follow the directions below.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab0.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab."
  },
  {
    "objectID": "labs/lab-0.html#r-and-r-studio",
    "href": "labs/lab-0.html#r-and-r-studio",
    "title": "Lab 0 - Hello R!",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file."
  },
  {
    "objectID": "labs/lab-0.html#yaml",
    "href": "labs/lab-0.html#yaml",
    "title": "Lab 0 - Hello R!",
    "section": "YAML",
    "text": "YAML\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document."
  },
  {
    "objectID": "labs/lab-0.html#committing-changes",
    "href": "labs/lab-0.html#committing-changes",
    "title": "Lab 0 - Hello R!",
    "section": "Committing changes",
    "text": "Committing changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you’re happy with these changes, we’ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, “updated author name”) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let’s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!"
  },
  {
    "objectID": "labs/lab-0.html#push-changes",
    "href": "labs/lab-0.html#push-changes",
    "title": "Lab 0 - Hello R!",
    "section": "Push changes",
    "text": "Push changes\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push."
  },
  {
    "objectID": "labs/lab-0.html#data-visualization-and-summary",
    "href": "labs/lab-0.html#data-visualization-and-summary",
    "title": "Lab 0 - Hello R!",
    "section": "Data visualization and summary",
    "text": "Data visualization and summary\n\nPlot y vs. x for the dino dataset. Then, calculate the correlation coefficient between x and y for this dataset.\n\nBelow is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your document and successfully render it and view the results.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data <- datasaurus_dozen |>\n  filter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s slow down and unpack it a bit.\nFirst, the pipe operator: |>, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: <-, assigns the name dino_data to the filtered data frame.\nNext, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data you’re visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point.\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\nFor the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as \\(r\\) in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate \\(r\\) only if relevant. In this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear (it’s dinosaurial)!\nFor illustrative purposes only, let’s calculate the correlation coefficient between x and y.\n\n\n\n\n\n\nNote\n\n\n\nStart with `dino_data` and calculate a summary statistic that we will call `r` as the `cor`relation between `x` and `y`.\n\n\n\ndino_data |>\n  summarize(r = cor(x, y))\n\n\nThis is a good place to pause, render, and commit changes with the commit message “Added answer for Ex 2.”\nThen, push these changes when you’re done.\n\n\nPlot y vs. x for the circle dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\n\nThis is another good place to pause, render, and commit changes with the commit message “Added answer for Ex 3.”\nThen, push these changes when you’re done.\n\n\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\n\nYou should pause again, render, commit changes with the commit message “Added answer for Ex 4”.\nThen, push.\n\nFinally, let’s plot all datasets at once. In order to do this we will make use of faceting, given by the code below:\n\n\n\n\n\n\nNote\n\n\n\nFacet by the dataset variable, placing the plots in a 3 column grid, and don’t add a legend.\n\n\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+\n  geom_point()+\n  facet_wrap(~ dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\nAnd we can use the group_by function to generate all the summary correlation coefficients. We’ll go through these functions next week when we learn about data wrangling.\n\ndatasaurus_dozen |>\n  group_by(dataset) |>\n  summarize(r = cor(x, y)) \n\n\nInclude the faceted plot and the summary of the correlation coefficients in your lab write-up by including relevant code in R chunks (and give them appropriate labels). In the narrative below the code chunks, briefly comment on what you notice about the plots and the correlations between x and y values within each of them (one or two sentences is fine!).\n\nYou’re done with the data analysis exercises, but we’d like to do one more thing to customize the look of the report."
  },
  {
    "objectID": "labs/lab-0.html#resize-your-figures",
    "href": "labs/lab-0.html#resize-your-figures",
    "title": "Lab 0 - Hello R!",
    "section": "Resize your figures",
    "text": "Resize your figures\nWe can customize the output from a particular R chunk by including options in the header that will override any global settings.\n\nIn the R chunks you wrote for Exercises 2-5, customize the settings by modifying the options in the R chunks used to create those figures.\n\nFor Exercises 2, 3, and 4, we want square figures. We can use fig.height and fig.width in the options to adjust the height and width of figures. Modify the chunks in Exercises 2-4 to be as follows:\n\n```{r}\n#| label: ex2-chunk-label\n#| fig-height: 5\n#| fig-width: 5\n\n# Your code that created the figure\n```\n\nFor Exercise 5, modify your figure to have fig-height of 10 and fig-width of 6.\nNow, save and render.\nOnce you’ve created this PDF file, you’re done!\n\nCommit all remaining changes with the commit message “Done with Lab 1!”.\nThen push."
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Thursday, May 25th at 11:59pm ET."
  },
  {
    "objectID": "labs/lab-1.html#packages",
    "href": "labs/lab-1.html#packages",
    "title": "Lab 1 - Data visualization",
    "section": "Packages",
    "text": "Packages\nWe will use the tidyverse package to create and customize plots in R.\n\nlibrary(tidyverse)\nlibrary(viridis)"
  },
  {
    "objectID": "labs/lab-1.html#data-lets-take-a-trip-to-the-midwest",
    "href": "labs/lab-1.html#data-lets-take-a-trip-to-the-midwest",
    "title": "Lab 1 - Data visualization",
    "section": "Data: Let’s take a trip to the Midwest",
    "text": "Data: Let’s take a trip to the Midwest\nThe data in this lab is in the midwest data frame. It is part of the ggplot2 R package, so the midwest data set is automatically loaded when you load the tidyverse package.\nThe data contains demographic characteristics of counties in the Midwest region of the United States.\nBecause the data set is part of the ggplot2 package, you can read documentation for the data set, including variable definitions by typing ?midwest in the console."
  },
  {
    "objectID": "labs/lab-2.html",
    "href": "labs/lab-2.html",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Monday May 29th at 11:59pm."
  },
  {
    "objectID": "labs/lab-2.html#group-formation",
    "href": "labs/lab-2.html#group-formation",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Group Formation",
    "text": "Group Formation\nAfter lab-2, lab assignments will be group based, and we will shortly be starting the group project.\nIn this lab, you are going choose who you want to work with. Groups are to be made up of 3-4 students per group. If you would like to be assigned to a group, please reach out to the TA."
  },
  {
    "objectID": "labs/lab-2.html#why-teams-rationale",
    "href": "labs/lab-2.html#why-teams-rationale",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Why Teams: Rationale",
    "text": "Why Teams: Rationale\nIn the real world, data scientists and statisticians often work in research teams. It is a skill to be able to communicate and work together on common projects. Thus, the remaining labs + your project will be team based.\nTeams work is better when members have a common understanding of the team’s goals and expectations for collaboration. The purpose of this activity is to help your team making a plan for working together during lab and outside of the scheduled lab time.\nEach team member will have some ideas about how a team should operate. These ideas may be very different. This is your opportunity to share your thoughts and ideas to promote optimal team function and prevent misunderstandings in the future."
  },
  {
    "objectID": "labs/lab-2.html#team-name",
    "href": "labs/lab-2.html#team-name",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Team Name",
    "text": "Team Name\nDiscuss with your group a team name to be called. Your GitHub repos will be created for this team name moving forward. Report your team name to your Lab Leader before moving on."
  },
  {
    "objectID": "labs/lab-2.html#instructions",
    "href": "labs/lab-2.html#instructions",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Instructions",
    "text": "Instructions\nThere are two items you need to complete when forming your group.\n– Report your group members and team name to your TA to be recorded\n– Fill out the team agreement\nTeam agreement: Discuss each of the items below with all in-person team members. If necessary, also follow up this week with any missing team members.\nHave one person act as the recorder and type the team’s decisions in the team-agreement.qmd file.\nBe sure the team agrees on an item before it is added to the document.\nOnce the document is complete, the recorder should render, commit, and push the team agreement to GitHub. All team members can refer to this document throughout the semester.\nThis is not graded for accuracy, and simply acts as a tool to facilitate good group work."
  },
  {
    "objectID": "labs/lab-2.html#team-agreement",
    "href": "labs/lab-2.html#team-agreement",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Team Agreement",
    "text": "Team Agreement\nWeekly meetings\nIdentify a 1 - 2 hour weekly block outside of lab where the team can meet to work on assignments. All team members should block off this time on their calendar in case the group needs to meet to finish lab or work on the project.\nMeeting “location”\nHow the team will meet to work together (e.g. in-person, Zoom, Facetime, Google Hangouts). Be sure every member is able to access the virtual meeting space, if needed. If you are unable to find a weekly time when the team can meet, briefly outline a plan to work on assignments outside of lab. Otherwise, you can delete this item.\nPrimary method of communication\nThe team’s primary method of communication outside of meetings (e.g. Slack, text messages, etc.)\nHow should someone notify the other members if they are unable to attend lab or a scheduled team meeting?\nBy when should everyone have their portion of the lab completed?\nKeep in mind your team may want to have time to review the lab before turning it in to make sure it is a cohesive write up.\nAny other items the team would like to discuss or plan.\nMissing Teammates\nIf someone is missing in your lab, and you would like them to be a part of your team, please communicate this information with both them and the TA so this can be documented."
  },
  {
    "objectID": "labs/lab-2.html#warm-up",
    "href": "labs/lab-2.html#warm-up",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and render the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your `.qmd and .pdf files. If anything is missing, render, commit, and push again."
  },
  {
    "objectID": "labs/lab-2.html#packages",
    "href": "labs/lab-2.html#packages",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "labs/lab-2.html#data",
    "href": "labs/lab-2.html#data",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSV (comma separated values) file in the data folder of your repository. You can read it in using the following.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nThe descriptions of the variables are as follows:\n\n\nid: ID number\n\nfirstname: First name of laureate\n\nsurname: Surname\n\nyear: Year prize won\n\ncategory: Category of prize\n\naffiliation: Affiliation of laureate\n\ncity: City of laureate in prize year\n\ncountry: Country of laureate in prize year\n\nborn_date: Birth date of laureate\n\ndied_date: Death date of laureate\n\ngender: Gender of laureate\n\nborn_city: City where laureate was born\n\nborn_country: Country where laureate was born\n\nborn_country_code: Code of country where laureate was born\n\ndied_city: City where laureate died\n\ndied_country: Country where laureate died\n\ndied_country_code: Code of country where laureate died\n\noverall_motivation: Overall motivation for recognition\n\nshare: Number of other winners award is shared with\n\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix _original.\n\n\nborn_country_original: Original country where laureate was born\n\nborn_city_original: Original city where laureate was born\n\ndied_country_original: Original country where laureate died\n\ndied_city_original: Original city where laureate died\n\ncity_original: Original city where laureate lived at the time of winning the award\n\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "labs/lab-2.html#get-to-know-your-data",
    "href": "labs/lab-2.html#get-to-know-your-data",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\n\n\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code."
  },
  {
    "objectID": "labs/lab-2.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "labs/lab-2.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nnobel_living <- nobel_living |>\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science <- nobel_living |>\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the following exercises, work with the nobel_living_science data frame you created above. This means you’ll need to define this data frame in your Quarto document, even though the next exercise doesn’t explicitly ask you to do so.\n\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.\n\n\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-2.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "labs/lab-2.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Lab 2 - Group Formation Data wrangling",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\n\nCreate a new variable called born_country_us in nobel_living_science that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\n\n\n\n\n\n\n\nNote\n\n\n\nYou should be able to cheat borrow from code you used earlier to create the country_us variable.\n\n\n\n\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Create two visualizations with this new variable added:\n\nPlot 1: Segmented frequency bar plot\nPlot 2: Segmented relative frequency bar plot (Hint: Add position = \"fill\" to geom_bar().)\n\nHere are some instructions that apply to both of these visualizations:\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be two bars for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\nWhich of these visualizations is a better fit for answering the following question: “Do the data appear to support Buzzfeed’s claim that of those US-based Nobel laureates, most were born in other countries?” First, state which plot you’re using to answer the question. Then, answer the question, explaining your reasoning in 1-2 sentences.\n\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n\n\n\nIn a single pipeline, filter the nobel_living_science data frame for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4 - Predicting a numerical outcome",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Thursday, June 8th at 11:59pm."
  },
  {
    "objectID": "labs/lab-4.html#intro",
    "href": "labs/lab-4.html#intro",
    "title": "Lab 4 - Predicting a numerical outcome",
    "section": "Intro",
    "text": "Intro\nParasites can cause infectious disease – but not all animals are affected by the same parasites. Some parasites are present in a multitude of species and others are confined to a single host. It is hypothesized that closely related hosts are more likely to share the same parasites. More specifically, it is thought that closely related hosts will live in similar environments and have similar genetic makeup that coincides with optimal conditions for the same parasite to flourish.\nIn this lab we will see how much evolutionary history predicts parasite similarity."
  },
  {
    "objectID": "labs/lab-4.html#the-data",
    "href": "labs/lab-4.html#the-data",
    "title": "Lab 4 - Predicting a numerical outcome",
    "section": "The Data",
    "text": "The Data\nToday’s dataset comes from an Ecology Letters paper by Cooper at al. (2012) “Phylogenetic host specificity and understanding parasite sharing in primates” which can be found here. The goal of the paper was to identify the ability of evolutionary history and ecological traits to characterize parasite host specificity.\nEach row of the data contains two species, species1 and species2.\nSubsequent columns describe metrics that compare the species:\n\ndivergence_time: how many (millions) of years ago the two species diverged. i.e. how many million years ago they were the same species.\ndistance: geodesic distance between species geographic range centroids (in kilometers)\nBMdiff: difference in body mass between the two species (in grams)\nprecdiff: difference in mean annual precipitation across the two species geographic ranges (mm)\nparsim: a measure of parasite similarity (proportion of parasites shared between species, ranges from 0 to 1.)\n\nThe data are available in parasites.csv in the data folder."
  },
  {
    "objectID": "labs/lab-4.html#packages",
    "href": "labs/lab-4.html#packages",
    "title": "Lab 4 - Predicting a numerical outcome",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization.\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tidyr' was built under R version 4.2.2\n\n\nWarning: package 'readr' was built under R version 4.2.2\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\nlibrary(tidymodels)\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2"
  },
  {
    "objectID": "labs/lab-4.html#exercises",
    "href": "labs/lab-4.html#exercises",
    "title": "Lab 4 - Predicting a numerical outcome",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nImportant\n\n\n\nPick another member of the team write the answer to Exercise 1. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\nTo get started, load the data and save the data frame as parasites.\n\nLet’s start by examining the relationship between divergence_time and parsim.\n\nBased on the goals of the analysis, what is the response variable?\nVisualize the relationship between the two variables.\nUse the visualization to describe the relationship between the two variables.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\n\nNext, we’ll model this relationship.\n\nFit the model and write the estimated regression equation.\nInterpret the slope and the intercept in the context of the data.\nRecreate the visualization from Exercise 1, this time adding a regression line to the visualization.\nWhat do you notice about the prediction (regression) line that may be strange, particularly for very large divergence times?\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 2 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 3. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\n\nSince parsim takes values between 0 and 1, we want to transform this variable so that it can range between (−∞,+∞). This will be better suited for fitting a regression model (and interpreting predicted values!)\n\nUsing mutate, create a new variable transformed_parsim that is calculated as log(parsim/(1-parsim)). Add this variable to your data frame. Note: log() in R represents taking the nautral log.\nThen, visualize the relationship between divergence_time and transformed_parsim. Add a regression line to your visualization.\nWrite a 1-2 sentence description of what you observe in the visualization.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 3 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 4. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\n\nWhich variable is the strongest individual predictor of parasite similarity between species? To answer this question, begin by fitting separate linear regression models predicting transformed_parsim with each of the following predictor variables:\n\ndivergence_time\ndistance\nBMdiff\nprecdiff\n\n\n\nDo not report the model outputs in a tidy format but save each one as dt_model, dist_model, BM_model, and prec_model, respectively. Then,\n\nReport the slopes for each of these models. Use proper notation.\nTo answer the question of interest, would it be useful to compare the slopes in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 4 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 5. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nRegardless of your answer to exercise 4b, we will also calculate the \\(R^2\\) of each model to help us identify the strongest individual linear predictor of transformed_parsim. \\(R^2\\) measures the percent of the variability in the response that is explained by the model.\n\nAs you may have guessed from the name, \\(R^2\\) can be calculated by squaring the correlation when we have a simple linear regression model. The correlation, r, takes values between -1 and 1, so \\(R^2\\) takes a value between 0 and 1. Intuitively, if r=1 or −1, then \\(R^2\\)=1, indicating the model perfectly fits the data. If r≈0 then \\(R^2\\)≈0, indicating the model is a very bad fit for the data.\nYou can calculate \\(R^2\\) using the glance function. For example, you can calculate \\(R^2\\) for dt_model using the code glance(dt_model)$r.squared.\n\nCalculate and report \\(R^2\\) for each model fit in the previous exercise.\nTo answer the question of interest, would it be useful to compare the \\(R^2\\) in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 5 renders, commits, and pushes, all other team members should pull the changes and render the document. Finally, a team member different than the one responsible for typing up responses to Exercise 5 should do the last task outlined below."
  },
  {
    "objectID": "labs/lab-5.html",
    "href": "labs/lab-5.html",
    "title": "Lab 5 - Logistic regression",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Thursday, June 15th at 5:00pm."
  },
  {
    "objectID": "labs/lab-5.html#packages",
    "href": "labs/lab-5.html#packages",
    "title": "Lab 5 - Logistic regression",
    "section": "Packages",
    "text": "Packages\nYou’ll need the following packages for today’s lab.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dsbox)"
  },
  {
    "objectID": "labs/lab-5.html#data",
    "href": "labs/lab-5.html#data",
    "title": "Lab 5 - Logistic regression",
    "section": "Data",
    "text": "Data\nThe data can be found in the dsbox package, and it’s called gss16. Since the dataset is distributed with the package, we don’t need to load it separately; it becomes available to us when we load the package.\nIf you would like to explicitly load the data into your environment so you can view it, you can do so by running this code.\n\ngss16 <- gss16\n\nYou can find out more about the dataset by inspecting its documentation, which you can access by running ?gss16 in the Console or using the Help menu in RStudio to search for gss16. You can also find this information here."
  },
  {
    "objectID": "labs/lab-5.html#exercise-1---data-wrangling",
    "href": "labs/lab-5.html#exercise-1---data-wrangling",
    "title": "Lab 5 - Logistic regression",
    "section": "Exercise 1 - Data wrangling",
    "text": "Exercise 1 - Data wrangling\n\n\n\n\n\n\nImportant\n\n\n\nRemember: For each exercise, you should choose one person to type. All others should contribute to the discussion, but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nCreate a new data frame called gss16_advfront that includes the variables advfront, educ, polviews, and wrkstat. Then, use the drop_na() function to remove rows that contain NAs from this new data frame. Sample code is provided below.\n\n\ngss16_advfront <- gss16 |>\n  select(___, ___, ___, ___) |>\n  drop_na()\n\n\nRe-level the advfront variable such that it has two levels: \"Strongly agree\" and \"Agree\" combined into a new level called \"Agree\" and the remaining levels combined into \"Not agree\". Then, re-order the levels in the following order: \"Agree\" and \"Not agree\". Finally, count() how many times each new level appears in the advfront variable.\n\nHint: You can do this in various ways, but you’ll likely need to use mutate along with either if_else() or case_when() to re-level the variable and then fct_relevel() to re-order the levels. (See Lab 2 for an example of using if_else and HW 1 Exercise 4 for an example of using fct_relevel.)\n\nCombine the levels of the polviews variable such that levels that have the word “liberal” in them are lumped into a level called \"Liberal\" and those that have the word “conservative” in them are lumped into a level called \"Conservative\". Then, re-order the levels in the following order: \"Conservative\" , \"Moderate\", and \"Liberal\". Finally, count() how many times each new level appears in the polviews variable.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, all other team members should pull. Then, choose a new team member to write the answer to Exercise 2. (And so on for the remaining exercises.)"
  },
  {
    "objectID": "labs/lab-5.html#exercise-2---train-and-test-sets",
    "href": "labs/lab-5.html#exercise-2---train-and-test-sets",
    "title": "Lab 5 - Logistic regression",
    "section": "Exercise 2 - Train and test sets",
    "text": "Exercise 2 - Train and test sets\nNow, let’s split the data into training and test sets so that we can evaluate the models we’re going to fit by how well they predict outcomes on data that wasn’t used to fit the models.\nSpecify a random seed of 1234 (i.e., include set.seed(1234) at the beginning of your code chunk), and then split gss16_advfront randomly into a training set train_data and a test set test_data. Do this so that the training set contains 80% of the rows of the original data."
  },
  {
    "objectID": "labs/lab-5.html#exercise-3---logistic-regression",
    "href": "labs/lab-5.html#exercise-3---logistic-regression",
    "title": "Lab 5 - Logistic regression",
    "section": "Exercise 3 - Logistic Regression",
    "text": "Exercise 3 - Logistic Regression\n\nUsing the training data, specify a logistic regression model that predicts advfront by educ. In particular, the model should predict the probability that advfront has value \"Not agree\". Name this model model1. Report the tidy output below.\nWrite out the estimated model in proper notation. State the meaning of any variables in the context of the data.\nUsing your estimated model, predict the probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years."
  },
  {
    "objectID": "labs/lab-5.html#exercise-4---another-model",
    "href": "labs/lab-5.html#exercise-4---another-model",
    "title": "Lab 5 - Logistic regression",
    "section": "Exercise 4 - Another model",
    "text": "Exercise 4 - Another model\n\nAgain using the training data, fit a new model that adds the additional explanatory variable of polviews. Name this model model2. Report the tidy output below.\nNow, predict the probability of agreeing with the following statement: Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government (Agree in advfront) if you have an education of 7 years and are Conservative."
  },
  {
    "objectID": "labs/lab-5.html#exercise-5---evaluating-models-with-aic",
    "href": "labs/lab-5.html#exercise-5---evaluating-models-with-aic",
    "title": "Lab 5 - Logistic regression",
    "section": "Exercise 5 - Evaluating models with AIC",
    "text": "Exercise 5 - Evaluating models with AIC\n\nReport the AIC values for each of model1 and model2.\nBased on your results in part a, does it appear that including political views in addition to years of education is useful for modeling whether employees agree with the statement “Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government”? Explain."
  },
  {
    "objectID": "labs/lab-5.html#exercise-6---evaluating-models-using-test-data",
    "href": "labs/lab-5.html#exercise-6---evaluating-models-using-test-data",
    "title": "Lab 5 - Logistic regression",
    "section": "Exercise 6 - Evaluating models using test data",
    "text": "Exercise 6 - Evaluating models using test data\n\n\nFor each of model1 and model2, plot an ROC curve to visualize the true positive rate (sensitivity) and false positive rate (1 - specificity) for predictions on the observations in test_data. Add a title to each graph indicating which model they represent.\nYou can use the code below to make the plot for model 1. Then adapt it as needed for model 2.\n\n\n\nmodel1_pred <- predict(model1, test_data, type = \"prob\") |>  \n  bind_cols(test_data |> select(advfront))\n\nmodel1_pred |>\n  roc_curve(\n    truth = advfront, # advfront contains the true labels\n    `.pred_Not agree`, # we're predicting the probability of \"Not agree\"\n    event_level = \"second\" # \"Not agree\" is the 2nd level of advfront\n  ) |>\n  autoplot() +\n  labs(title = \"ROC curve for model 1\")\n\n\nReport the area under the curve (AUC) for each of the ROC curves from part\n\n\n\n\nAre the AUC values consistent with your conclusion in Exercise 5b? Explain."
  },
  {
    "objectID": "prepare/5-18.html",
    "href": "prepare/5-18.html",
    "title": "Prepare",
    "section": "",
    "text": "Watch: Meet the toolkit\nRead:\n\nR for Data Science: Chapter 1 - Introduction\nIntro to Modern Data Science: Chapter 1 - Hello data\nR4DS: Chp 2 - Data visualization - Sections 2.1 and 2.4\n\nIf you haven’t yet done so:\n\nJoin the course Slack using the invitation link in your email.\nComplete the Getting to know you survey.\nReserve a STA 198-199 container at https://cmgr.oit.duke.edu/containers."
  },
  {
    "objectID": "prepare/5-22.html",
    "href": "prepare/5-22.html",
    "title": "Prepare",
    "section": "",
    "text": "::: callout-note Videos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class. :::"
  },
  {
    "objectID": "prepare/5-23.html",
    "href": "prepare/5-23.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/5-25.html",
    "href": "prepare/5-25.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/6-1.html",
    "href": "prepare/6-1.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/6-12.html",
    "href": "prepare/6-12.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/6-13.html",
    "href": "prepare/6-13.html",
    "title": "Prepare",
    "section": "",
    "text": "Hypothesis testing\n\nRead (optional): section 12\n\n(optional): 13.1, 13.2, 13.3: inference with mathematical models"
  },
  {
    "objectID": "prepare/6-15.html",
    "href": "prepare/6-15.html",
    "title": "Prepare",
    "section": "",
    "text": "Read: chapter 20 - section 20.1"
  },
  {
    "objectID": "prepare/6-5.html",
    "href": "prepare/6-5.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS :: Chp 7 - Linear regression with a single predictor\n\n⌨️ Watch:\n\nUnit 4 - Deck 2: Fitting and interpreting models\nUnit 4 - Deck 3: Modelling nonlinear relationships\n\n::: callout-note Videos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class. :::"
  },
  {
    "objectID": "prepare/6-6.html",
    "href": "prepare/6-6.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS :: Chp 8 - Linear regression with multiple predictors\n\n⌨️ Watch:\n\nUnit 4 - Deck 4: Models with multiple predictors\nUnit 4 - Deck 5: More models with multiple predictors\n\n::: callout-note Videos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class. :::"
  },
  {
    "objectID": "prepare/6-8.html",
    "href": "prepare/6-8.html",
    "title": "Prepare",
    "section": "",
    "text": "Watch Logistic Regression\nWatch StringR\nRead (optional): chapter 9: logistic regression"
  },
  {
    "objectID": "prepare/sample.html",
    "href": "prepare/sample.html",
    "title": "Prepare",
    "section": "",
    "text": "Watch: Meet the toolkit\nRead:\n\nR for Data Science: Chapter 1 - Introduction\nIntro to Modern Data Science: Chapter 1 - Hello data\n\nIf you haven’t yet done so:\n\nJoin the course Slack using the invitation link in your email.\nComplete the Getting to know you survey.\nReserve a STA 198-199 container at https://cmgr.oit.duke.edu/containers."
  },
  {
    "objectID": "project-description-post-later.html#criteria-for-datasets",
    "href": "project-description-post-later.html#criteria-for-datasets",
    "title": "project-description-post-later",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations (or approved by me)\nAt least 8 columns (or approved by me)\nAt least 6 of the columns must be useful and unique explanatory variables (or approved by me)\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nWe strongly recommend curating at least one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements."
  },
  {
    "objectID": "project-description-post-later.html#resources-for-datasets",
    "href": "project-description-post-later.html#resources-for-datasets",
    "title": "project-description-post-later",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)"
  },
  {
    "objectID": "project-description-post-later.html#proposal-components",
    "href": "project-description-post-later.html#proposal-components",
    "title": "project-description-post-later",
    "section": "Proposal components",
    "text": "Proposal components\nFor each data set, include the following:\nIntroduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.\n\nResearch question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\nGlimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set."
  },
  {
    "objectID": "project-description-post-later.html#proposal-grading",
    "href": "project-description-post-later.html#proposal-grading",
    "title": "project-description-post-later",
    "section": "Proposal grading",
    "text": "Proposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction and data\n3\n\n\nResearch question\n3\n\n\nGlimpse of data\n3\n\n\nWorkflow and formatting\n1\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.\n\nIt is critical to check feedback on your project proposal. Even if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project-description-post-later.html#draft-components",
    "href": "project-description-post-later.html#draft-components",
    "title": "project-description-post-later",
    "section": "Draft components",
    "text": "Draft components\nIntroduction and data\nThe introduction provides motivation and context for your research. Describe your topic (citing sources) and provide a concise, clear statement of your research question and hypotheses.\nThen identify the source of the data, when and how it was collected, the cases, a general description of relevant variables.\nMethodology\nThe methodology section should include visualizations and summary statistics relevant to your research question. You should also justify the choice of statistical method(s) used to answer your research question.\nResults\nShowcase how you arrived at answers to your research question using the techniques we have learned in class (and beyond, if you’re feeling adventurous).\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R. More is not better."
  },
  {
    "objectID": "project-description-post-later.html#draft-grading",
    "href": "project-description-post-later.html#draft-grading",
    "title": "project-description-post-later",
    "section": "Draft grading",
    "text": "Draft grading\nYour first draft will be reviewed and graded by your TAs. We recommend you incorporate their suggestions into your second (optional) draft before the second round of feedback by your peers."
  },
  {
    "objectID": "project-description-post-later.html#process-and-questions",
    "href": "project-description-post-later.html#process-and-questions",
    "title": "project-description-post-later",
    "section": "Process and questions",
    "text": "Process and questions\nSpend ~30 mins to review each team’s project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team’s repo.\nOpen the repo of the team you’re reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description-post-later.html#peer-review-grading",
    "href": "project-description-post-later.html#peer-review-grading",
    "title": "project-description-post-later",
    "section": "Peer review grading",
    "text": "Peer review grading\nPeer reviews will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, and any inference, modeling, or conclusions."
  },
  {
    "objectID": "project-description-post-later.html#report-components",
    "href": "project-description-post-later.html#report-components",
    "title": "project-description-post-later",
    "section": "Report components",
    "text": "Report components\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\nResults\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\nGrading criteria\nThe analysis results are clearly assessed and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\nDiscussion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\nGrading criteria\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description-post-later.html#report-grading",
    "href": "project-description-post-later.html#report-grading",
    "title": "project-description-post-later",
    "section": "Report grading",
    "text": "Report grading\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts"
  },
  {
    "objectID": "project-description-post-later.html#slides",
    "href": "project-description-post-later.html#slides",
    "title": "project-description-post-later",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\n\n\n\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work"
  },
  {
    "objectID": "project-description-post-later.html#presentation",
    "href": "project-description-post-later.html#presentation",
    "title": "project-description-post-later",
    "section": "Presentation",
    "text": "Presentation\nPresentations will take place in class during the last lab of the semester. The presentation must be no longer than 5 minutes. You can choose to present live in class (recommended) or pre-record a video to be shown in class. Either way you must attend the lab session for the Q&A following your presentation.\nIf you choose to pre-record your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video in your repo README.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum."
  },
  {
    "objectID": "project-description-post-later.html#reproducibility-organization",
    "href": "project-description-post-later.html#reproducibility-organization",
    "title": "project-description-post-later",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description-post-later.html#teamwork",
    "href": "project-description-post-later.html#teamwork",
    "title": "project-description-post-later",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project presentation deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description-post-later.html#grading-summary",
    "href": "project-description-post-later.html#grading-summary",
    "title": "project-description-post-later",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-description-post-later.html#late-work-policy",
    "href": "project-description-post-later.html#late-work-policy",
    "title": "project-description-post-later",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-description-s23.html",
    "href": "project-description-s23.html",
    "title": "project-description-s23",
    "section": "",
    "text": "Proposal due Friday, March 10th\nDraft 1 due April 7th\nPeer review due April 14th (5:00 PM)\nPresentation + slides due April 25th\nFinal report and [final GitHub repo] due April 28th"
  },
  {
    "objectID": "project-description-s23.html#criteria-for-datasets",
    "href": "project-description-s23.html#criteria-for-datasets",
    "title": "project-description-s23",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 300 observations (or approved by me)\nAt least 6 unique columns that are useful and not simply identifiers (or approved by me)\nData must be real\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria."
  },
  {
    "objectID": "project-description-s23.html#resources-for-datasets",
    "href": "project-description-s23.html#resources-for-datasets",
    "title": "project-description-s23",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)"
  },
  {
    "objectID": "project-description-s23.html#proposal-components",
    "href": "project-description-s23.html#proposal-components",
    "title": "project-description-s23",
    "section": "Proposal components",
    "text": "Proposal components\nFor each data set, include the following:\n\nIntroduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.\n\n\n\nResearch question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\n\n\nLiterature\nA literature review is an overview of the previously published works on a topic. It is good practice to familiarize yourself with published work that has already been done on the topic you are researching. Often, a literature review spans many articles, and allows the researcher to communicate how their research fits in / extends our current understanding of a topic. For this project, we will do a “mini” literature review. For each data set:\n\nFind one published credible article on the topic you are interested in researching.\nProvide a one paragraph summary about the article.\nIn 1-2 sentences, explain how your research question builds on / is different than the article you have cited.\n\nYou can find articles using Google Scholar or some other academic search engine. Please reach out if you have any questions about this.\n\n\nGlimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set."
  },
  {
    "objectID": "project-description-s23.html#proposal-grading",
    "href": "project-description-s23.html#proposal-grading",
    "title": "project-description-s23",
    "section": "Proposal grading",
    "text": "Proposal grading\n\n\n\nTotal\n15 pts\n\n\n\n\nIntroduction and data\n3\n\n\nResearch question\n3\n\n\nLiterature\n3\n\n\nGlimpse of data\n3\n\n\nWorkflow and formatting\n3\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.\n\nIt is critical to check feedback on your project proposal. Even if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project-description-s23.html#draft-components",
    "href": "project-description-s23.html#draft-components",
    "title": "project-description-s23",
    "section": "Draft components",
    "text": "Draft components\n\nIntroduction and data\nThe introduction provides motivation and context for your research. Describe your topic (citing sources) and provide a concise, clear statement of your research question and hypotheses. Additionally, consider any potential ethical issues that you believe should be addressed (if any) regarding how your data were collected.\nThen identify the source of the data, when and how it was collected, the cases, a general description of relevant variables.\n\n\nMethodology\nThe methodology section should include visualizations and summary statistics relevant to your research question. You should also justify the choice of statistical method(s) used to answer your research question.\n\n\nResults\nShowcase how you arrived at answers to your research question using the techniques we have learned in class (and beyond, if you’re feeling adventurous).\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R. More is not better.\n\n\nWorkflow + Formatting\nTo earn full credit, please be mindful of the following:\nHave an updated about qmd for your project.\nResponded to / Closed all issues from your proposal.\nYour website must be able to be rendered by me and your lab leader prior to submission.\nEVERYONE in your group must have at least 3 commits.\nPipes %>%, |> and ggplot layers + should be followed by a new line.\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not."
  },
  {
    "objectID": "project-description-s23.html#draft-grading",
    "href": "project-description-s23.html#draft-grading",
    "title": "project-description-s23",
    "section": "Draft grading",
    "text": "Draft grading\nThe project draft report grade is worth 10 points and will be graded by your Lab Leaders and will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.\n\nIt is critical to check feedback on your project proposal. Even if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project-description-s23.html#report-components",
    "href": "project-description-s23.html#report-components",
    "title": "project-description-s23",
    "section": "Report components",
    "text": "Report components\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.)\n\n\n\nLiterature Review\nThis section includes an overview of one previously published work on your topic of interest. This includes a summary on the author’s study design, findings/results, as well as how your study is related to + adds to the existing literature on the topic. You may use footnote citations for referenced literature.\n\nGrading criteria\nThe article is clearly referenced and the connection between the article you have chosen with your research is clear. The article is well summarized to the point that the reader understands the article “at a high level”, including how the study were designed and the results that came out of it. It is clearly articulated how your study pushes the existing literature on your topic of interest, answering the question “Why is your research important?”\n\n\n\nMethodology\nThis section includes any exploratory data analysis and a brief description of your statistical procedure. If you are fitting a model, explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\nIf you are conducting a hypothesis test or creating a confidence interval, justify your decision, specifically on how it relates to your research question. Justify if you are going to use theory or simulation based techniques. Use resulting output to help address your research question.\nYou may use more than one statistical method to answer your research question.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\nResults\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe analysis results are clearly assessed and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\nDiscussion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix or plots) is no longer than 10 pages."
  },
  {
    "objectID": "project-description-s23.html#report-grading",
    "href": "project-description-s23.html#report-grading",
    "title": "project-description-s23",
    "section": "Report grading",
    "text": "Report grading\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n5 pts\n\n\nLiterature Review\n3 pts\n\n\nMethodology\n10 pts\n\n\nResults\n12 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts"
  },
  {
    "objectID": "project-description-s23.html#slides",
    "href": "project-description-s23.html#slides",
    "title": "project-description-s23",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\n\n\nIt is recommended that the slide deck have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work"
  },
  {
    "objectID": "project-description-s23.html#presentation",
    "href": "project-description-s23.html#presentation",
    "title": "project-description-s23",
    "section": "Presentation",
    "text": "Presentation\nPresentations will take place in class during the last lab of the semester. The presentation must be no longer than 5 minutes. You can choose to present live in class (recommended) or pre-record a video to be shown in class. Either way you must attend the lab session for the Q&A following your presentation. Attendance will be recorded, and failing to attend will impact your grade.\nIf you choose to pre-record your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video in your repo README.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum."
  },
  {
    "objectID": "project-description-s23.html#reproducibility-organization",
    "href": "project-description-s23.html#reproducibility-organization",
    "title": "project-description-s23",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description-s23.html#teamwork",
    "href": "project-description-s23.html#teamwork",
    "title": "project-description-s23",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf this is not indicated on the survey, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description-s23.html#grading-summary",
    "href": "project-description-s23.html#grading-summary",
    "title": "project-description-s23",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-description-s23.html#late-work-policy",
    "href": "project-description-s23.html#late-work-policy",
    "title": "project-description-s23",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-description-summer.html",
    "href": "project-description-summer.html",
    "title": "project-description-s23",
    "section": "",
    "text": "Proposal June 12th\nDraft 1 June 22nd\nPresentation + slides June 29th\nFinal report and [final GitHub repo] June 29th"
  },
  {
    "objectID": "project-description-summer.html#criteria-for-datasets",
    "href": "project-description-summer.html#criteria-for-datasets",
    "title": "project-description-s23",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 300 observations (or approved by me)\nAt least 6 unique columns that are useful and not simply identifiers (or approved by me)\nData must be real\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria."
  },
  {
    "objectID": "project-description-summer.html#resources-for-datasets",
    "href": "project-description-summer.html#resources-for-datasets",
    "title": "project-description-s23",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)"
  },
  {
    "objectID": "project-description-summer.html#proposal-components",
    "href": "project-description-summer.html#proposal-components",
    "title": "project-description-s23",
    "section": "Proposal components",
    "text": "Proposal components\nFor each data set, include the following:\n\nIntroduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.\n\n\n\nResearch question\nYour research question should be clear and easily understood by a general audience. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\n\n\nLiterature\nA literature review is an overview of the previously published works on a topic. It is good practice to familiarize yourself with published work that has already been done on the topic you are researching. Often, a literature review spans many articles, and allows the researcher to communicate how their research fits in / extends our current understanding of a topic. For this project, we will do a “mini” literature review. For each data set:\n\nFind one published credible article on the topic you are interested in researching.\nProvide a one paragraph summary about the article.\nIn 1-2 sentences, explain how your research question builds on / is different than the article you have cited.\n\nYou can find articles using Google Scholar or some other academic search engine. Please reach out if you have any questions about this.\n\n\nGlimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set."
  },
  {
    "objectID": "project-description-summer.html#proposal-grading",
    "href": "project-description-summer.html#proposal-grading",
    "title": "project-description-s23",
    "section": "Proposal grading",
    "text": "Proposal grading\n\n\n\nTotal\n15 pts\n\n\n\n\nIntroduction and data\n3\n\n\nResearch question\n3\n\n\nLiterature\n3\n\n\nGlimpse of data\n3\n\n\nWorkflow and formatting\n3\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.\n\nIt is critical to check feedback on your project proposal. Even if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project-description-summer.html#reproducibility-organization",
    "href": "project-description-summer.html#reproducibility-organization",
    "title": "project-description-s23",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description-summer.html#draft-components",
    "href": "project-description-summer.html#draft-components",
    "title": "project-description-s23",
    "section": "Draft components",
    "text": "Draft components\n\nIntroduction and data\nThe introduction provides motivation and context for your research. Describe your topic (citing sources) and provide a concise, clear statement of your research question and hypotheses. Additionally, consider any potential ethical issues that you believe should be addressed (if any) regarding how your data were collected.\nThen identify the source of the data, when and how it was collected, the cases, a general description of relevant variables.\n\n\nMethodology\nThe methodology section should include visualizations and summary statistics relevant to your research question. You should also justify the choice of statistical method(s) used to answer your research question.\n\n\nResults\nShowcase how you arrived at answers to your research question using the techniques we have learned in class (and beyond, if you’re feeling adventurous).\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R. More is not better.\n\n\nWorkflow + Formatting\nTo earn full credit, please be mindful of the following:\nHave an updated about qmd for your project.\nResponded to / Closed all issues from your proposal.\nYour website must be able to be rendered by me and your lab leader prior to submission.\nEVERYONE in your group must have at least 1 meaningful commit.\nPipes %>%, |> and ggplot layers + should be followed by a new line.\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not."
  },
  {
    "objectID": "project-description-summer.html#draft-grading",
    "href": "project-description-summer.html#draft-grading",
    "title": "project-description-s23",
    "section": "Draft grading",
    "text": "Draft grading\nThe project draft report grade is worth 10 points and will be graded by your Lab Leaders and will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.\n\nIt is critical to check feedback on your project proposal. Even if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project-description-summer.html#slides",
    "href": "project-description-summer.html#slides",
    "title": "project-description-s23",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\n\n\nHere is a suggested outline as you think through the slides; Note, you should feel free to add additional slides to help better explain your research.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work"
  },
  {
    "objectID": "project-description-summer.html#presentation",
    "href": "project-description-summer.html#presentation",
    "title": "project-description-s23",
    "section": "Presentation",
    "text": "Presentation\nPresentations will take place in class during our scheduled final exam time on June 29th from 9AM- 12PM. We will not need the full three hours. The presentation should be between 5-15 minutes. The expectation is that you present live in class (recommended). Additionally, you must attend the final session for the Q&A following your presentation. If you have an extreme circumstance that prohibits you from attending class, you must complete the following:\n\nCommunicate this with your group ASAP.\nPre-record your portion of the presentation to be played during presentation time.\nExpect an email with 1-2 questions (from me) about the content from your pre-recorded section to ensure you get practice answering questions. Failure to answer these questions will impact your grade.\n\nIf you must pre-record your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\n\nTips for Slides / Presentation\n– When presenting, we should be focusing on YOU and not trying to read your slides.\n– The less words, the better.\n– Visualizations do a great job at helping the audience through your presentation.\n– Visualizations can often appear to small when projected, making them more distracting than useful. Make sure that your visualizations are large enough for the audience to be able to read labels / understand what is going on.\n– Tell a story. Nobody knows about the research you have done. Why are you interested in it? Why is this topic important? Quickly situating the audience here can help grab their attention prior to going into the details.\n– Limitations: No research study is perfect, and it is important to reconize this (normally at the end of the presentation). What limitations did you face with data / statistical inference? If you could continue this project, what new steps might you take? etc."
  },
  {
    "objectID": "project-description-summer.html#report-components",
    "href": "project-description-summer.html#report-components",
    "title": "project-description-s23",
    "section": "Report components",
    "text": "Report components\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.)\n\n\n\nLiterature Review\nThis section includes an overview of one previously published work on your topic of interest. This includes a summary on the author’s study design, findings/results, as well as how your study is related to + adds to the existing literature on the topic. You may use footnote citations for referenced literature.\n\nGrading criteria\nThe article is clearly referenced and the connection between the article you have chosen with your research is clear. The article is well summarized to the point that the reader understands the article “at a high level”, including how the study were designed and the results that came out of it. It is clearly articulated how your study pushes the existing literature on your topic of interest, answering the question “Why is your research important?”\n\n\n\nMethodology\nThis section includes any exploratory data analysis and a brief description of your statistical procedure. If you are fitting a model, explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\nIf you are conducting a hypothesis test or creating a confidence interval, justify your decision, specifically on how it relates to your research question. Justify if you are going to use theory or simulation based techniques. Use resulting output to help address your research question.\nYou may use more than one statistical method to answer your research question.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to determine analyses types and addressed any concerns over appropriateness of analyses chosen.\n\n\n\nResults\nThis is where you will discuss your overall finding and describe the key results from your analysis. The goal is not to interpret every single element of an output shown, but instead to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe analysis results are clearly assessed and interesting findings from the analysis are described. Interpretations are used to to support the key findings and conclusions, rather than merely listing, e.g., the interpretation of every model coefficient.\n\n\n\nDiscussion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the analysis results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix or plots) is recommended to be no longer than 10 pages. If you go past this, it is okay, but you may need to start thinking about the content of your report, and if their is “fluff” added to it."
  },
  {
    "objectID": "project-description-summer.html#report-grading",
    "href": "project-description-summer.html#report-grading",
    "title": "project-description-s23",
    "section": "Report grading",
    "text": "Report grading\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n5 pts\n\n\nLiterature Review\n3 pts\n\n\nMethodology\n10 pts\n\n\nResults\n12 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts"
  },
  {
    "objectID": "project-description-summer.html#teamwork",
    "href": "project-description-summer.html#teamwork",
    "title": "project-description-s23",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a surveys where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf this is not indicated on the survey, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description-summer.html#grading-summary",
    "href": "project-description-summer.html#grading-summary",
    "title": "project-description-s23",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-description-summer.html#late-work-policy",
    "href": "project-description-summer.html#late-work-policy",
    "title": "project-description-s23",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-examples.html",
    "href": "project-examples.html",
    "title": "project-examples",
    "section": "",
    "text": "Covid19\n\n\n\n\n\n\nCost of Rent\n\n\n\n\n\n\nAir Pollution\n\n\n\n\n\n\nBasketball"
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "slides/01-welcome-199.html#welcome",
    "href": "slides/01-welcome-199.html#welcome",
    "title": "Welcome to STA 199",
    "section": "Welcome",
    "text": "Welcome"
  },
  {
    "objectID": "slides/01-welcome-199.html#goals-for-day-1",
    "href": "slides/01-welcome-199.html#goals-for-day-1",
    "title": "Welcome to STA 199",
    "section": "Goals for Day 1",
    "text": "Goals for Day 1\nGet organized\n\nGet to know the professor\nGet to know each other\nCourse overview\nRegister with GitHub & Slack (if you haven’t already)\nGo over R + R-studio\nStart making visualizations"
  },
  {
    "objectID": "slides/01-welcome-199.html#who-am-i",
    "href": "slides/01-welcome-199.html#who-am-i",
    "title": "Welcome to STA 199",
    "section": "Who Am I?",
    "text": "Who Am I?"
  },
  {
    "objectID": "slides/01-welcome-199.html#who-are-you",
    "href": "slides/01-welcome-199.html#who-are-you",
    "title": "Welcome to STA 199",
    "section": "Who Are You?",
    "text": "Who Are You?\nPlease share with your neighbors:\n\nMajor\nYear\nWhy you are taking this course\nAnything else"
  },
  {
    "objectID": "slides/01-welcome-199.html#what-is-data-science-1",
    "href": "slides/01-welcome-199.html#what-is-data-science-1",
    "title": "Welcome to STA 199",
    "section": "What is data science?",
    "text": "What is data science?\n“Data science is a concept to unify statistics, data analysis, machine learning and their related methods in order to understand and analyze actual phenomena with data. It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science.”\n-Donoho, 2017"
  },
  {
    "objectID": "slides/01-welcome-199.html#examples-of-data-science",
    "href": "slides/01-welcome-199.html#examples-of-data-science",
    "title": "Welcome to STA 199",
    "section": "Examples of data science",
    "text": "Examples of data science\n\nIdentification and prediction of disease\nTargeted advertising\nSupply chain optimization\nSports recruitment + strategist\nThe list goes on and on….."
  },
  {
    "objectID": "slides/01-welcome-199.html#jobs",
    "href": "slides/01-welcome-199.html#jobs",
    "title": "Welcome to STA 199",
    "section": "Jobs",
    "text": "Jobs"
  },
  {
    "objectID": "slides/01-welcome-199.html#jobs-1",
    "href": "slides/01-welcome-199.html#jobs-1",
    "title": "Welcome to STA 199",
    "section": "Jobs",
    "text": "Jobs"
  },
  {
    "objectID": "slides/01-welcome-199.html#jobs-2",
    "href": "slides/01-welcome-199.html#jobs-2",
    "title": "Welcome to STA 199",
    "section": "Jobs",
    "text": "Jobs"
  },
  {
    "objectID": "slides/01-welcome-199.html#data-literacy",
    "href": "slides/01-welcome-199.html#data-literacy",
    "title": "Welcome to STA 199",
    "section": "Data literacy",
    "text": "Data literacy"
  },
  {
    "objectID": "slides/01-welcome-199.html#our-classroom",
    "href": "slides/01-welcome-199.html#our-classroom",
    "title": "Welcome to STA 199",
    "section": "Our Classroom",
    "text": "Our Classroom\n\nCommunity\nCommunication\nRespect"
  },
  {
    "objectID": "slides/01-welcome-199.html#course-objectives",
    "href": "slides/01-welcome-199.html#course-objectives",
    "title": "Welcome to STA 199",
    "section": "Course objectives",
    "text": "Course objectives\n\nLearn to explore, visualize, and analyze data in a reproducible and shareable manner\nGain experience in data wrangling, exploratory data analysis, predictive modeling, and data visualization\nWork on problems and case studies inspired by and based on real-world questions and data\nLearn to effectively communicate results through written assignments and final project presentation"
  },
  {
    "objectID": "slides/01-welcome-199.html#some-of-what-you-will-learn",
    "href": "slides/01-welcome-199.html#some-of-what-you-will-learn",
    "title": "Welcome to STA 199",
    "section": "Some of what you will learn",
    "text": "Some of what you will learn\n\n\n\n\n\n– Fundamentals of R\n– Data visualization\n– Version control with GitHub\n\n– Reproducible reports with Quarto\n– Regression\n– Statistical inference"
  },
  {
    "objectID": "slides/01-welcome-199.html#r---figures",
    "href": "slides/01-welcome-199.html#r---figures",
    "title": "Welcome to STA 199",
    "section": "R - figures",
    "text": "R - figures\n\n\n\n\n\n\n\n\n\n\nFigure 1: Example R Figures"
  },
  {
    "objectID": "slides/01-welcome-199.html#section",
    "href": "slides/01-welcome-199.html#section",
    "title": "Welcome to STA 199",
    "section": "",
    "text": "{fig.align = “center”}"
  },
  {
    "objectID": "slides/01-welcome-199.html#r",
    "href": "slides/01-welcome-199.html#r",
    "title": "Welcome to STA 199",
    "section": "R",
    "text": "R\n\n\n\n\n\n\nNote\n\n\n This is a new language"
  },
  {
    "objectID": "slides/01-welcome-199.html#workflow",
    "href": "slides/01-welcome-199.html#workflow",
    "title": "Welcome to STA 199",
    "section": "Workflow",
    "text": "Workflow\nBefore Class\n\nWatch lecture content videos (will locate these during website tour)\nClone the application exercise (can be done right before class; we will practice this today)\n\nDuring Class\n\nWarm up question\nMix of lecture and live coding"
  },
  {
    "objectID": "slides/01-welcome-199.html#website",
    "href": "slides/01-welcome-199.html#website",
    "title": "Welcome to STA 199",
    "section": "Website",
    "text": "Website\nsta199-summer-1.github.io/"
  },
  {
    "objectID": "slides/01-welcome-199.html#activities-and-assessments",
    "href": "slides/01-welcome-199.html#activities-and-assessments",
    "title": "Welcome to STA 199",
    "section": "Activities and assessments",
    "text": "Activities and assessments\n\nHomework: Individual assignments combining conceptual and computational skills.\nLabs: Individual or team assignments focusing on computational skills.\nExams: Two take-home exams.\nFinal Project: Team project presented during the final exam period.\nApplication Exercises: Exercises worked on during the live lecture session."
  },
  {
    "objectID": "slides/01-welcome-199.html#application-exercises",
    "href": "slides/01-welcome-199.html#application-exercises",
    "title": "Welcome to STA 199",
    "section": "Application Exercises",
    "text": "Application Exercises\n\nAre not graded for the first week\nTurned in on GitHub (You will have this ability after Lab-0)\nWhat is due is what we get through in-class"
  },
  {
    "objectID": "slides/01-welcome-199.html#lab",
    "href": "slides/01-welcome-199.html#lab",
    "title": "Welcome to STA 199",
    "section": "Lab",
    "text": "Lab\n\nRun by TA Pritam Dey\nFocus on computing using R tidyverse syntax\nApply concepts from lecture to case study scenarios\nWork on labs individually or in teams of 3 - 4"
  },
  {
    "objectID": "slides/01-welcome-199.html#textbooks-and-readings",
    "href": "slides/01-welcome-199.html#textbooks-and-readings",
    "title": "Welcome to STA 199",
    "section": "Textbooks and readings",
    "text": "Textbooks and readings\n\nR for Data Science by Grolemund & Wickham (2nd ed. O’Reilly)\nIntroduction to Modern Statistics by Cetinkaya-Rundel & Hardin (1st ed. OpenIntro)"
  },
  {
    "objectID": "slides/01-welcome-199.html#r-r-studio-posit",
    "href": "slides/01-welcome-199.html#r-r-studio-posit",
    "title": "Welcome to STA 199",
    "section": "R + R-studio (Posit)",
    "text": "R + R-studio (Posit)\n– Specialization in data visualization\n– Computing tools to fit models\n– Well respected\n– You can take these skills with you\nThe language has grown significantly in popularity and is now used in a range of professions including software development, business analysis, statistical reporting and scientific research"
  },
  {
    "objectID": "slides/01-welcome-199.html#create-a-github-account-why",
    "href": "slides/01-welcome-199.html#create-a-github-account-why",
    "title": "Welcome to STA 199",
    "section": "Create a GitHub account (Why?)",
    "text": "Create a GitHub account (Why?)\nGitHub, Inc., is an Internet hosting service for software development and version control."
  },
  {
    "objectID": "slides/01-welcome-199.html#what-we-need-to-do-5-min",
    "href": "slides/01-welcome-199.html#what-we-need-to-do-5-min",
    "title": "Welcome to STA 199",
    "section": "What we need to do (5 min)",
    "text": "What we need to do (5 min)\n– If you have not set up:\n\nGitHub Account\nSlack Account\nReserved a Duke Container"
  },
  {
    "objectID": "slides/01-welcome-199.html#create-a-github-account",
    "href": "slides/01-welcome-199.html#create-a-github-account",
    "title": "Welcome to STA 199",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\nPlease do this before the Getting to know you survey\nGo to https://github.com/, and create an account (unless you already have one).\nSome tips from Happy Git with R.\n– Incorporate your actual name!\n– Reuse your username from other contexts if you can, e. g., Twitter or Slack.\n– Pick a username you will be comfortable revealing to your future boss.\n– Be as unique as possible in as few characters as possible. Shorter is better than longer.\n– Avoid words with special meaning in programming (e.g. NA)."
  },
  {
    "objectID": "slides/01-welcome-199.html#github-account",
    "href": "slides/01-welcome-199.html#github-account",
    "title": "Welcome to STA 199",
    "section": "GitHub account",
    "text": "GitHub account\n\n\n\n\n\n\n\n\n\n\n\nInvite Example"
  },
  {
    "objectID": "slides/01-welcome-199.html#slack",
    "href": "slides/01-welcome-199.html#slack",
    "title": "Welcome to STA 199",
    "section": "Slack",
    "text": "Slack\n\nhttps://slack.com/get-started#/createnew"
  },
  {
    "objectID": "slides/01-welcome-199.html#r-studio",
    "href": "slides/01-welcome-199.html#r-studio",
    "title": "Welcome to STA 199",
    "section": "R-Studio",
    "text": "R-Studio\n– Reserve a STA198-1991 RStudio container\n– Go to https://cmgr.oit.duke.edu/containers\n– Click Reserve Container for the STA198-199 container"
  },
  {
    "objectID": "slides/01-welcome-199.html#ae-01",
    "href": "slides/01-welcome-199.html#ae-01",
    "title": "Welcome to STA 199",
    "section": "ae-01",
    "text": "ae-01\n– We will clone this from GitHub here: https://github.com/sta199-summer-1/ae-01-summer\n– You will do this every day before class & with homework & with labs\n– You will not have the capability to “push changes” to GitHub (yet… this will happen during your first lab!)"
  },
  {
    "objectID": "slides/01-welcome-199.html#cloning-demo",
    "href": "slides/01-welcome-199.html#cloning-demo",
    "title": "Welcome to STA 199",
    "section": "Cloning Demo",
    "text": "Cloning Demo\nhttps://github.com/sta199-summer-1/ae-01-summer"
  },
  {
    "objectID": "slides/01-welcome-199.html#some-r-essentials",
    "href": "slides/01-welcome-199.html#some-r-essentials",
    "title": "Welcome to STA 199",
    "section": "Some R essentials",
    "text": "Some R essentials\n– Functions are (normally) verbs, followed by what they will be applied to in parentheses:"
  },
  {
    "objectID": "slides/01-welcome-199.html#r-essentials",
    "href": "slides/01-welcome-199.html#r-essentials",
    "title": "Welcome to STA 199",
    "section": "R essentials",
    "text": "R essentials\n– Packages are installed with the install.packages function and loaded with the library function, once per session.\n– If you are using R through the container, almost all packages are already installed for you!"
  },
  {
    "objectID": "slides/01-welcome-199.html#packages",
    "href": "slides/01-welcome-199.html#packages",
    "title": "Welcome to STA 199",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/01-welcome-199.html#packages-1",
    "href": "slides/01-welcome-199.html#packages-1",
    "title": "Welcome to STA 199",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/01-welcome-199.html#tidyverse",
    "href": "slides/01-welcome-199.html#tidyverse",
    "title": "Welcome to STA 199",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\n\n\n\n\n\n– The tidyverse is a collection of R packages designed for data science.\n– All packages share an underlying philosophy and a common grammar."
  },
  {
    "objectID": "slides/01-welcome-199.html#quarto",
    "href": "slides/01-welcome-199.html#quarto",
    "title": "Welcome to STA 199",
    "section": "Quarto",
    "text": "Quarto\n– an open-source scientific and technical publishing system\n– publish high-quality articles, reports, presentations, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more\n– Code goes in chunks, defined by three backticks, narrative goes outside of chunks"
  },
  {
    "objectID": "slides/01-welcome-199.html#how-will-we-use-quarto",
    "href": "slides/01-welcome-199.html#how-will-we-use-quarto",
    "title": "Welcome to STA 199",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n– Every assignment / lab / project will be given to you as a Quarto document\n– You will always have a Quarto template document to start with\n– As we get more familiar with R, the more code you will construct on your own"
  },
  {
    "objectID": "slides/01-welcome-199.html#the-process",
    "href": "slides/01-welcome-199.html#the-process",
    "title": "Welcome to STA 199",
    "section": "The process",
    "text": "The process\nmtcars\nYou want to create a visualization. The first thing we need to do is set up the canvas…"
  },
  {
    "objectID": "slides/01-welcome-199.html#the-process-1",
    "href": "slides/01-welcome-199.html#the-process-1",
    "title": "Welcome to STA 199",
    "section": "The process",
    "text": "The process\n    mtcars |>\n        ggplot()"
  },
  {
    "objectID": "slides/01-welcome-199.html#the-process-2",
    "href": "slides/01-welcome-199.html#the-process-2",
    "title": "Welcome to STA 199",
    "section": "The process",
    "text": "The process\n    mtcars |>\n        ggplot(\n        aes(\n             x = variable.name, y = variable.name)\n               )\naes: describe how variables in the data are mapped to your canvas"
  },
  {
    "objectID": "slides/01-welcome-199.html#the-process-3",
    "href": "slides/01-welcome-199.html#the-process-3",
    "title": "Welcome to STA 199",
    "section": "The process",
    "text": "The process\n+ “and”\nWhen working with ggplot functions, we will add to our canvas using +"
  },
  {
    "objectID": "slides/01-welcome-199.html#the-process-4",
    "href": "slides/01-welcome-199.html#the-process-4",
    "title": "Welcome to STA 199",
    "section": "The process",
    "text": "The process\n    mtcars |>\n        ggplot(\n        aes(\n             x = variable.name, y = variable.name)\n               ) +\n        geom_point()"
  },
  {
    "objectID": "slides/01-welcome-199.html#the-process-5",
    "href": "slides/01-welcome-199.html#the-process-5",
    "title": "Welcome to STA 199",
    "section": "The process",
    "text": "The process"
  },
  {
    "objectID": "slides/01-welcome-199.html#summary",
    "href": "slides/01-welcome-199.html#summary",
    "title": "Welcome to STA 199",
    "section": "Summary",
    "text": "Summary\n– There area lot of moving parts in this course\n– Coding is not learned in a day\n– Ask questions often\n– What is version control? Why is it important?\n– What is R vs RStudio?\n– What is Quarto?\n– Starting to work with code!\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#checklist",
    "href": "slides/02-Meet-the-toolkit.html#checklist",
    "title": "R Intro",
    "section": "Checklist",
    "text": "Checklist\n– Are you on Slack?\n– Have you reserved a Duke container?\n– Have you accepted your GitHub organization invite?\n– Do you see ae-1 on GitHub? If so, clone it for class!\n– Chat with me before or after class / send an email with your GitHub username if you do not see ae-01"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#announcements",
    "href": "slides/02-Meet-the-toolkit.html#announcements",
    "title": "R Intro",
    "section": "Announcements",
    "text": "Announcements\n– Slack postings\n– Lab 0\n– AE grading (Drop/Add ends - 25th)"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#clone-ae-01",
    "href": "slides/02-Meet-the-toolkit.html#clone-ae-01",
    "title": "R Intro",
    "section": "Clone ae-01",
    "text": "Clone ae-01\n– If you have not accepted your GitHub invitation, you can’t do this\n– If you don’t see ae-01 in your org, work with the people around you\n– Chat with me after class / send an email with your GitHub username if you do not see ae-01"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#goals-for-today",
    "href": "slides/02-Meet-the-toolkit.html#goals-for-today",
    "title": "R Intro",
    "section": "Goals for today",
    "text": "Goals for today\nBasics we will use throughout the semester\n\nR and RStudio\nQuarto Documents\nMore Practice\nTrain your brain."
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#what-is-r-and-rstudio",
    "href": "slides/02-Meet-the-toolkit.html#what-is-r-and-rstudio",
    "title": "R Intro",
    "section": "What is R and RStudio?",
    "text": "What is R and RStudio?\n– R is a statistical programming language\n– RStudio is a convenient interface for R"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#warm-up-question",
    "href": "slides/02-Meet-the-toolkit.html#warm-up-question",
    "title": "R Intro",
    "section": "Warm Up Question",
    "text": "Warm Up Question\nPlease think through / write down what each line of code would produce.\nTip (and good practice): if you have questions about a function, use ?function.name to pull up the help page! If the help page is not helpful, look at their examples section and click Run Examples."
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#some-r-essentials",
    "href": "slides/02-Meet-the-toolkit.html#some-r-essentials",
    "title": "R Intro",
    "section": "Some R essentials",
    "text": "Some R essentials\n– Functions are (normally) verbs, followed by what they will be applied to in parentheses:"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#r-essentials",
    "href": "slides/02-Meet-the-toolkit.html#r-essentials",
    "title": "R Intro",
    "section": "R essentials",
    "text": "R essentials\n– Packages are installed with the install.packages function and loaded with the library function, once per session:"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#packages",
    "href": "slides/02-Meet-the-toolkit.html#packages",
    "title": "R Intro",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#packages-1",
    "href": "slides/02-Meet-the-toolkit.html#packages-1",
    "title": "R Intro",
    "section": "Packages",
    "text": "Packages\n\n\n\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#tidyverse",
    "href": "slides/02-Meet-the-toolkit.html#tidyverse",
    "title": "R Intro",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\n\n\n\n\n\n– The tidyverse is a collection of R packages designed for data science.\n– All packages share an underlying philosophy and a common grammar."
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#github-version-control",
    "href": "slides/02-Meet-the-toolkit.html#github-version-control",
    "title": "R Intro",
    "section": "GitHub: Version control",
    "text": "GitHub: Version control"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push",
    "href": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push",
    "title": "R Intro",
    "section": "GitHub Commands: Pull Commit Push",
    "text": "GitHub Commands: Pull Commit Push"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-1",
    "href": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-1",
    "title": "R Intro",
    "section": "GitHub Commands: Pull Commit Push",
    "text": "GitHub Commands: Pull Commit Push"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-2",
    "href": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-2",
    "title": "R Intro",
    "section": "GitHub Commands: Pull Commit Push",
    "text": "GitHub Commands: Pull Commit Push"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#quarto",
    "href": "slides/02-Meet-the-toolkit.html#quarto",
    "title": "R Intro",
    "section": "Quarto",
    "text": "Quarto\n– an open-source scientific and technical publishing system\n– publish high-quality articles, reports, presentations, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more\n– Code goes in chunks, defined by three backticks, narrative goes outside of chunks"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#how-will-we-use-quarto",
    "href": "slides/02-Meet-the-toolkit.html#how-will-we-use-quarto",
    "title": "R Intro",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n– Every assignment / lab / project will be given to you as a Quarto document\n– You will always have a Quarto template document to start with\n– As we get more familiar with R, the more code you will construct on your own"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#wrap-up",
    "href": "slides/02-Meet-the-toolkit.html#wrap-up",
    "title": "R Intro",
    "section": "Wrap up",
    "text": "Wrap up\n– What is version control? Why is it important?\n– What is R vs RStudio?\n– What is Quarto?\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#checklist",
    "href": "slides/day-3-grammar-of-data-wrangling.html#checklist",
    "title": "Data Viz + Data Wrangling",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n– Clone ae-03-summer-your-user-name using the SSH key\nNote: if you do not see an ae-03 specifically for you, you have not accepted your org invite"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#announcements",
    "href": "slides/day-3-grammar-of-data-wrangling.html#announcements",
    "title": "Data Viz + Data Wrangling",
    "section": "Announcements",
    "text": "Announcements\n– AE’s are being graded: We will demo how to turn AE’s in today\n– Keep up to date with Slack"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#goals-for-today",
    "href": "slides/day-3-grammar-of-data-wrangling.html#goals-for-today",
    "title": "Data Viz + Data Wrangling",
    "section": "Goals for today",
    "text": "Goals for today\n– Finish off data visualization\n– Introduce dplyr functions\n– Continue R practice"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#warm-up",
    "href": "slides/day-3-grammar-of-data-wrangling.html#warm-up",
    "title": "Data Viz + Data Wrangling",
    "section": "Warm up",
    "text": "Warm up\nIdentify which plot eachgeom creates\n– geom_point()\n– geom_density()\n– geom_boxplot()\n– geom_bar()"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#warm-up-2",
    "href": "slides/day-3-grammar-of-data-wrangling.html#warm-up-2",
    "title": "Data Viz + Data Wrangling",
    "section": "Warm Up #2",
    "text": "Warm Up #2\nWhat is the difference between |> and + ?"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#warm-up-3-reading-practice",
    "href": "slides/day-3-grammar-of-data-wrangling.html#warm-up-3-reading-practice",
    "title": "Data Viz + Data Wrangling",
    "section": "Warm Up #3 (Reading Practice)",
    "text": "Warm Up #3 (Reading Practice)\npenguins |>\n ggplot(\n aes(x = body_mass_g, fill = species )) +\n geom_histogram(binwidth = 200, alpha = 0.3)"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#types-of-variables-1",
    "href": "slides/day-3-grammar-of-data-wrangling.html#types-of-variables-1",
    "title": "Data Viz + Data Wrangling",
    "section": "Types of variables",
    "text": "Types of variables\nType is how an object is stored in memory.\n– glimpse is a great way to check data types\n– Can also use typeof()"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#examples",
    "href": "slides/day-3-grammar-of-data-wrangling.html#examples",
    "title": "Data Viz + Data Wrangling",
    "section": "Examples",
    "text": "Examples\n– glimpse(mtcars)\n– typeof(mtcars$mpg)"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#types-of-variables-2",
    "href": "slides/day-3-grammar-of-data-wrangling.html#types-of-variables-2",
    "title": "Data Viz + Data Wrangling",
    "section": "Types of variables",
    "text": "Types of variables\nSome of the types of variables include:\n– “logical”\n– “integer”\n– “double”\n– “character”\n– “factor”"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#logical",
    "href": "slides/day-3-grammar-of-data-wrangling.html#logical",
    "title": "Data Viz + Data Wrangling",
    "section": "logical",
    "text": "logical\n– logi in glimpse\n– The logical data type in R is also known as boolean data type. It can only have two values: TRUE and FALSE. \n– as.logical can turn a variable into a logical. False = 0; True everything else"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#integer",
    "href": "slides/day-3-grammar-of-data-wrangling.html#integer",
    "title": "Data Viz + Data Wrangling",
    "section": "integer",
    "text": "integer\n– int in glimpse\n– Integers are whole numbers (those numbers without a decimal point)\n– as.integer can turn a double into an integer. Forces 22.8 -> 22."
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#double",
    "href": "slides/day-3-grammar-of-data-wrangling.html#double",
    "title": "Data Viz + Data Wrangling",
    "section": "double",
    "text": "double\n– dbl in glimpse\n– Real numbers (can include decimals)\n– as.doublecan force a column to be a double. Identical to as.numeric."
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#character",
    "href": "slides/day-3-grammar-of-data-wrangling.html#character",
    "title": "Data Viz + Data Wrangling",
    "section": "character",
    "text": "character\n– chr in glimpse\n– Character string (text)\n– as.character attempts to coerce its argument to character type"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#factor",
    "href": "slides/day-3-grammar-of-data-wrangling.html#factor",
    "title": "Data Viz + Data Wrangling",
    "section": "factor",
    "text": "factor\n– fct in glimpse\n– Factor in R is also known as a categorical variable that stores both string and integer data values as levels.\n– factor attempts to coerce its argument to factor type"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#why-this-matters",
    "href": "slides/day-3-grammar-of-data-wrangling.html#why-this-matters",
    "title": "Data Viz + Data Wrangling",
    "section": "Why this matters",
    "text": "Why this matters\nam: Transmission (0 = automatic; 1 = manual)"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#why-this-matters-1",
    "href": "slides/day-3-grammar-of-data-wrangling.html#why-this-matters-1",
    "title": "Data Viz + Data Wrangling",
    "section": "Why this matters",
    "text": "Why this matters\n– Functions\n– Plotting\n– Summary statistics"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#general-takeaways",
    "href": "slides/day-3-grammar-of-data-wrangling.html#general-takeaways",
    "title": "Data Viz + Data Wrangling",
    "section": "General takeaways",
    "text": "General takeaways\n– Can you identify variable types\n– Often need to turn something into a factor to make it categorical\n– Often need to turn something into a double (numeric) to make it quantitative"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#todays-live-coding-topic-data-manipulation",
    "href": "slides/day-3-grammar-of-data-wrangling.html#todays-live-coding-topic-data-manipulation",
    "title": "Data Viz + Data Wrangling",
    "section": "Today’s live coding topic (Data Manipulation)",
    "text": "Today’s live coding topic (Data Manipulation)"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#data-manipulation",
    "href": "slides/day-3-grammar-of-data-wrangling.html#data-manipulation",
    "title": "Data Viz + Data Wrangling",
    "section": "Data Manipulation",
    "text": "Data Manipulation\n– Want to subset\n– Want to manipulate\n– Want to create\n… from data"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#function-of-the-day-saw-on-lab-0",
    "href": "slides/day-3-grammar-of-data-wrangling.html#function-of-the-day-saw-on-lab-0",
    "title": "Data Viz + Data Wrangling",
    "section": "Function of the day (saw on lab-0)",
    "text": "Function of the day (saw on lab-0)\nThemes are a powerful way to customize the non-data components of your plots: i.e. titles, labels, fonts, background, gridlines, and legends.\ntheme()\n– https://ggplot2.tidyverse.org/reference/theme.html\n– I often use it for legend manipulation… but there is so much more!"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#plot-recreate",
    "href": "slides/day-3-grammar-of-data-wrangling.html#plot-recreate",
    "title": "Data Viz + Data Wrangling",
    "section": "Plot Recreate",
    "text": "Plot Recreate"
  },
  {
    "objectID": "slides/day-3-grammar-of-data-wrangling.html#wrap-up",
    "href": "slides/day-3-grammar-of-data-wrangling.html#wrap-up",
    "title": "Data Viz + Data Wrangling",
    "section": "Wrap up",
    "text": "Wrap up\n– Data types matter. Get in the habit of checking them at the beginning of analysis\n– Have the tools to create new variables, calculate summary statistics, etc. that accompany strong visualizations\n– Have the tools to manipulate data to be in a more usable format\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day10logistic.html#checklist",
    "href": "slides/day10logistic.html#checklist",
    "title": "MLR - Logistic Regression",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-10\n– Homework 3 Due Tuesday (6-13)\n– Project Proposal due Monday (6-12)\n— Turn in on GitHub\n— Lab today is a project work day"
  },
  {
    "objectID": "slides/day10logistic.html#warm-up-question-1",
    "href": "slides/day10logistic.html#warm-up-question-1",
    "title": "MLR - Logistic Regression",
    "section": "Warm Up: Question 1",
    "text": "Warm Up: Question 1\n– What is the main difference between Simple Linear Regression and Multiple Linear Regression?"
  },
  {
    "objectID": "slides/day10logistic.html#warm-up-question-2",
    "href": "slides/day10logistic.html#warm-up-question-2",
    "title": "MLR - Logistic Regression",
    "section": "Warm Up: Question 2",
    "text": "Warm Up: Question 2\n– What is the main difference between an additive model and an interaction model?"
  },
  {
    "objectID": "slides/day10logistic.html#goals",
    "href": "slides/day10logistic.html#goals",
    "title": "MLR - Logistic Regression",
    "section": "Goals",
    "text": "Goals\n– Understand R-squared vs Adjusted R-squared\n– What, why and how of logistic regression"
  },
  {
    "objectID": "slides/day10logistic.html#more-about-r-squared-vs-adjusted-r-squared",
    "href": "slides/day10logistic.html#more-about-r-squared-vs-adjusted-r-squared",
    "title": "MLR - Logistic Regression",
    "section": "More about R-Squared vs Adjusted R-Squared",
    "text": "More about R-Squared vs Adjusted R-Squared\nR-squared has…\n\nA meaningful definition\na relationship with cor when in the SLR case"
  },
  {
    "objectID": "slides/day10logistic.html#r-squared",
    "href": "slides/day10logistic.html#r-squared",
    "title": "MLR - Logistic Regression",
    "section": "R-Squared",
    "text": "R-Squared"
  },
  {
    "objectID": "slides/day10logistic.html#r-squared-1",
    "href": "slides/day10logistic.html#r-squared-1",
    "title": "MLR - Logistic Regression",
    "section": "R-squared",
    "text": "R-squared"
  },
  {
    "objectID": "slides/day10logistic.html#more-about-r-squared-vs-adjusted-r-squared-1",
    "href": "slides/day10logistic.html#more-about-r-squared-vs-adjusted-r-squared-1",
    "title": "MLR - Logistic Regression",
    "section": "More about R-Squared vs Adjusted R-Squared",
    "text": "More about R-Squared vs Adjusted R-Squared\nWhen can we use R-squared for model selection?\n\nWhen models have the same number of variables\nWhy can’t we use it to compare models with different number of variables? See ae-09 for demonstration."
  },
  {
    "objectID": "slides/day10logistic.html#r-squared-takeaway",
    "href": "slides/day10logistic.html#r-squared-takeaway",
    "title": "MLR - Logistic Regression",
    "section": "R-squared: Takeaway",
    "text": "R-squared: Takeaway\n– statistical measure in a regression model that determines the proportion of variance in the response variable that can be explained by the explanatory variable(s).\n– The more variables you include, the larger the R-squared value will be (always)"
  },
  {
    "objectID": "slides/day10logistic.html#more-about-r-squared-vs-adjusted-r-squared-2",
    "href": "slides/day10logistic.html#more-about-r-squared-vs-adjusted-r-squared-2",
    "title": "MLR - Logistic Regression",
    "section": "More about R-Squared vs Adjusted R-Squared",
    "text": "More about R-Squared vs Adjusted R-Squared\nAdjusted R-squared …\n\nDoesn’t have a clean definition\nIs very useful for model selection"
  },
  {
    "objectID": "slides/day10logistic.html#adjusted-r-squared",
    "href": "slides/day10logistic.html#adjusted-r-squared",
    "title": "MLR - Logistic Regression",
    "section": "Adjusted R-Squared",
    "text": "Adjusted R-Squared\nTakeaway: Adds a penalty for “unimportant” predictors (x’s)"
  },
  {
    "objectID": "slides/day10logistic.html#finish-mlr",
    "href": "slides/day10logistic.html#finish-mlr",
    "title": "MLR - Logistic Regression",
    "section": "Finish MLR",
    "text": "Finish MLR\n– clone ae-10\n– finish MLR (2 quantitative explanatory variables)"
  },
  {
    "objectID": "slides/day10logistic.html#goals-1",
    "href": "slides/day10logistic.html#goals-1",
    "title": "MLR - Logistic Regression",
    "section": "Goals",
    "text": "Goals\n– The What, Why, and How of Logistic Regression"
  },
  {
    "objectID": "slides/day10logistic.html#what-is-logistic-regreesion",
    "href": "slides/day10logistic.html#what-is-logistic-regreesion",
    "title": "MLR - Logistic Regression",
    "section": "What is Logistic Regreesion",
    "text": "What is Logistic Regreesion\n\nSimilar to linear regression…. but\nModeling tool when our response is categorical"
  },
  {
    "objectID": "slides/day10logistic.html#what-we-will-do-today",
    "href": "slides/day10logistic.html#what-we-will-do-today",
    "title": "MLR - Logistic Regression",
    "section": "What we will do today",
    "text": "What we will do today\n– This type of model is called a generalized linear model"
  },
  {
    "objectID": "slides/day10logistic.html#terms",
    "href": "slides/day10logistic.html#terms",
    "title": "MLR - Logistic Regression",
    "section": "Terms",
    "text": "Terms\n– Bernoulli Distribution\n\n2 outcomes: Success (p) or Failure (1-p)\n\\(y_i\\) ~ Bern(p)\nWhat we can do is we can use our explanatory variable(s) to model p"
  },
  {
    "objectID": "slides/day10logistic.html#steps",
    "href": "slides/day10logistic.html#steps",
    "title": "MLR - Logistic Regression",
    "section": "2 Steps",
    "text": "2 Steps\n– 1: Define a linear model\n– 2: Define a link function"
  },
  {
    "objectID": "slides/day10logistic.html#a-linear-model",
    "href": "slides/day10logistic.html#a-linear-model",
    "title": "MLR - Logistic Regression",
    "section": "A linear model",
    "text": "A linear model\n\\(\\eta_i = \\beta_o + \\beta_1*X_i + ...\\)\nNote: \\(\\eta_i\\) is some response of our linear model\n\nBut we can’t stop here… \\(\\eta_i\\) isn’t the probability of success of our response\nThink about what a linear model looks like"
  },
  {
    "objectID": "slides/day10logistic.html#next-steps",
    "href": "slides/day10logistic.html#next-steps",
    "title": "MLR - Logistic Regression",
    "section": "Next steps",
    "text": "Next steps\n– Preform a transformation to our response variable so it has the appropriate range of values\n– “Link” our linear model to the paramater of the outcome distribution\n– \\(y_i\\) ~ Bern(p)"
  },
  {
    "objectID": "slides/day10logistic.html#generalized-linear-model",
    "href": "slides/day10logistic.html#generalized-linear-model",
    "title": "MLR - Logistic Regression",
    "section": "Generalized linear model",
    "text": "Generalized linear model\n\nNext, we need a link function that relates the linear model to the parameter of the outcome distribution i.e. transform the linear model to have an appropriate range"
  },
  {
    "objectID": "slides/day10logistic.html#logit-link-function",
    "href": "slides/day10logistic.html#logit-link-function",
    "title": "MLR - Logistic Regression",
    "section": "Logit Link Function",
    "text": "Logit Link Function\nThe logit link function is defined as follows:\n\n\\(\\eta_i\\) = \\(log (\\frac{p}{1-p})\\)\n– Note: log is in reference to natural log"
  },
  {
    "objectID": "slides/day10logistic.html#logit-link-function-1",
    "href": "slides/day10logistic.html#logit-link-function-1",
    "title": "MLR - Logistic Regression",
    "section": "Logit Link function",
    "text": "Logit Link function\n– A logit link function transforms the probabilities of the levels of a categorical response variable to a continuous scale that is unbounded\n– Note: log is in reference to natural log"
  },
  {
    "objectID": "slides/day10logistic.html#whats-this-look-like",
    "href": "slides/day10logistic.html#whats-this-look-like",
    "title": "MLR - Logistic Regression",
    "section": "What’s this look like",
    "text": "What’s this look like\nTakes a [0,1] probability and maps it to log odds (-\\(\\infty\\) to \\(\\infty\\).)"
  },
  {
    "objectID": "slides/day10logistic.html#almost.",
    "href": "slides/day10logistic.html#almost.",
    "title": "MLR - Logistic Regression",
    "section": "Almost….",
    "text": "Almost….\nThis isn’t exactly what we need though…..\nWill help us get to our goal"
  },
  {
    "objectID": "slides/day10logistic.html#so-we-have-a-generalized-linear-model-glm",
    "href": "slides/day10logistic.html#so-we-have-a-generalized-linear-model-glm",
    "title": "MLR - Logistic Regression",
    "section": "So we have a generalized linear model (GLM)",
    "text": "So we have a generalized linear model (GLM)\n\n\\(logit(p_i)\\) = \\(\\widehat{\\beta_o} +\\widehat{\\beta}_1X1_i + ....\\)\nlogit(p) is also known as the log-odds\nlogit(p) = \\(log(\\frac{p}{1-p})\\)\n\\(log(\\frac{p}{1-p})\\) = \\(\\widehat{\\beta_o} +\\widehat{\\beta}_1X1 + ....\\)"
  },
  {
    "objectID": "slides/day10logistic.html#one-final-fix",
    "href": "slides/day10logistic.html#one-final-fix",
    "title": "MLR - Logistic Regression",
    "section": "One final fix",
    "text": "One final fix\n– Recall, the goal is to take values between -\\(\\infty\\) and \\(\\infty\\) and map them to probabilities. We need the opposite of the link function… or the inverse\n– How do we take the inverse of a natural log?\n\nTaking the inverse of the logit function will map arbitrary real values back to the range [0, 1]"
  },
  {
    "objectID": "slides/day10logistic.html#so",
    "href": "slides/day10logistic.html#so",
    "title": "MLR - Logistic Regression",
    "section": "So",
    "text": "So\nWe need to take the inverse of the logit function\n\n\\[log(\\frac{p}{1-p}) = \\widehat{\\beta_o} +\\widehat{\\beta}_1X1 + ....\\]"
  },
  {
    "objectID": "slides/day10logistic.html#inverse-logit-link",
    "href": "slides/day10logistic.html#inverse-logit-link",
    "title": "MLR - Logistic Regression",
    "section": "Inverse Logit Link",
    "text": "Inverse Logit Link\nExample Figure:"
  },
  {
    "objectID": "slides/day10logistic.html#what-we-will-do-today-1",
    "href": "slides/day10logistic.html#what-we-will-do-today-1",
    "title": "MLR - Logistic Regression",
    "section": "What we will do today",
    "text": "What we will do today\nCalculate probabilities of success of a response based on values of explanatory variable x.\n\n\n\n\n\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day11log2.html#checklist",
    "href": "slides/day11log2.html#checklist",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-11\n– Homework 3 Due Tuesday (6-13)\n– Project Proposal due tonight (6-12)\n— Turn in on GitHub\n— Feedback coming in the next day or two"
  },
  {
    "objectID": "slides/day11log2.html#feedback-for-your-project",
    "href": "slides/day11log2.html#feedback-for-your-project",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Feedback for your project",
    "text": "Feedback for your project\n– Will be on GitHub Issues\n— Demo"
  },
  {
    "objectID": "slides/day11log2.html#warm-up-question",
    "href": "slides/day11log2.html#warm-up-question",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Warm Up: Question",
    "text": "Warm Up: Question\nWhat are the main differences between:\n– Simple Linear Regression vs Multiple Linear Regression\n– Logistic Regression vs Linear Regression"
  },
  {
    "objectID": "slides/day11log2.html#warm-up-logistic-interpretation",
    "href": "slides/day11log2.html#warm-up-logistic-interpretation",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Warm Up: Logistic Interpretation",
    "text": "Warm Up: Logistic Interpretation\nRecall: Fit a logistic regression model to predict if an email was spam or not.\n\n– Interpret the estimate associated with exclaim_mess\n– Using this output, how can we calculate probabilities of a spam email?\nNote: If you are interested in log-odds, I found this small article useful here"
  },
  {
    "objectID": "slides/day11log2.html#model-selection",
    "href": "slides/day11log2.html#model-selection",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Model Selection",
    "text": "Model Selection\n\nR-squared (if number of variables are the same)\nAdj-R-squared (if number of variables are same / different)\nAIC"
  },
  {
    "objectID": "slides/day11log2.html#akaike-information-criterion-aic",
    "href": "slides/day11log2.html#akaike-information-criterion-aic",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Akaike information criterion (AIC)",
    "text": "Akaike information criterion (AIC)\n– which of multiple models is most likely to be the best model for a given data set.\n– based on the data, which model is the most likely"
  },
  {
    "objectID": "slides/day11log2.html#akaike-information-criterion-aic-1",
    "href": "slides/day11log2.html#akaike-information-criterion-aic-1",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Akaike information criterion (AIC)",
    "text": "Akaike information criterion (AIC)\n– No “nice” definition\n– Lower is better (different than Adj-R-squared)\n– Lower AIC and BIC values mean that a model is considered to be closer to the ‘truth’"
  },
  {
    "objectID": "slides/day11log2.html#aic-in-r",
    "href": "slides/day11log2.html#aic-in-r",
    "title": "More Model Selection + Logistic Regression II",
    "section": "AIC in R",
    "text": "AIC in R\n– glance(model1)$AIC"
  },
  {
    "objectID": "slides/day11log2.html#aic-vs-adj-r-squared",
    "href": "slides/day11log2.html#aic-vs-adj-r-squared",
    "title": "More Model Selection + Logistic Regression II",
    "section": "AIC vs Adj-R-squared",
    "text": "AIC vs Adj-R-squared\n– Common to see AIC and Adj-R-squared used for model selection\n– The differences are more clear in a theory course. In there own way, they provide evidence of the “best” model.\n– In short: Use one in practice, but do not mix…\n— They are built off a different theoretical foundation"
  },
  {
    "objectID": "slides/day11log2.html#situation",
    "href": "slides/day11log2.html#situation",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Situation",
    "text": "Situation\nWant to build a model that predicts well.\n– What should that model look like?\n– How do we build it?\n– How do we know if it predicts well?"
  },
  {
    "objectID": "slides/day11log2.html#what-should-it-look-like",
    "href": "slides/day11log2.html#what-should-it-look-like",
    "title": "More Model Selection + Logistic Regression II",
    "section": "What should it look like?",
    "text": "What should it look like?\nWhich model would you prefer?"
  },
  {
    "objectID": "slides/day11log2.html#model-selection-tools",
    "href": "slides/day11log2.html#model-selection-tools",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Model Selection tools",
    "text": "Model Selection tools\n– can most definitely select an overfit model"
  },
  {
    "objectID": "slides/day11log2.html#overfitting",
    "href": "slides/day11log2.html#overfitting",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Overfitting",
    "text": "Overfitting\n– Overfitting is a concept in data science, which occurs when a statistical model fits exactly against its data.\n– This doesn’t make sense if are goal is to predict!"
  },
  {
    "objectID": "slides/day11log2.html#assessing-model-prediction",
    "href": "slides/day11log2.html#assessing-model-prediction",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Assessing model prediction",
    "text": "Assessing model prediction\nVocab…\n– Testing Data Set\n– Training Data Set\n– ROC Curve\n– Sensitivity (True Positive)\n– Specificity (True Negative)"
  },
  {
    "objectID": "slides/day11log2.html#splitting-the-data",
    "href": "slides/day11log2.html#splitting-the-data",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Splitting the data",
    "text": "Splitting the data\nWhen the goal is prediction….\n– When able, it may be advantageous to withhold a part of your data when creating your model\n– Can use what’s withheld to evaluate how well your model predicts"
  },
  {
    "objectID": "slides/day11log2.html#training-data-set",
    "href": "slides/day11log2.html#training-data-set",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Training Data Set",
    "text": "Training Data Set\n– training data is the dataset you use to build your model\n– roughly 80% of a larger data set\n“Sandbox” for model building."
  },
  {
    "objectID": "slides/day11log2.html#testing-data-set",
    "href": "slides/day11log2.html#testing-data-set",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Testing Data Set",
    "text": "Testing Data Set\n– data to be used to evaluate your model\n– evaluate the predictive performance\n– roughly 20% of the larger data set"
  },
  {
    "objectID": "slides/day11log2.html#important-note",
    "href": "slides/day11log2.html#important-note",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Important Note",
    "text": "Important Note\n– Training and Testing data sets are created at random"
  },
  {
    "objectID": "slides/day11log2.html#true-positive-rate",
    "href": "slides/day11log2.html#true-positive-rate",
    "title": "More Model Selection + Logistic Regression II",
    "section": "True Positive Rate",
    "text": "True Positive Rate\n– Also known as sensitivity\n– Probability of correctly detecting a “success”"
  },
  {
    "objectID": "slides/day11log2.html#false-positive",
    "href": "slides/day11log2.html#false-positive",
    "title": "More Model Selection + Logistic Regression II",
    "section": "False Positive",
    "text": "False Positive\n– a result which incorrectly indicates that a particular condition or attribute is present (something is not there, but we say it is)\n– Incorrectly predicting the truth of “not present”\n– 1 - specificity\nSpecificity - how well a test can classify something who truly does not have the condition of interest"
  },
  {
    "objectID": "slides/day11log2.html#email-context",
    "href": "slides/day11log2.html#email-context",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Email Context",
    "text": "Email Context\nGoal: Create a spam filter (want to predict if an email is spam)\n– Define a true positive\n– Define a false positive"
  },
  {
    "objectID": "slides/day11log2.html#plotting-predictive-performance",
    "href": "slides/day11log2.html#plotting-predictive-performance",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Plotting predictive performance",
    "text": "Plotting predictive performance"
  },
  {
    "objectID": "slides/day11log2.html#receiver-operating-characteristic-curve-roc",
    "href": "slides/day11log2.html#receiver-operating-characteristic-curve-roc",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Receiver operating characteristic curve (ROC)",
    "text": "Receiver operating characteristic curve (ROC)\n– Is a graph showing the performance of a classification model at different classification thresholds\n– The larger the area under the curve is, the better the performance of the model across all thresholds"
  },
  {
    "objectID": "slides/day11log2.html#statistical-inference-1",
    "href": "slides/day11log2.html#statistical-inference-1",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n Cleaning Data  EDA   Modeling   Statistical Inference \n— Hypothesis Testing\n— Confidence Intervals"
  },
  {
    "objectID": "slides/day11log2.html#motivate-discussion",
    "href": "slides/day11log2.html#motivate-discussion",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Motivate Discussion",
    "text": "Motivate Discussion\nHow tall are Duke Students?\n\nWe don’t know…. but we can collect data and learn more about this"
  },
  {
    "objectID": "slides/day11log2.html#population-parameters",
    "href": "slides/day11log2.html#population-parameters",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Population Parameters",
    "text": "Population Parameters\n– What we are interested in\n\\(\\mu\\)\n\\(\\pi\\)"
  },
  {
    "objectID": "slides/day11log2.html#population-parameters-1",
    "href": "slides/day11log2.html#population-parameters-1",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Population Parameters",
    "text": "Population Parameters\n– Are these population parameters different than some value?\n– What is a range of plausible values that the population parameter could be?"
  },
  {
    "objectID": "slides/day11log2.html#general-process",
    "href": "slides/day11log2.html#general-process",
    "title": "More Model Selection + Logistic Regression II",
    "section": "General Process",
    "text": "General Process\n– Decide what we want to investigate\n– Collect data\n– We need to quantify variability!"
  },
  {
    "objectID": "slides/day11log2.html#goals",
    "href": "slides/day11log2.html#goals",
    "title": "More Model Selection + Logistic Regression II",
    "section": "Goals",
    "text": "Goals\n– Assess how good your model is at prediction\n– Visualize how well your model predicts new observations\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day12inference.html#checklist",
    "href": "slides/day12inference.html#checklist",
    "title": "Intro to Inference",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-12\n– Homework 3 Due tonight 11:59 (6-13)\n– Project Proposal Feedback Soon\n– Lab due Thursday 5:00 (6-15)\n— Issues\n– Group Feedback Survey in Sakai Coming Today (look for announcement)\n– Exam 1 common mistakes to be posted on Slack today\n– Exam 2: June 15th Start | June 20th due date"
  },
  {
    "objectID": "slides/day12inference.html#warm-up",
    "href": "slides/day12inference.html#warm-up",
    "title": "Intro to Inference",
    "section": "Warm Up",
    "text": "Warm Up\nLast class, we fit a model to predict"
  },
  {
    "objectID": "slides/day12inference.html#warm-up-1",
    "href": "slides/day12inference.html#warm-up-1",
    "title": "Intro to Inference",
    "section": "Warm Up",
    "text": "Warm Up\nGo to ae-12. Go to the roc.qmd\nCreate your own roc curve using email_fit2.\nCompare the predictive performance to email_fit.\nIs this new model better? Worse? How can you tell?"
  },
  {
    "objectID": "slides/day12inference.html#statistical-inference",
    "href": "slides/day12inference.html#statistical-inference",
    "title": "Intro to Inference",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n– the methods of forming judgments about population parameters"
  },
  {
    "objectID": "slides/day12inference.html#population-parameters",
    "href": "slides/day12inference.html#population-parameters",
    "title": "Intro to Inference",
    "section": "Population Parameters",
    "text": "Population Parameters\n– \\(\\mu\\)\n– \\(\\pi\\)"
  },
  {
    "objectID": "slides/day12inference.html#population-parameters-1",
    "href": "slides/day12inference.html#population-parameters-1",
    "title": "Intro to Inference",
    "section": "Population Parameters",
    "text": "Population Parameters\n– \\(\\mu_1 - \\mu_2\\)\n– \\(\\pi_1 - \\pi_2\\)"
  },
  {
    "objectID": "slides/day12inference.html#motivation",
    "href": "slides/day12inference.html#motivation",
    "title": "Intro to Inference",
    "section": "Motivation",
    "text": "Motivation\nBut…. we don’t know what these values are, so we collect data!"
  },
  {
    "objectID": "slides/day12inference.html#sample-statistics",
    "href": "slides/day12inference.html#sample-statistics",
    "title": "Intro to Inference",
    "section": "Sample Statistics",
    "text": "Sample Statistics\n– \\(\\bar{x}\\)\n– \\(\\hat{p}\\)"
  },
  {
    "objectID": "slides/day12inference.html#sample-statistics-1",
    "href": "slides/day12inference.html#sample-statistics-1",
    "title": "Intro to Inference",
    "section": "Sample Statistics",
    "text": "Sample Statistics\n– \\(\\bar{x_1} - \\bar{x_2}\\)\n– \\(\\hat{p_1} - \\hat{p_2}\\)"
  },
  {
    "objectID": "slides/day12inference.html#questions-that-we-will-answer",
    "href": "slides/day12inference.html#questions-that-we-will-answer",
    "title": "Intro to Inference",
    "section": "Questions that we will answer",
    "text": "Questions that we will answer\n– Test to see if our population parameter is different than a value (hypothesis testing)\n– Estimate the value of the population parameter\nand we will use data and the idea of variability to answer these questions"
  },
  {
    "objectID": "slides/day12inference.html#today",
    "href": "slides/day12inference.html#today",
    "title": "Intro to Inference",
    "section": "Today",
    "text": "Today\nWe will go through how to conduct a hypothesis test using bootstrapping procedures!"
  },
  {
    "objectID": "slides/day12inference.html#bootstrap-randomization",
    "href": "slides/day12inference.html#bootstrap-randomization",
    "title": "Intro to Inference",
    "section": "Bootstrap & Randomization",
    "text": "Bootstrap & Randomization\nBootstrapping is a statistical procedure that re samples within a single data set to create many simulated samples.\nThe term bootstrapping comes from the phrase “pulling oneself up by one’s bootstraps”, which is a metaphor for accomplishing an impossible task without any outside help\nRandomization is when we randomly shuffle within a single data set to create many simulated samples"
  },
  {
    "objectID": "slides/day12inference.html#why",
    "href": "slides/day12inference.html#why",
    "title": "Intro to Inference",
    "section": "Why",
    "text": "Why\nImpossible task: estimating / testing a population parameter using data from only the given sample.\nNote: This notion of saying something about a population parameter using only information from an observed sample is the crux of statistical inference."
  },
  {
    "objectID": "slides/day12inference.html#hypothesis-testing",
    "href": "slides/day12inference.html#hypothesis-testing",
    "title": "Intro to Inference",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n– Null hypothesis \\(H_o:\\)\n– Alternative hypothesis \\(H_a:\\)"
  },
  {
    "objectID": "slides/day12inference.html#null-hypothesis",
    "href": "slides/day12inference.html#null-hypothesis",
    "title": "Intro to Inference",
    "section": "Null hypothesis",
    "text": "Null hypothesis\n– Assumes “nothing is going on”\n– Sets a parameter = 0\n– Sets group equal to each other"
  },
  {
    "objectID": "slides/day12inference.html#alternative-hypothesis",
    "href": "slides/day12inference.html#alternative-hypothesis",
    "title": "Intro to Inference",
    "section": "Alternative hypothesis",
    "text": "Alternative hypothesis\n– This is what we are interested in!\n– We dictate this by the sign of our alternative hypothesis"
  },
  {
    "objectID": "slides/day12inference.html#alternative-hypothesis-1",
    "href": "slides/day12inference.html#alternative-hypothesis-1",
    "title": "Intro to Inference",
    "section": "Alternative hypothesis",
    "text": "Alternative hypothesis\n– >\n– <\n– \\(\\neq\\)"
  },
  {
    "objectID": "slides/day12inference.html#ae-12",
    "href": "slides/day12inference.html#ae-12",
    "title": "Intro to Inference",
    "section": "ae-12",
    "text": "ae-12\n– p-value\n– significance level\n– Decisions; Conclusions; Interpretations"
  },
  {
    "objectID": "slides/day12inference.html#when-can-we-trust-these-results",
    "href": "slides/day12inference.html#when-can-we-trust-these-results",
    "title": "Intro to Inference",
    "section": "When can we trust these results?",
    "text": "When can we trust these results?\n– When the sample we take is representative\nWe have a random sample\nSample size is not very small"
  },
  {
    "objectID": "slides/day12inference.html#can-you-read-martian-bumba-kiki",
    "href": "slides/day12inference.html#can-you-read-martian-bumba-kiki",
    "title": "Intro to Inference",
    "section": "Can you read Martian? Bumba & Kiki",
    "text": "Can you read Martian? Bumba & Kiki\nAlone, please think about which option is Bumba\n\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day13.html#checklist",
    "href": "slides/day13.html#checklist",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "Checklist",
    "text": "Checklist\n– Proposal feedback has been given. See issues.\n– Exam 2 released at 5 (post in Slack if you have any questions)\n— Start early. This is slightly longer than Exam 1\n– Group Feedback Survey in Sakai Due by 5\n– Lab Due by 5\n– Keep up with Slack!"
  },
  {
    "objectID": "slides/day13.html#warm-up---notation-check",
    "href": "slides/day13.html#warm-up---notation-check",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "Warm Up - Notation Check",
    "text": "Warm Up - Notation Check\n– \\(\\pi\\)\n– \\(\\bar{x}\\)\n– \\(\\mu\\)\n– \\(\\hat{p}\\)"
  },
  {
    "objectID": "slides/day13.html#p-value-of-0",
    "href": "slides/day13.html#p-value-of-0",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "P-value of 0?",
    "text": "P-value of 0?\nWhen would a p-value of 0 be reported? Let’s draw it.\nIn R, you will get this error…\nPlease be cautious in reporting a p-value of 0. This result is an approximation based on the number of reps chosen in the generate()"
  },
  {
    "objectID": "slides/day13.html#we-have-been-very-carful-with-our-language",
    "href": "slides/day13.html#we-have-been-very-carful-with-our-language",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "We have been very carful with our language",
    "text": "We have been very carful with our language\nHere’s why\n– \\(\\alpha\\) > p-value (Reject Ho, Conclude Ha)\n– \\(\\alpha\\) < p-value (Fail to reject Ho, Weak evidence for Ha)\n– Demo after airbnb example"
  },
  {
    "objectID": "slides/day13.html#the-research-process",
    "href": "slides/day13.html#the-research-process",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "The research process",
    "text": "The research process\n– Set up your null and alternative\n– Collect data\n– Conduct a hypothesis test using simulation methods\n– Talk about the results"
  },
  {
    "objectID": "slides/day13.html#when-can-we-trust-these-results",
    "href": "slides/day13.html#when-can-we-trust-these-results",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "When can we trust these results?",
    "text": "When can we trust these results?\n– When the sample we take is representative\nWe have a random sample\nSample size is not very small"
  },
  {
    "objectID": "slides/day13.html#cpr",
    "href": "slides/day13.html#cpr",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "CPR",
    "text": "CPR\nHere we consider an experiment with patients who underwent CPR for a heart attack and were subsequently admitted to a hospital. Each patient was randomly assigned to either receive a blood thinner (treatment group) or not receive a blood thinner (control group). The outcome variable of interest was whether the patient survived for at least 24 hours. We are interested in if the proportion of patients who died were different between those who were given blood thinners or not. Note: We will considered “died” as a “success”\n– Null\n– Alternative"
  },
  {
    "objectID": "slides/day13.html#how-do-we-simulate-this-distribution",
    "href": "slides/day13.html#how-do-we-simulate-this-distribution",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "How do we simulate this distribution?",
    "text": "How do we simulate this distribution?\nLet’s demonstrate!"
  },
  {
    "objectID": "slides/day13.html#confidence-intervals",
    "href": "slides/day13.html#confidence-intervals",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n– Confidence Intervals are a statistical method uses to estimate population parameters"
  },
  {
    "objectID": "slides/day13.html#ci-vs-hypo-testing",
    "href": "slides/day13.html#ci-vs-hypo-testing",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "CI vs Hypo Testing",
    "text": "CI vs Hypo Testing\n– Both are curious about population parameters\n– Both use the idea of variability"
  },
  {
    "objectID": "slides/day13.html#ci-vs-hypo-testing-1",
    "href": "slides/day13.html#ci-vs-hypo-testing-1",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "CI vs Hypo Testing",
    "text": "CI vs Hypo Testing\n– CIs do not assume a hypothesis\n– The distribution used is not centered at the null value (more on this in a second)"
  },
  {
    "objectID": "slides/day13.html#confidence-vs-probability",
    "href": "slides/day13.html#confidence-vs-probability",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "Confidence vs Probability",
    "text": "Confidence vs Probability\n– Before making confidence intervals, let’s define what it is and how it is different than probability.\n\nTakeaway: Being unknown is not the same as being random"
  },
  {
    "objectID": "slides/day13.html#confidence",
    "href": "slides/day13.html#confidence",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "Confidence",
    "text": "Confidence\nConfidence - the percentage of all possible confidence intervals, created under the same conditions, expected to include the true population parameter\n– https://www.rossmanchance.com/applets/2021/confsim/ConfSim.html\n– For your confidence interval, the parameter is not random"
  },
  {
    "objectID": "slides/day13.html#confidence-interval",
    "href": "slides/day13.html#confidence-interval",
    "title": "Bootstrap Hypothesis Testing Continued",
    "section": "Confidence Interval",
    "text": "Confidence Interval\nNow, let’s make one and talk through it!\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#checklist",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#checklist",
    "title": "Visualizing various types of data",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n– Go to https://github.com/sta199-summer-1/ae-02-summer and find your ae-02-summer\n– Clone the repo in your container, open the Quarto document in the repo (as we did with ae-01)\n– Have you filled out the Getting to know you survey?\n– Are you on Slack?\n– Prepare Material?"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#announcements",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#announcements",
    "title": "Visualizing various types of data",
    "section": "Announcements",
    "text": "Announcements\nDue Dates + Turn In\n– All AEs are due the upcoming Friday night by 11:59 - GitHub\n– Labs due Thursday and Monday (before lecture)- Gradescope\n– HWs due ~ 1 week from assigned - Gradescope"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#announcements-getting-to-know-you-survey",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#announcements-getting-to-know-you-survey",
    "title": "Visualizing various types of data",
    "section": "Announcements: Getting to Know you Survey",
    "text": "Announcements: Getting to Know you Survey"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#announcements-getting-to-know-you-survey-1",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#announcements-getting-to-know-you-survey-1",
    "title": "Visualizing various types of data",
    "section": "Announcements: Getting to Know you Survey",
    "text": "Announcements: Getting to Know you Survey"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#announcements-getting-to-know-you-survey-2",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#announcements-getting-to-know-you-survey-2",
    "title": "Visualizing various types of data",
    "section": "Announcements: Getting to Know you Survey",
    "text": "Announcements: Getting to Know you Survey\nVideos\n– Will not post\n– Can always request"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#goals-for-today",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#goals-for-today",
    "title": "Visualizing various types of data",
    "section": "Goals for today",
    "text": "Goals for today\nCreate plots!\n– Understand geoms\n– Scatterplots, boxplots, histograms, etc\n– Practice with the fundamentals of ggplot"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#tips-and-tricks",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#tips-and-tricks",
    "title": "Visualizing various types of data",
    "section": "Tips and Tricks",
    "text": "Tips and Tricks\n– Let the types of variables dictate the plot\n– Informative title\n– Axes should be labeled\n– Careful consideration of aesthetic choices (like color)"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#warm-up-questions",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#warm-up-questions",
    "title": "Visualizing various types of data",
    "section": "Warm Up Questions",
    "text": "Warm Up Questions\nWhy is the following code so important?\n\nlibrary(tidyverse)\nWhat word do we associate with |> ?"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#warm-up-questions-1",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#warm-up-questions-1",
    "title": "Visualizing various types of data",
    "section": "Warm Up Questions",
    "text": "Warm Up Questions\nLet’s practice reading code as a sentence\n    mtcars |>\n        ggplot(\n        aes(\n             x = mpg, y = wt)\n               ) +\n        geom_point()\nQ2\n      mtcars |>\n          summarize(med = median(wt))"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#single-pipeline",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#single-pipeline",
    "title": "Visualizing various types of data",
    "section": "Single Pipeline",
    "text": "Single Pipeline\nGoal: Calculate the mean weight of cards over 4000 lbs.\nGood:\n  mtcars |>\n      filter(wt > 4) |>\n      summarize(avg = mean(wt))\nNot as good:\n  large_cars <- mtcars |>\n        filter(wt > 4)\n\n  large_cars |>\n        summarize(avg = mean(wt))"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#geom-reference",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#geom-reference",
    "title": "Visualizing various types of data",
    "section": "geom reference",
    "text": "geom reference\nhttps://ggplot2.tidyverse.org/reference/\nA geom is the geometrical object that a plot uses to represent data. People often describe plots by the type of geom that the plot uses. For example, bar charts use bar geoms, line charts use line geoms, boxplots use boxplot geoms, and so on. Scatterplots break the trend; they use the point geom."
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#we-can-make-plots.",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#we-can-make-plots.",
    "title": "Visualizing various types of data",
    "section": "We can make plots….",
    "text": "We can make plots….\nBut how do we talk about them?"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#general-rules",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#general-rules",
    "title": "Visualizing various types of data",
    "section": "General Rules",
    "text": "General Rules\n– Look for patterns\n– Look at shape\n– Look for outliers or anything unusual\n– Look for spread of the data"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#shape",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#shape",
    "title": "Visualizing various types of data",
    "section": "Shape",
    "text": "Shape\nWe often talk about skew when describing shape of data\n– Positive Skew (Right Skew)\n– Negative Skew (Left Skew)\n– Roughlyl Symmentric"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#outliers",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#outliers",
    "title": "Visualizing various types of data",
    "section": "Outliers",
    "text": "Outliers\nA data point that does not follow the general trend of the data"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#center",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#center",
    "title": "Visualizing various types of data",
    "section": "Center",
    "text": "Center\n– What’s the mean\n– What’s the median"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#spread-more-coming-later",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#spread-more-coming-later",
    "title": "Visualizing various types of data",
    "section": "Spread (More Coming Later!)",
    "text": "Spread (More Coming Later!)\nHow spread out things are…\n– Standard deviation\n– IQR"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#useful-function-of-the-day",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#useful-function-of-the-day",
    "title": "Visualizing various types of data",
    "section": "Useful function of the day",
    "text": "Useful function of the day\nnames()\nThere are many ways we can extract variable names from our data set. I find myself using this a lot in practice."
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#ae-02-s23",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#ae-02-s23",
    "title": "Visualizing various types of data",
    "section": "ae-02-s23",
    "text": "ae-02-s23\nThese data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (“No Rights Reserved”) in accordance with the Palmer Station Data Policy.\nhttps://github.com/sta199-summer-1/ae-02-summer"
  },
  {
    "objectID": "slides/Day2-Visualizing-various-types-of-data.html#recap-of-ae",
    "href": "slides/Day2-Visualizing-various-types-of-data.html#recap-of-ae",
    "title": "Visualizing various types of data",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nPick geoms based on data types.\nManipulate graphs to be more appropriate with arguments\nTake control of your labels\nUse color to your advantage. https://ggplot2.tidyverse.org/reference/ggtheme.html & https://ggplot2.tidyverse.org/reference/scale_viridis.html\n\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#checklist",
    "href": "slides/day4-working-with-multiple-data-frames.html#checklist",
    "title": "Working with multiple data frames",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n– Clone ae-04\n– Make sure you are keeping up with Preparation Videos\n– Lab-1 due Thursday (25th before class)\n– HW-1 due Monday (29th at 11:59 PM)\n– All AEs for this week due Friday (26th at 11:59 PM)"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#announcements",
    "href": "slides/day4-working-with-multiple-data-frames.html#announcements",
    "title": "Working with multiple data frames",
    "section": "Announcements",
    "text": "Announcements\nVideos\n– Requesting videos for missed classes\nHomework + Labs\n– Late work policy\n– Drop 1"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#announcements-1",
    "href": "slides/day4-working-with-multiple-data-frames.html#announcements-1",
    "title": "Working with multiple data frames",
    "section": "Announcements",
    "text": "Announcements\nExam\n– June 1st\n– Take home\n– Open Notes / Internet / etc"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#exam",
    "href": "slides/day4-working-with-multiple-data-frames.html#exam",
    "title": "Working with multiple data frames",
    "section": "Exam",
    "text": "Exam\n– Coding + Short answer questions\n– Extension questions\n– Can NOT be late\n– Pull -> Commit -> Push after every question"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#questions-on-content-for-class",
    "href": "slides/day4-working-with-multiple-data-frames.html#questions-on-content-for-class",
    "title": "Working with multiple data frames",
    "section": "Questions on Content for Class",
    "text": "Questions on Content for Class\n– Posted in Slack #class-questions\n– Reply under the comment\n– Will guide warm up questions for Thursday"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#warm-up",
    "href": "slides/day4-working-with-multiple-data-frames.html#warm-up",
    "title": "Working with multiple data frames",
    "section": "Warm up",
    "text": "Warm up\nPlease define the following…\n– select()\n– slice()\n– arrange()"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#warm-up-2",
    "href": "slides/day4-working-with-multiple-data-frames.html#warm-up-2",
    "title": "Working with multiple data frames",
    "section": "Warm up (2)",
    "text": "Warm up (2)\nWe glossed over this on Monday…. it needs more attention!\nWe can string multiple pipes together. That’s the purpose of tidyverse!\nflights |> \n  select(tailnum, carrier, dep_delay) |>\n  arrange(desc(dep_delay)) |>\n  slice(1)"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#render-discussion",
    "href": "slides/day4-working-with-multiple-data-frames.html#render-discussion",
    "title": "Working with multiple data frames",
    "section": "Render Discussion",
    "text": "Render Discussion\nWhy can’t I Render?\n– Error in your code?\n– Duplicate code chunk label?\n– Are you using a function that brings up an external panel such as View()?"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#github-discussion",
    "href": "slides/day4-working-with-multiple-data-frames.html#github-discussion",
    "title": "Working with multiple data frames",
    "section": "GitHub Discussion",
    "text": "GitHub Discussion\nWhy are my changes not showing up in GitHub?\n– Are you in the right project?\nYou can see the project you are working in in the top right corner of your screen. This MUST be the project that you cloned for the exam / assignment / lab. Do not use the files tab to go search for a file outside of your project repo."
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#tibble-vs-data-frame-in-r",
    "href": "slides/day4-working-with-multiple-data-frames.html#tibble-vs-data-frame-in-r",
    "title": "Working with multiple data frames",
    "section": "Tibble vs Data Frame in R",
    "text": "Tibble vs Data Frame in R\nIn the console, type mtcars in the data set\nNow, type as_tibble(mtcars)"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#tibble-vs-data-frame-in-r-1",
    "href": "slides/day4-working-with-multiple-data-frames.html#tibble-vs-data-frame-in-r-1",
    "title": "Working with multiple data frames",
    "section": "TIbble vs Data Frame in R",
    "text": "TIbble vs Data Frame in R\n– A tibble is often considered a neater format of a data frame\n– Tibble has a more advanced print function\n– Tidyverse functions are built to work with tibbles\nhttps://stackoverflow.com/questions/64856424/what-are-the-differences-between-data-frame-tibble-and-matrix"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#function-of-the-day",
    "href": "slides/day4-working-with-multiple-data-frames.html#function-of-the-day",
    "title": "Working with multiple data frames",
    "section": "Function of the day",
    "text": "Function of the day\nfct_reorder"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#function-of-the-day-1",
    "href": "slides/day4-working-with-multiple-data-frames.html#function-of-the-day-1",
    "title": "Working with multiple data frames",
    "section": "Function of the day",
    "text": "Function of the day\niris |>\n  ggplot(\n  aes(x = fct_reorder(Species, Sepal.Width), y = Sepal.Width)\n) + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#goals",
    "href": "slides/day4-working-with-multiple-data-frames.html#goals",
    "title": "Working with multiple data frames",
    "section": "Goals",
    "text": "Goals\n– Play with dplyr functions\n– Understand join functions\n– Join multiple data frames"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#motivation",
    "href": "slides/day4-working-with-multiple-data-frames.html#motivation",
    "title": "Working with multiple data frames",
    "section": "Motivation",
    "text": "Motivation\nMessy data\n– The sheer volume of information is sometimes referred to as “messy” data, because it’s hard to make sense of it all."
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#messy-data",
    "href": "slides/day4-working-with-multiple-data-frames.html#messy-data",
    "title": "Working with multiple data frames",
    "section": "Messy data",
    "text": "Messy data"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#joining-datasets",
    "href": "slides/day4-working-with-multiple-data-frames.html#joining-datasets",
    "title": "Working with multiple data frames",
    "section": "Joining datasets",
    "text": "Joining datasets\nData merging is the process of combining two or more data sets into a single data set. Most often, this process is necessary when you have raw data stored in multiple files, worksheets, or data tables, that you want to analyze together."
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#joining-datasets-1",
    "href": "slides/day4-working-with-multiple-data-frames.html#joining-datasets-1",
    "title": "Working with multiple data frames",
    "section": "Joining datasets",
    "text": "Joining datasets\n– Left Join\n– Inner Join\n– Right Join\n– Full Join"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#joining-datasets-2",
    "href": "slides/day4-working-with-multiple-data-frames.html#joining-datasets-2",
    "title": "Working with multiple data frames",
    "section": "Joining datasets",
    "text": "Joining datasets"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#ae-04-1",
    "href": "slides/day4-working-with-multiple-data-frames.html#ae-04-1",
    "title": "Working with multiple data frames",
    "section": "AE-04",
    "text": "AE-04\n– ae-04 part 2!\n– Joining Fisheries"
  },
  {
    "objectID": "slides/day4-working-with-multiple-data-frames.html#recap-of-ae",
    "href": "slides/day4-working-with-multiple-data-frames.html#recap-of-ae",
    "title": "Working with multiple data frames",
    "section": "Recap of AE",
    "text": "Recap of AE\n– This is important! Data are messy!\n– Think carefully about the join you use\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day5.html#checklist",
    "href": "slides/day5.html#checklist",
    "title": "Joins + Tidy Data",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n– Clone ae-05\n– Make sure you are keeping up with Preparation Videos\n– HW-1 due Monday (29th at 11:59 PM)\n– Lab-1 due Today (25th at 11:59 PM) <- We will talk about this deadline\n– All AEs for this week due Friday (26th at 11:59 PM)"
  },
  {
    "objectID": "slides/day5.html#lab-2-announcement",
    "href": "slides/day5.html#lab-2-announcement",
    "title": "Joins + Tidy Data",
    "section": "Lab 2 Announcement",
    "text": "Lab 2 Announcement\n– Group Formation\n– 3-4 students\n– GitHub is a tool for collaboration\n– It is a skill to be able to communicate and work together on common projects"
  },
  {
    "objectID": "slides/day5.html#warm-up---joins",
    "href": "slides/day5.html#warm-up---joins",
    "title": "Joins + Tidy Data",
    "section": "Warm up - Joins",
    "text": "Warm up - Joins\n\n– left_join(x,y); right_join(x,y); full_join(x,y)"
  },
  {
    "objectID": "slides/day5.html#function-of-the-day",
    "href": "slides/day5.html#function-of-the-day",
    "title": "Joins + Tidy Data",
    "section": "Function of the day",
    "text": "Function of the day\nif_else\n– If this, do this, else this\n– Commonly used to create new variables"
  },
  {
    "objectID": "slides/day5.html#function-of-the-day-1",
    "href": "slides/day5.html#function-of-the-day-1",
    "title": "Joins + Tidy Data",
    "section": "Function of the day",
    "text": "Function of the day"
  },
  {
    "objectID": "slides/day5.html#function-of-the-day-2",
    "href": "slides/day5.html#function-of-the-day-2",
    "title": "Joins + Tidy Data",
    "section": "Function of the day",
    "text": "Function of the day\n\nNew column added"
  },
  {
    "objectID": "slides/day5.html#function-of-the-day-bonus",
    "href": "slides/day5.html#function-of-the-day-bonus",
    "title": "Joins + Tidy Data",
    "section": "Function of the day (Bonus!)",
    "text": "Function of the day (Bonus!)\niris |>\n  ggplot(\n  aes(x = fct_reorder(Species, Sepal.Width), y = Sepal.Width)\n) + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/day5.html#goals",
    "href": "slides/day5.html#goals",
    "title": "Joins + Tidy Data",
    "section": "Goals",
    "text": "Goals\n– Finish Joins\n– Define Tidy Data\n– Play with pivot functions in R"
  },
  {
    "objectID": "slides/day5.html#data-format-wide-vs-long",
    "href": "slides/day5.html#data-format-wide-vs-long",
    "title": "Joins + Tidy Data",
    "section": "Data Format (Wide vs Long)",
    "text": "Data Format (Wide vs Long)\n– Wide data contains values that do not repeat in the first column. Also called “unstacked”. Tabular format.\n– Long data contains values that do repeat in the first column. Each row is a single observation of a particular group."
  },
  {
    "objectID": "slides/day5.html#data-format-wide-vs-long-1",
    "href": "slides/day5.html#data-format-wide-vs-long-1",
    "title": "Joins + Tidy Data",
    "section": "Data Format (Wide vs Long)",
    "text": "Data Format (Wide vs Long)\n– Which have we typically used to create plots in this class?"
  },
  {
    "objectID": "slides/day5.html#tidy-data",
    "href": "slides/day5.html#tidy-data",
    "title": "Joins + Tidy Data",
    "section": "Tidy Data",
    "text": "Tidy Data\nThere are three interrelated rules that make a dataset tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is row; each row is an observation.\nEach value is a cell; each cell is a single value.\n\nThis typically describes long data"
  },
  {
    "objectID": "slides/day5.html#motivation",
    "href": "slides/day5.html#motivation",
    "title": "Joins + Tidy Data",
    "section": "Motivation",
    "text": "Motivation\n– Sometimes, data are not in this format…"
  },
  {
    "objectID": "slides/day5.html#pivots",
    "href": "slides/day5.html#pivots",
    "title": "Joins + Tidy Data",
    "section": "pivots",
    "text": "pivots\n– pivot_longer\n– pivot_wider"
  },
  {
    "objectID": "slides/day5.html#pivot_wider-1",
    "href": "slides/day5.html#pivot_wider-1",
    "title": "Joins + Tidy Data",
    "section": "pivot_wider",
    "text": "pivot_wider\n– Making tables for quick comparison / display purposes\n– names_to\n– values_to"
  },
  {
    "objectID": "slides/day5.html#pivot-motivation",
    "href": "slides/day5.html#pivot-motivation",
    "title": "Joins + Tidy Data",
    "section": "Pivot Motivation",
    "text": "Pivot Motivation\nLook at points by game"
  },
  {
    "objectID": "slides/day5.html#ae-summary",
    "href": "slides/day5.html#ae-summary",
    "title": "Joins + Tidy Data",
    "section": "ae-summary",
    "text": "ae-summary"
  },
  {
    "objectID": "slides/day5.html#recap-of-ae",
    "href": "slides/day5.html#recap-of-ae",
    "title": "Joins + Tidy Data",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nThere are many different types of joins. Think critically about your goal in order to decide which join you should use.\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\npivot_wider() which makes data sets wider by increasing columns and reducing rows. pivot_wider() has the opposite interface to pivot_longer(): we need to provide the existing columns that define the values (values_from) and the column name (names_from).\n\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day6-debugging.html#checklist",
    "href": "slides/day6-debugging.html#checklist",
    "title": "Debugging + ggplot practice",
    "section": "Checklist",
    "text": "Checklist\n\nClone your ae-06 project in RStudio\nHW-2 is out. Due Thursday by 5:00\nLab-02 - Team Agreement on Gradescope\nAre you in a project group?\nAre you keeping up with prepare material?"
  },
  {
    "objectID": "slides/day6-debugging.html#announcements",
    "href": "slides/day6-debugging.html#announcements",
    "title": "Debugging + ggplot practice",
    "section": "Announcements",
    "text": "Announcements\n– Exam 1 - June 1st\n– Project is starting up!"
  },
  {
    "objectID": "slides/day6-debugging.html#project",
    "href": "slides/day6-debugging.html#project",
    "title": "Debugging + ggplot practice",
    "section": "Project",
    "text": "Project\n– Find a data set\n– Come up with a research question\n– Perform EDA\n– Perform Statistical Procedure\n– Give a presentation"
  },
  {
    "objectID": "slides/day6-debugging.html#project-1",
    "href": "slides/day6-debugging.html#project-1",
    "title": "Debugging + ggplot practice",
    "section": "Project",
    "text": "Project\nCan be found on the website\nIdentify 2 data sets you’re interested in potentially using for the final project.\n– 300 observations\n– 6 variables\nPlenty of places to find data online"
  },
  {
    "objectID": "slides/day6-debugging.html#project-data",
    "href": "slides/day6-debugging.html#project-data",
    "title": "Debugging + ggplot practice",
    "section": "Project Data",
    "text": "Project Data\nData must be real\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables. If you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials."
  },
  {
    "objectID": "slides/day6-debugging.html#project-proposal",
    "href": "slides/day6-debugging.html#project-proposal",
    "title": "Debugging + ggplot practice",
    "section": "Project Proposal",
    "text": "Project Proposal\nIntroduction and data\nResearch question\nLiterature\nGlimpse\nRepos will be coming soon for each group!"
  },
  {
    "objectID": "slides/day6-debugging.html#exam-instructions",
    "href": "slides/day6-debugging.html#exam-instructions",
    "title": "Debugging + ggplot practice",
    "section": "Exam Instructions",
    "text": "Exam Instructions\n– You must submit a PDF document to Gradescope\n– With the exception of major emergencies, late submissions will not be accepted. A last-minute technical issue is not a major emergency.\n– Include appropriate labels, titles, etc. when making any plot."
  },
  {
    "objectID": "slides/day6-debugging.html#exam-instructions-1",
    "href": "slides/day6-debugging.html#exam-instructions-1",
    "title": "Debugging + ggplot practice",
    "section": "Exam Instructions",
    "text": "Exam Instructions\n– This is an individual assignment.\n– You may post clarification questions on Slack in the #exam-1 channel.\n– Don’t cheat\n– You may use R documentation, as well as course materials (notes and textbooks), or existing internet resources to answer exam questions. You may not, under any circumstances, use ChatGPT on the exam. Doing so will result in an 0."
  },
  {
    "objectID": "slides/day6-debugging.html#exam-instructions-2",
    "href": "slides/day6-debugging.html#exam-instructions-2",
    "title": "Debugging + ggplot practice",
    "section": "Exam Instructions",
    "text": "Exam Instructions\n– PDF not submitted on Gradescope (-10 points): If a PDF is not uploaded to Gradescope by the submission deadline, the PDF at your latest commit prior to the deadline will be used as your submission.\n– If there is no PDF in your repo, i.e., you’ve never rendered your .qmd file, your work will not be graded and you will receive a 0 on the exam.\n– Pages not marked on Gradescope (-10 points)"
  },
  {
    "objectID": "slides/day6-debugging.html#exam-questions",
    "href": "slides/day6-debugging.html#exam-questions",
    "title": "Debugging + ggplot practice",
    "section": "Exam Questions",
    "text": "Exam Questions\nWill cover data viz and data wrangling\nQuestions will be similar\nRender + Commit + Push after EVERY question"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up",
    "href": "slides/day6-debugging.html#warm-up",
    "title": "Debugging + ggplot practice",
    "section": "Warm-Up",
    "text": "Warm-Up\nWide vs Long Data\n– What’s the difference?"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-1",
    "href": "slides/day6-debugging.html#warm-up-1",
    "title": "Debugging + ggplot practice",
    "section": "Warm-Up",
    "text": "Warm-Up"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-2",
    "href": "slides/day6-debugging.html#warm-up-2",
    "title": "Debugging + ggplot practice",
    "section": "Warm-Up",
    "text": "Warm-Up\n\nnew.blazer <- trailblazer |>\n    pivot_longer(cols = !Player,\n                 names_to = \"Game\", \n                 values_to = \"Points\")"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-3",
    "href": "slides/day6-debugging.html#warm-up-3",
    "title": "Debugging + ggplot practice",
    "section": "Warm-Up",
    "text": "Warm-Up"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-go-back-to-wide",
    "href": "slides/day6-debugging.html#warm-up-go-back-to-wide",
    "title": "Debugging + ggplot practice",
    "section": "Warm-Up (Go Back to Wide)",
    "text": "Warm-Up (Go Back to Wide)\n\nnew.blazer |>\n  pivot_wider(\n  names_from = Game,\n  values_from = Points\n  )"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-thought-exercise",
    "href": "slides/day6-debugging.html#warm-up-thought-exercise",
    "title": "Debugging + ggplot practice",
    "section": "Warm-Up (Thought Exercise)",
    "text": "Warm-Up (Thought Exercise)\nSuppose a researcher wants to subset the mtcars data set to only include cars with 4 and 6 cylinders."
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-4",
    "href": "slides/day6-debugging.html#warm-up-4",
    "title": "Debugging + ggplot practice",
    "section": "Warm-Up",
    "text": "Warm-Up\nTwo researchers set out to subset these data using the following code. What’s different? What’s correct?\nResearcher 1:\ncylinders <- c(\"6\", \"4\")\n\nmtcars |>\n  mutate(cyl = factor(cyl)) |>\n  filter(cyl == cylinders)\nResearcher 2:\ncylinders <- c(\"6\", \"4\")\n\nmtcars |>\n  mutate(cyl = factor(cyl)) |>\n  filter(cyl %in% cylinders)"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-5",
    "href": "slides/day6-debugging.html#warm-up-5",
    "title": "Debugging + ggplot practice",
    "section": "Warm up",
    "text": "Warm up\ncylinders <- c(\"6\", \"4\")\n\nmtcars |>\n  mutate(cyl = factor(cyl)) |>\n  filter(cyl == cylinders)"
  },
  {
    "objectID": "slides/day6-debugging.html#warm-up-6",
    "href": "slides/day6-debugging.html#warm-up-6",
    "title": "Debugging + ggplot practice",
    "section": "Warm up",
    "text": "Warm up\ncylinders <- c(\"6\", \"4\")\n\nmtcars |>\n  mutate(cyl = factor(cyl)) |>\n  filter(cyl %in% cylinders)\n}"
  },
  {
    "objectID": "slides/day6-debugging.html#function-of-the-day",
    "href": "slides/day6-debugging.html#function-of-the-day",
    "title": "Debugging + ggplot practice",
    "section": "Function of the day",
    "text": "Function of the day\nnrow() and ncol()"
  },
  {
    "objectID": "slides/day6-debugging.html#inline-code",
    "href": "slides/day6-debugging.html#inline-code",
    "title": "Debugging + ggplot practice",
    "section": "Inline Code",
    "text": "Inline Code"
  },
  {
    "objectID": "slides/day6-debugging.html#not-seeing-my-changes-in-git",
    "href": "slides/day6-debugging.html#not-seeing-my-changes-in-git",
    "title": "Debugging + ggplot practice",
    "section": "Not seeing my changes in Git",
    "text": "Not seeing my changes in Git\n– You can see the project you are working in in the top right corner of your screen. This MUST be the project that you cloned for the exam / assignment / lab. Do not use the files tab to go search for a file outside of your project repo."
  },
  {
    "objectID": "slides/day6-debugging.html#tips-for-not-rendering",
    "href": "slides/day6-debugging.html#tips-for-not-rendering",
    "title": "Debugging + ggplot practice",
    "section": "Tips for not rendering",
    "text": "Tips for not rendering\n– External viewer error?\n– Did you put View() in a code chunk? We don’t use View often, but we need to be aware that any function that calls for an external viewer will break the render."
  },
  {
    "objectID": "slides/day6-debugging.html#tips-for-not-rendering-1",
    "href": "slides/day6-debugging.html#tips-for-not-rendering-1",
    "title": "Debugging + ggplot practice",
    "section": "Tips for not rendering",
    "text": "Tips for not rendering\n– Something wrong with your code chunk arguments?"
  },
  {
    "objectID": "slides/day6-debugging.html#expected",
    "href": "slides/day6-debugging.html#expected",
    "title": "Debugging + ggplot practice",
    "section": "Expected :",
    "text": "Expected :"
  },
  {
    "objectID": "slides/day6-debugging.html#duplicate-labels",
    "href": "slides/day6-debugging.html#duplicate-labels",
    "title": "Debugging + ggplot practice",
    "section": "Duplicate labels",
    "text": "Duplicate labels"
  },
  {
    "objectID": "slides/day6-debugging.html#something-in-the-yaml",
    "href": "slides/day6-debugging.html#something-in-the-yaml",
    "title": "Debugging + ggplot practice",
    "section": "Something in the YAML",
    "text": "Something in the YAML\n– The YAML is the metadata that tells Quarto exactly how to process or display the document. This happens in the first few lines of the document between the tick marks."
  },
  {
    "objectID": "slides/day6-debugging.html#tips-for-not-rendering-2",
    "href": "slides/day6-debugging.html#tips-for-not-rendering-2",
    "title": "Debugging + ggplot practice",
    "section": "Tips for not rendering",
    "text": "Tips for not rendering\n— Does your code run? If you have errors in your code, you will also have errors when rendering the document.\n\nError should give you an idea about where the error is occurring.\nIf error can’t be found, go through question by question to find it."
  },
  {
    "objectID": "slides/day6-debugging.html#general-strategies",
    "href": "slides/day6-debugging.html#general-strategies",
    "title": "Debugging + ggplot practice",
    "section": "General Strategies",
    "text": "General Strategies\n– Help files (?function.name)\n– https://ggplot2.tidyverse.org/reference/index.html\n– Slack\n– Keys\n– Google"
  },
  {
    "objectID": "slides/day6-debugging.html#ae-06",
    "href": "slides/day6-debugging.html#ae-06",
    "title": "Debugging + ggplot practice",
    "section": "ae-06",
    "text": "ae-06\n– We will start with the debugging qmd."
  },
  {
    "objectID": "slides/day6-debugging.html#goal",
    "href": "slides/day6-debugging.html#goal",
    "title": "Debugging + ggplot practice",
    "section": "Goal",
    "text": "Goal\n\n\n\n\n\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day7merge.html#checklist",
    "href": "slides/day7merge.html#checklist",
    "title": "GitHub + ggplot practice",
    "section": "Checklist",
    "text": "Checklist\n\nClone your merge-demo-summer project in RStudio. Do not make any changes to it after you clone.\nHW-2 is out. Due Thursday by 5:00\nAre you keeping up with prepare material?"
  },
  {
    "objectID": "slides/day7merge.html#announcements",
    "href": "slides/day7merge.html#announcements",
    "title": "GitHub + ggplot practice",
    "section": "Announcements",
    "text": "Announcements\n– Exam 1 - June 1st\n– Project is starting up!\n– Grading Questions"
  },
  {
    "objectID": "slides/day7merge.html#exam",
    "href": "slides/day7merge.html#exam",
    "title": "GitHub + ggplot practice",
    "section": "Exam",
    "text": "Exam\n– Will be released today between 5-6\n– Individual assignment only\n– RENDER AND PUSH AFTER EVERY QUESTION\n– Due Monday at Noon\n– Slack for clarification questions\n– All questions will be in the README of the exam-summer repo\n– All questions will be answered in the exam.qmd\n– Start early. It make take you 5 hours…. or 15…. and that’s fine!"
  },
  {
    "objectID": "slides/day7merge.html#project",
    "href": "slides/day7merge.html#project",
    "title": "GitHub + ggplot practice",
    "section": "Project",
    "text": "Project\nYou now have your project repos!\nLet’s take a tour…"
  },
  {
    "objectID": "slides/day7merge.html#lab-expectations",
    "href": "slides/day7merge.html#lab-expectations",
    "title": "GitHub + ggplot practice",
    "section": "Lab Expectations",
    "text": "Lab Expectations\n– During lab, you will work on your project with your group\n– After lab, you are to “table” the project until after the exam\n– Project proposal due June 12th"
  },
  {
    "objectID": "slides/day7merge.html#warm-up-1",
    "href": "slides/day7merge.html#warm-up-1",
    "title": "GitHub + ggplot practice",
    "section": "Warm Up 1",
    "text": "Warm Up 1\n– When you see an NA in a data set, what are some possibilities it could represent?\n– Are we justified to always change NAs to 0?"
  },
  {
    "objectID": "slides/day7merge.html#warm-up-2",
    "href": "slides/day7merge.html#warm-up-2",
    "title": "GitHub + ggplot practice",
    "section": "Warm Up 2",
    "text": "Warm Up 2\n\nseparate(degree, sep = \"\\\\(\" , into = c(\"major\", \"degree_type\"))"
  },
  {
    "objectID": "slides/day7merge.html#warm-up-3",
    "href": "slides/day7merge.html#warm-up-3",
    "title": "GitHub + ggplot practice",
    "section": "Warm Up 3",
    "text": "Warm Up 3\n– Why do we use GitHub?"
  },
  {
    "objectID": "slides/day7merge.html#github",
    "href": "slides/day7merge.html#github",
    "title": "GitHub + ggplot practice",
    "section": "GitHub",
    "text": "GitHub\nAt its core, Git keeps track of changes to files and allows multiple users to coordinate updates to those files."
  },
  {
    "objectID": "slides/day7merge.html#github-1",
    "href": "slides/day7merge.html#github-1",
    "title": "GitHub + ggplot practice",
    "section": "GitHub",
    "text": "GitHub\nBut…. not on the same lines of code at the same time….."
  },
  {
    "objectID": "slides/day7merge.html#github-2",
    "href": "slides/day7merge.html#github-2",
    "title": "GitHub + ggplot practice",
    "section": "GitHub",
    "text": "GitHub"
  },
  {
    "objectID": "slides/day7merge.html#github-3",
    "href": "slides/day7merge.html#github-3",
    "title": "GitHub + ggplot practice",
    "section": "GitHub",
    "text": "GitHub\nNot all merge conflicts are bad!"
  },
  {
    "objectID": "slides/day7merge.html#github-rules-for-collaboration",
    "href": "slides/day7merge.html#github-rules-for-collaboration",
    "title": "GitHub + ggplot practice",
    "section": "GitHub Rules for Collaboration",
    "text": "GitHub Rules for Collaboration\n– ALWAYS PULL before starting your work\n– Commit and push every and all documents. Merge conflicts occur when someone saves changes, but doesn’t push them to GitHub.\n– If merge conflicts happen, we can fix (most) of them! We will talk about this during our first activity today."
  },
  {
    "objectID": "slides/day7merge.html#merge-conflict",
    "href": "slides/day7merge.html#merge-conflict",
    "title": "GitHub + ggplot practice",
    "section": "merge conflict",
    "text": "merge conflict\n– The first activity we will do is the merge-demo-summer activity.\n– Clone this and assign a Role number 1 through 4. If you have more than 4 members, alternate.\n– Do not change this document until the activity begins.\n– Click on the icon under the ae_sa column on the website for today to find activity instructions."
  },
  {
    "objectID": "slides/day7merge.html#fisheries-plot",
    "href": "slides/day7merge.html#fisheries-plot",
    "title": "GitHub + ggplot practice",
    "section": "Fisheries Plot",
    "text": "Fisheries Plot"
  },
  {
    "objectID": "slides/day7merge.html#what-is-it",
    "href": "slides/day7merge.html#what-is-it",
    "title": "GitHub + ggplot practice",
    "section": "What is it?",
    "text": "What is it?\n– The claims that we can make from research around population parameters\n\nSo what are population parameters?"
  },
  {
    "objectID": "slides/day7merge.html#populatin-parameters",
    "href": "slides/day7merge.html#populatin-parameters",
    "title": "GitHub + ggplot practice",
    "section": "Populatin Parameters",
    "text": "Populatin Parameters\n– Population parameters represent the truth or true summary statistics of an entire population.\n\nWe are almost always interested in these as the researcher\nAnd we can almost never know exactly what these are…."
  },
  {
    "objectID": "slides/day7merge.html#example",
    "href": "slides/day7merge.html#example",
    "title": "GitHub + ggplot practice",
    "section": "Example",
    "text": "Example\nDuke Students’ Height"
  },
  {
    "objectID": "slides/day7merge.html#statistical-inference",
    "href": "slides/day7merge.html#statistical-inference",
    "title": "GitHub + ggplot practice",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n– Test to see if parameters are different from a value, or from each other\n– Estimate population parameters"
  },
  {
    "objectID": "slides/day7merge.html#quantifying-variability",
    "href": "slides/day7merge.html#quantifying-variability",
    "title": "GitHub + ggplot practice",
    "section": "Quantifying variability",
    "text": "Quantifying variability\n– Variability is understood as the lack of consistency. As we take samples from a population, will we always get the same value back?"
  },
  {
    "objectID": "slides/day7merge.html#distribution",
    "href": "slides/day7merge.html#distribution",
    "title": "GitHub + ggplot practice",
    "section": "Distribution",
    "text": "Distribution\nBut some values are more common and some are uncommon\nWe use distributions to understand that. This allows us to conduct hypothesis tests and make confidence intervals.\n\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day8slr.html#checklist",
    "href": "slides/day8slr.html#checklist",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Checklist",
    "text": "Checklist\n\nClone your ae-08.\nExam-1 is over. Nice work!\nAre you keeping up with prepare material?"
  },
  {
    "objectID": "slides/day8slr.html#announcements",
    "href": "slides/day8slr.html#announcements",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Announcements",
    "text": "Announcements\n– Project is here! Let’s talk about it."
  },
  {
    "objectID": "slides/day8slr.html#project",
    "href": "slides/day8slr.html#project",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Project",
    "text": "Project\nRight now, you are working on the project proposal (June 12th)\nProject draft report due (June 22nd)\nProject presentation (June 29th)"
  },
  {
    "objectID": "slides/day8slr.html#project-proposal",
    "href": "slides/day8slr.html#project-proposal",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Project proposal",
    "text": "Project proposal\n– 2 data sets\n– Research question for each data set\n– Introduction for each data set\n– “Literature review” for each data set\n– glimpse for each data set"
  },
  {
    "objectID": "slides/day8slr.html#research-questions",
    "href": "slides/day8slr.html#research-questions",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Research Questions",
    "text": "Research Questions\n– Should be clear and focused\n– Should be something that can be answered"
  },
  {
    "objectID": "slides/day8slr.html#research-questions-1",
    "href": "slides/day8slr.html#research-questions-1",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Research Questions",
    "text": "Research Questions\n– There is no recommendation to the number of variables you need to include when writing your research question. It can be between 2, it can have more than 2.\n– Your research question can (and probably will) change as you get feedback / we move through the Summer session. That’s okay for this class project!\n– You will answer this question using statistical procedures we will learn starting now! This includes modeling, hypothesis testing, and confidence intervals."
  },
  {
    "objectID": "slides/day8slr.html#examples",
    "href": "slides/day8slr.html#examples",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Examples",
    "text": "Examples\n– What is the relationship between baldness and age?\n– What is the relationship between baldness and age? Does this change based on sex?\n– Does the mean age of retirement differ based on region of the US?\n– What is the estiamted difference in GPA between those who live on vs off the dorms at Duke University?"
  },
  {
    "objectID": "slides/day8slr.html#teamwork",
    "href": "slides/day8slr.html#teamwork",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Teamwork",
    "text": "Teamwork\n– Everyone must contribute\n– You are not guarenteed the same grade on the project as your group members\n– Commit messages + group surveys"
  },
  {
    "objectID": "slides/day8slr.html#draft-report",
    "href": "slides/day8slr.html#draft-report",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Draft Report",
    "text": "Draft Report\n– Introduction and Data (Updated)\n– Literature Review (Updated)\n– Methodology: visualizations and summary statistics relevant to your research question. You should also justify the choice of statistical method(s) used to answer your research question.\n– Showcase how you arrived at answers to your research question using the techniques we have learned in class"
  },
  {
    "objectID": "slides/day8slr.html#draft-report-1",
    "href": "slides/day8slr.html#draft-report-1",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Draft Report",
    "text": "Draft Report\nThe goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R. More is not better."
  },
  {
    "objectID": "slides/day8slr.html#presentation",
    "href": "slides/day8slr.html#presentation",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Presentation",
    "text": "Presentation\n– Short 5-10 minute presentation on all of the hard work you have accomplished\n– This takes place of your final exam"
  },
  {
    "objectID": "slides/day8slr.html#warm-up",
    "href": "slides/day8slr.html#warm-up",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Warm Up",
    "text": "Warm Up\nWhat is the true mean height for all Duke students who take Summer classes?"
  },
  {
    "objectID": "slides/day8slr.html#you-dont-know.",
    "href": "slides/day8slr.html#you-dont-know.",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "You don’t know….",
    "text": "You don’t know….\nBut we can collect data and try to better answer this question!"
  },
  {
    "objectID": "slides/day8slr.html#warm-up-2",
    "href": "slides/day8slr.html#warm-up-2",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Warm Up-2",
    "text": "Warm Up-2\nIs the weight of a car a good predictor for miles per gallon?\nHow many miles per gallon would we estimate a car to have if the weight was equal to 5000 pounds?"
  },
  {
    "objectID": "slides/day8slr.html#you-dont-know.-1",
    "href": "slides/day8slr.html#you-dont-know.-1",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "You don’t know….",
    "text": "You don’t know….\nBut we can collect data, fit a model, and use this model to better understand relationships and make predictions!"
  },
  {
    "objectID": "slides/day8slr.html#warm-up-3",
    "href": "slides/day8slr.html#warm-up-3",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Warm up 3",
    "text": "Warm up 3\nHow many miles per gallon would we estimate a car to have if the weight was equal to 5000 pounds?"
  },
  {
    "objectID": "slides/day8slr.html#goals",
    "href": "slides/day8slr.html#goals",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Goals",
    "text": "Goals\n– Introduce the idea of modeling\n— Modeling with single predictors\n— How to write equations\n— Interpret Slopes\n— Interpret Intercepts"
  },
  {
    "objectID": "slides/day8slr.html#what-is-a-statistical-model",
    "href": "slides/day8slr.html#what-is-a-statistical-model",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "What is a statistical model?",
    "text": "What is a statistical model?\n– Statistical modeling is the process of applying statistical analysis to a data set.\n– A statistical model is a mathematical representation of observed data."
  },
  {
    "objectID": "slides/day8slr.html#why",
    "href": "slides/day8slr.html#why",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Why",
    "text": "Why\n– Interpretation\n– Prediction"
  },
  {
    "objectID": "slides/day8slr.html#what-is-linear-regression",
    "href": "slides/day8slr.html#what-is-linear-regression",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "What is linear regression?",
    "text": "What is linear regression?\n– Model data using a straight line\n– Quantitative response\n– Quantitative or categorical explanatory"
  },
  {
    "objectID": "slides/day8slr.html#vocab---response-variable",
    "href": "slides/day8slr.html#vocab---response-variable",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Vocab - Response variable",
    "text": "Vocab - Response variable"
  },
  {
    "objectID": "slides/day8slr.html#vocab---explanatory-variable",
    "href": "slides/day8slr.html#vocab---explanatory-variable",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Vocab - Explanatory variable",
    "text": "Vocab - Explanatory variable"
  },
  {
    "objectID": "slides/day8slr.html#how-are-models-fit---2-minutes",
    "href": "slides/day8slr.html#how-are-models-fit---2-minutes",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "How are Models Fit? - 2 minutes",
    "text": "How are Models Fit? - 2 minutes"
  },
  {
    "objectID": "slides/day8slr.html#how-are-models-fit",
    "href": "slides/day8slr.html#how-are-models-fit",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "How are Models Fit?",
    "text": "How are Models Fit?"
  },
  {
    "objectID": "slides/day8slr.html#how-are-models-fit-1",
    "href": "slides/day8slr.html#how-are-models-fit-1",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "How are Models Fit?",
    "text": "How are Models Fit?"
  },
  {
    "objectID": "slides/day8slr.html#its-all-linear-algebra-beyond-the-scope",
    "href": "slides/day8slr.html#its-all-linear-algebra-beyond-the-scope",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "It’s all linear algebra (beyond the scope)",
    "text": "It’s all linear algebra (beyond the scope)\nFirst derivative of \\((y-XB)`(y-XB)\\)\n… and set it equal to 0 to find the set of betas that minimizes RSS"
  },
  {
    "objectID": "slides/day8slr.html#what-about-when-x-is-categorical",
    "href": "slides/day8slr.html#what-about-when-x-is-categorical",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "What about when X is categorical?",
    "text": "What about when X is categorical?"
  },
  {
    "objectID": "slides/day8slr.html#what-about-when-x-is-categorical-1",
    "href": "slides/day8slr.html#what-about-when-x-is-categorical-1",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "What about when X is categorical?",
    "text": "What about when X is categorical?"
  },
  {
    "objectID": "slides/day8slr.html#in-r-slr",
    "href": "slides/day8slr.html#in-r-slr",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "In R: SLR",
    "text": "In R: SLR\nlinear_reg() |>\n\n     set_engine(\"lm\") |>\n\n     fit(y ~ x , data = data-set ) |>\n\n     tidy()"
  },
  {
    "objectID": "slides/day8slr.html#model-notation---population",
    "href": "slides/day8slr.html#model-notation---population",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Model Notation - Population",
    "text": "Model Notation - Population\n\\[ Y_i = \\beta\\_o + \\beta\\_1x_i +\\epsilon\\_i\\]\n\\[ Y\\; - True\\; mean\\;response \\]\n\\[\\beta\\_o\\; -True\\; intercept\\]\n\\[\\beta\\_1\\; - True\\; slope\\; coefficient\\]\n\\[\\epsilon\\_i\\; -  Error\\; term\\; for\\; each\\; observation\\; i\\]"
  },
  {
    "objectID": "slides/day8slr.html#model-notation---estimated",
    "href": "slides/day8slr.html#model-notation---estimated",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Model Notation - Estimated",
    "text": "Model Notation - Estimated\n\\[\\hat{Y} = b + b_1x\\]\n\\[\\hat{Y} = \\hat{\\beta_o} + \\hat{\\beta_1}x\\]\n\\[\\hat{Y} - estimated\\; (predicted)\\; mean \\;response\\] \\[\\hat{\\beta_o} - estimated\\; intercept\\] \\[\\hat{\\beta_1} - estimated\\; slope\\] We assume that our error term is normally distributed and has a mean of 0. Thus, it does not show up in our model."
  },
  {
    "objectID": "slides/day8slr.html#model-notes",
    "href": "slides/day8slr.html#model-notes",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Model Notes",
    "text": "Model Notes\nThings to note:\nX is our explanatory variable and is not random. We know the value of X.\nY is our response variable. For a fixed X, Y will be a random variable (have a random outcome).\nThis random outcome is observed based on a random draw from a distribution we assume.\nWhen using this model for prediction, we expect Y to take on the most likely value for a given X… which is the center of the distribution.\nLet’s draw it out…"
  },
  {
    "objectID": "slides/day8slr.html#takeaway",
    "href": "slides/day8slr.html#takeaway",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Takeaway",
    "text": "Takeaway\nSo, for an observed X….. we are modeling the mean of the distribution of Y\nOr, Y is a mean response\n“we estimate a mean change in Y”\n“we estimate, on average…..”\nThis is extremely important when we think about interpretation"
  },
  {
    "objectID": "slides/day8slr.html#is-the-predictor-any-good",
    "href": "slides/day8slr.html#is-the-predictor-any-good",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Is the predictor any good?",
    "text": "Is the predictor any good?\n– Correlation and r-squared"
  },
  {
    "objectID": "slides/day8slr.html#correlation-r",
    "href": "slides/day8slr.html#correlation-r",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Correlation (r)",
    "text": "Correlation (r)\n– Between [-1,1]\n– Measures the strength and direction of a linear relationship\n– We can calculate correlation using the cor function in R"
  },
  {
    "objectID": "slides/day8slr.html#r-squared",
    "href": "slides/day8slr.html#r-squared",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "r-squared",
    "text": "r-squared\n– For SLR, r-squared is the correlation coefficient squared\n– Quantifies the amount of variability in our response y that is explained by x\n– In general, the higher the value is, the better or important the predictor is!\n– Note: We do need to be careful with over fitting, and want to be wary of r-squared values close to one. More on this later…."
  },
  {
    "objectID": "slides/day8slr.html#r-squared-1",
    "href": "slides/day8slr.html#r-squared-1",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "r-squared",
    "text": "r-squared\nWe can calculate this in R using glance(model.name)$r.squared"
  },
  {
    "objectID": "slides/day8slr.html#summary",
    "href": "slides/day8slr.html#summary",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Summary",
    "text": "Summary\n– Y is a random variable.\n– We assume that observations from this random variable are normally distributed.\n– Because of this distributional assumption, we are modeling the mean of Y and not just Y."
  },
  {
    "objectID": "slides/day8slr.html#wrap-up-check-yourself",
    "href": "slides/day8slr.html#wrap-up-check-yourself",
    "title": "Statistical Inference + Simple Linear Regression",
    "section": "Wrap up: Check yourself",
    "text": "Wrap up: Check yourself\n– What is a model?\n– What are the 2 main reasons we fit models?\n– Slope coefficients? Intercepts?\n– How does linear regression change when x is quantitative vs categorical?\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/day9mlr.final.html#checklist",
    "href": "slides/day9mlr.final.html#checklist",
    "title": "SLR + MLR",
    "section": "Checklist",
    "text": "Checklist\n– Clone `ae-09\n– Homework 3 Release Today\n– Lab 4 due Thursday (11:59)\n— 1 submission. Attach everyone to it"
  },
  {
    "objectID": "slides/day9mlr.final.html#lab-4",
    "href": "slides/day9mlr.final.html#lab-4",
    "title": "SLR + MLR",
    "section": "Lab 4",
    "text": "Lab 4\n– Team Submission\n– Attach ALL team members to submission on Gradescope\n– Communicate!\n– “It was my responsibility to turn the lab in and I forgot….”"
  },
  {
    "objectID": "slides/day9mlr.final.html#warm-up-correlation",
    "href": "slides/day9mlr.final.html#warm-up-correlation",
    "title": "SLR + MLR",
    "section": "Warm Up: Correlation",
    "text": "Warm Up: Correlation\n– Proper notation?\n– Definition?\n– Bounds?\nChallenge your friends to a game of guess the correlation"
  },
  {
    "objectID": "slides/day9mlr.final.html#warm-up",
    "href": "slides/day9mlr.final.html#warm-up",
    "title": "SLR + MLR",
    "section": "Warm Up",
    "text": "Warm Up\nLast time, we fit a model that investigated the effect of Island on a penguin’s body mass. The results are below:\n\nLet’s write out the estimated model together as a class…"
  },
  {
    "objectID": "slides/day9mlr.final.html#correlation",
    "href": "slides/day9mlr.final.html#correlation",
    "title": "SLR + MLR",
    "section": "Correlation",
    "text": "Correlation\nCan find this with the cor or correlate function in R\n\nhttps://www.tidyverse.org/blog/2020/12/corrr-0-4-3/"
  },
  {
    "objectID": "slides/day9mlr.final.html#warm-up-3",
    "href": "slides/day9mlr.final.html#warm-up-3",
    "title": "SLR + MLR",
    "section": "Warm Up 3",
    "text": "Warm Up 3\nDefine each of these terms below:\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(b_0\\)\n\\(b_1\\)\n\\(\\epsilon\\)\n\\(\\hat{y}\\)"
  },
  {
    "objectID": "slides/day9mlr.final.html#multiple-linear-regression",
    "href": "slides/day9mlr.final.html#multiple-linear-regression",
    "title": "SLR + MLR",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nestimates the relationship between a quantitative response variable and two or more explanatory variables\nmotivated by scenarios where many variables may be simultaneously connected to an output"
  },
  {
    "objectID": "slides/day9mlr.final.html#multiple-linear-regression-1",
    "href": "slides/day9mlr.final.html#multiple-linear-regression-1",
    "title": "SLR + MLR",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression"
  },
  {
    "objectID": "slides/day9mlr.final.html#slight-change-in-interpretation",
    "href": "slides/day9mlr.final.html#slight-change-in-interpretation",
    "title": "SLR + MLR",
    "section": "Slight Change in interpretation",
    "text": "Slight Change in interpretation\n– Holding all else constant\nBecause we estimate our coefficients all at the same time. Thus, when we add variables to the model, our estimates will change!"
  },
  {
    "objectID": "slides/day9mlr.final.html#beyond-the-scope",
    "href": "slides/day9mlr.final.html#beyond-the-scope",
    "title": "SLR + MLR",
    "section": "Beyond the scope",
    "text": "Beyond the scope\n– Linear algebra is driving what we do in R\n– Least squares estimator: estimating parameters by minimizing the squared discrepancies between observed data\n– \\[\\hat{\\beta} = (X^t X)^{-1} X^tY\\]"
  },
  {
    "objectID": "slides/day9mlr.final.html#additive-model-vs-interaction-model",
    "href": "slides/day9mlr.final.html#additive-model-vs-interaction-model",
    "title": "SLR + MLR",
    "section": "Additive Model vs Interaction Model",
    "text": "Additive Model vs Interaction Model\nIn words….\nThe relationship between x and y do not change based on the values of z (additive)\nThe relationship between x and y DO change based on the values of z (interaction)"
  },
  {
    "objectID": "slides/day9mlr.final.html#additive-model-for-today",
    "href": "slides/day9mlr.final.html#additive-model-for-today",
    "title": "SLR + MLR",
    "section": "Additive Model for Today",
    "text": "Additive Model for Today"
  },
  {
    "objectID": "slides/day9mlr.final.html#interaction-model-for-today",
    "href": "slides/day9mlr.final.html#interaction-model-for-today",
    "title": "SLR + MLR",
    "section": "Interaction Model for Today",
    "text": "Interaction Model for Today"
  },
  {
    "objectID": "slides/day9mlr.final.html#principle-of-parsimony-occams-razor",
    "href": "slides/day9mlr.final.html#principle-of-parsimony-occams-razor",
    "title": "SLR + MLR",
    "section": "Principle of parsimony (Occam’s Razor)",
    "text": "Principle of parsimony (Occam’s Razor)\nfor a statistical model states that: a simpler model with fewer parameters is favored over more complex models with more parameters, provided the models fit the data similarly well\nKEEP IT SIMPLE (when you can)"
  },
  {
    "objectID": "slides/day9mlr.final.html#so-how-do-we-choose",
    "href": "slides/day9mlr.final.html#so-how-do-we-choose",
    "title": "SLR + MLR",
    "section": "So how do we choose?",
    "text": "So how do we choose?\nMany different ways\n– Initial visual evidence\n– R-squared & Adjusted R-squared"
  },
  {
    "objectID": "slides/day9mlr.final.html#r-squared",
    "href": "slides/day9mlr.final.html#r-squared",
    "title": "SLR + MLR",
    "section": "R-squared",
    "text": "R-squared\n– statistical measure in a regression model that determines the proportion of variance in the response variable that can be explained by the explanatory variable(s)."
  },
  {
    "objectID": "slides/day9mlr.final.html#r-squared-1",
    "href": "slides/day9mlr.final.html#r-squared-1",
    "title": "SLR + MLR",
    "section": "R-squared",
    "text": "R-squared"
  },
  {
    "objectID": "slides/day9mlr.final.html#r-squared-2",
    "href": "slides/day9mlr.final.html#r-squared-2",
    "title": "SLR + MLR",
    "section": "R-squared",
    "text": "R-squared"
  },
  {
    "objectID": "slides/day9mlr.final.html#r-squared-takeaway",
    "href": "slides/day9mlr.final.html#r-squared-takeaway",
    "title": "SLR + MLR",
    "section": "R-squared: Takeaway",
    "text": "R-squared: Takeaway\n– statistical measure in a regression model that determines the proportion of variance in the response variable that can be explained by the explanatory variable(s).\n– The more variables you include, the larger the R-squared value will be (always)"
  },
  {
    "objectID": "slides/day9mlr.final.html#adjusted-r-squared",
    "href": "slides/day9mlr.final.html#adjusted-r-squared",
    "title": "SLR + MLR",
    "section": "Adjusted R-squared",
    "text": "Adjusted R-squared\nTakeaway: Adds a penalty for “unimportant” predictors (x’s)"
  },
  {
    "objectID": "slides/day9mlr.html#checklist",
    "href": "slides/day9mlr.html#checklist",
    "title": "SLR + MLR",
    "section": "Checklist",
    "text": "Checklist\n– Clone `ae-09\n– Homework 3 Release Today\n– Lab 4 due Thursday (11:59)\n— 1 submission. Attach everyone to it"
  },
  {
    "objectID": "slides/day9mlr.html#lab-4",
    "href": "slides/day9mlr.html#lab-4",
    "title": "SLR + MLR",
    "section": "Lab 4",
    "text": "Lab 4\n– Team Submission\n– Attach ALL team members to submission on Gradescope\n– Communicate!\n– “It was my responsibility to turn the lab in and I forgot….”"
  },
  {
    "objectID": "slides/day9mlr.html#warm-up-correlation",
    "href": "slides/day9mlr.html#warm-up-correlation",
    "title": "SLR + MLR",
    "section": "Warm Up: Correlation",
    "text": "Warm Up: Correlation\n– Proper notation?\n– Definition?\n– Bounds?\nChallenge your friends to a game of guess the correlation"
  },
  {
    "objectID": "slides/day9mlr.html#warm-up",
    "href": "slides/day9mlr.html#warm-up",
    "title": "SLR + MLR",
    "section": "Warm Up",
    "text": "Warm Up\nLast time, we fit a model that investigated the effect of Island on a penguin’s body mass. The results are below:\n\nLet’s write out the estimated model together as a class…"
  },
  {
    "objectID": "slides/day9mlr.html#correlation",
    "href": "slides/day9mlr.html#correlation",
    "title": "SLR + MLR",
    "section": "Correlation",
    "text": "Correlation\nCan find this with the cor or correlate function in R\n\nhttps://www.tidyverse.org/blog/2020/12/corrr-0-4-3/"
  },
  {
    "objectID": "slides/day9mlr.html#warm-up-3",
    "href": "slides/day9mlr.html#warm-up-3",
    "title": "SLR + MLR",
    "section": "Warm Up 3",
    "text": "Warm Up 3\nDefine each of these terms below:\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(b_0\\)\n\\(b_1\\)\n\\(\\epsilon\\)\n\\(\\hat{y}\\)"
  },
  {
    "objectID": "slides/day9mlr.html#multiple-linear-regression",
    "href": "slides/day9mlr.html#multiple-linear-regression",
    "title": "SLR + MLR",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nestimates the relationship between a quantitative response variable and two or more explanatory variables\nmotivated by scenarios where many variables may be simultaneously connected to an output"
  },
  {
    "objectID": "slides/day9mlr.html#multiple-linear-regression-1",
    "href": "slides/day9mlr.html#multiple-linear-regression-1",
    "title": "SLR + MLR",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression"
  },
  {
    "objectID": "slides/day9mlr.html#slight-change-in-interpretation",
    "href": "slides/day9mlr.html#slight-change-in-interpretation",
    "title": "SLR + MLR",
    "section": "Slight Change in interpretation",
    "text": "Slight Change in interpretation\n– Holding all else constant\nBecause we estimate our coefficients all at the same time. Thus, when we add variables to the model, our estimates will change!"
  },
  {
    "objectID": "slides/day9mlr.html#beyond-the-scope",
    "href": "slides/day9mlr.html#beyond-the-scope",
    "title": "SLR + MLR",
    "section": "Beyond the scope",
    "text": "Beyond the scope\n– Linear algebra is driving what we do in R\n– Least squares estimator: estimating parameters by minimizing the squared discrepancies between observed data\n– \\[\\hat{\\beta} = (X^t X)^{-1} X^tY\\]"
  },
  {
    "objectID": "slides/day9mlr.html#additive-model-vs-interaction-model",
    "href": "slides/day9mlr.html#additive-model-vs-interaction-model",
    "title": "SLR + MLR",
    "section": "Additive Model vs Interaction Model",
    "text": "Additive Model vs Interaction Model\nIn words….\nThe relationship between x and y do not change based on the values of z (additive)\nThe relationship between x and y DO change based on the values of z (interaction)"
  },
  {
    "objectID": "slides/day9mlr.html#additive-model-for-today",
    "href": "slides/day9mlr.html#additive-model-for-today",
    "title": "SLR + MLR",
    "section": "Additive Model for Today",
    "text": "Additive Model for Today"
  },
  {
    "objectID": "slides/day9mlr.html#interaction-model-for-today",
    "href": "slides/day9mlr.html#interaction-model-for-today",
    "title": "SLR + MLR",
    "section": "Interaction Model for Today",
    "text": "Interaction Model for Today"
  },
  {
    "objectID": "slides/day9mlr.html#principle-of-parsimony-occams-razor",
    "href": "slides/day9mlr.html#principle-of-parsimony-occams-razor",
    "title": "SLR + MLR",
    "section": "Principle of parsimony (Occam’s Razor)",
    "text": "Principle of parsimony (Occam’s Razor)\nfor a statistical model states that: a simpler model with fewer parameters is favored over more complex models with more parameters, provided the models fit the data similarly well\nKEEP IT SIMPLE (when you can)"
  },
  {
    "objectID": "slides/day9mlr.html#so-how-do-we-choose",
    "href": "slides/day9mlr.html#so-how-do-we-choose",
    "title": "SLR + MLR",
    "section": "So how do we choose?",
    "text": "So how do we choose?\nMany different ways\n– Initial visual evidence\n– R-squared & Adjusted R-squared"
  },
  {
    "objectID": "slides/day9mlr.html#r-squared",
    "href": "slides/day9mlr.html#r-squared",
    "title": "SLR + MLR",
    "section": "R-squared",
    "text": "R-squared\n– statistical measure in a regression model that determines the proportion of variance in the response variable that can be explained by the explanatory variable(s)."
  },
  {
    "objectID": "slides/day9mlr.html#r-squared-1",
    "href": "slides/day9mlr.html#r-squared-1",
    "title": "SLR + MLR",
    "section": "R-squared",
    "text": "R-squared"
  },
  {
    "objectID": "slides/day9mlr.html#r-squared-2",
    "href": "slides/day9mlr.html#r-squared-2",
    "title": "SLR + MLR",
    "section": "R-squared",
    "text": "R-squared"
  },
  {
    "objectID": "slides/day9mlr.html#r-squared-takeaway",
    "href": "slides/day9mlr.html#r-squared-takeaway",
    "title": "SLR + MLR",
    "section": "R-squared: Takeaway",
    "text": "R-squared: Takeaway\n– statistical measure in a regression model that determines the proportion of variance in the response variable that can be explained by the explanatory variable(s).\n– The more variables you include, the larger the R-squared value will be (always)"
  },
  {
    "objectID": "slides/day9mlr.html#adjusted-r-squared",
    "href": "slides/day9mlr.html#adjusted-r-squared",
    "title": "SLR + MLR",
    "section": "Adjusted R-squared",
    "text": "Adjusted R-squared\nTakeaway: Adds a penalty for “unimportant” predictors (x’s)"
  },
  {
    "objectID": "slides/lab-0-slides.html#introductions",
    "href": "slides/lab-0-slides.html#introductions",
    "title": "Welcome to Lab",
    "section": "Introductions",
    "text": "Introductions\n\n\n\n– Meet the Lab Leader!\n– The file that you work in will be on GitHub\n– You can find Lab on sta199-summer-1.github.io/\n– You can find your lab starter: https://github.com/sta199-summer-1/lab-0-starter"
  },
  {
    "objectID": "slides/lab-0-slides.html#what-to-expect-in-labs",
    "href": "slides/lab-0-slides.html#what-to-expect-in-labs",
    "title": "Welcome to Lab",
    "section": "What to expect in labs",
    "text": "What to expect in labs\n– Introduce lab assignment (5-10 minutes, longer today)\n– Work on the lab assignment. You are encouraged to work with others but your submission must be your own for the first several labs.\n– Submissions will be done on Gradescope (demo at end of class)\n– Lab may end with important announcements\n– If you don’t finish labs in-class…\n— Thursday labs due Noon Monday before lecture\n— Monday labs due Noon Thursday before lecture"
  },
  {
    "objectID": "slides/lab-0-slides.html#tips",
    "href": "slides/lab-0-slides.html#tips",
    "title": "Welcome to Lab",
    "section": "Tips",
    "text": "Tips\n– Read all instructions on the lab.\n– Be involved! This will better prepare you for the exams + project\n– Make use of office hours.\n– Make use of Slack."
  },
  {
    "objectID": "slides/lab-0-slides.html#demo-setting-up",
    "href": "slides/lab-0-slides.html#demo-setting-up",
    "title": "Welcome to Lab",
    "section": "Demo: setting up",
    "text": "Demo: setting up\nNow that your lab repo is created, let’s setup git to work within RStudio.\nTo begin, open\n– the lab instructions here and\n– the RStudio containers here\nFollow the instructions in the lab as I demo."
  },
  {
    "objectID": "slides/lab-0-slides.html#demo-how-to-turn-something-in-via-gradescope",
    "href": "slides/lab-0-slides.html#demo-how-to-turn-something-in-via-gradescope",
    "title": "Welcome to Lab",
    "section": "Demo: How to turn something in via Gradescope",
    "text": "Demo: How to turn something in via Gradescope\nPlease do not lose free points!\n– How to turn in a PDF\n– How to select pages"
  },
  {
    "objectID": "slides/lab-0-slides.html#remember",
    "href": "slides/lab-0-slides.html#remember",
    "title": "Welcome to Lab",
    "section": "Remember",
    "text": "Remember\nNo programming experience is required or expected to take this class. Come to lecture, lab and office hours. It’s okay to be confused. Stick with it, you will get the hang of it!\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/lab-2-slides.html#lab-2",
    "href": "slides/lab-2-slides.html#lab-2",
    "title": "Data Wranging + Group Formation",
    "section": "Lab 2",
    "text": "Lab 2\nThree parts for today’s lab\n– Group Formation (Do this first)\n– Team Agreement\n– Data Wrangling"
  },
  {
    "objectID": "slides/lab-2-slides.html#group-formation",
    "href": "slides/lab-2-slides.html#group-formation",
    "title": "Data Wranging + Group Formation",
    "section": "Group Formation",
    "text": "Group Formation\n– 3-4 students\n– You may choose your group\n– If you would like to work with a student who is missing, communicate this with them, other groupmates, and the TA\n– Come up with Team Name and report name + all group members to TA when ready"
  },
  {
    "objectID": "slides/lab-2-slides.html#lab-2-1",
    "href": "slides/lab-2-slides.html#lab-2-1",
    "title": "Data Wranging + Group Formation",
    "section": "Lab 2",
    "text": "Lab 2\nIs due Monday (29th) before class. You will turn in the following:\n– Team Agreement (1 per group)\n– Data Wrangling (individual assignment)\nSome groups may want to start on the data wrangling portion during lab, while others may want to start with the team agreement. Please prioritize whichever you see fit.\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "slides/projectworkday1.html#announcements",
    "href": "slides/projectworkday1.html#announcements",
    "title": "Project Work Day",
    "section": "Announcements",
    "text": "Announcements\n– Your assigned group can be found on the website here\n– Your group has a summer-project repo with your team name on GitHub. Each of you are to clone this repo. Each component of the project will be completed here.\n– Today, you will work in the proposal.qmd"
  },
  {
    "objectID": "slides/projectworkday1.html#todays-lab",
    "href": "slides/projectworkday1.html#todays-lab",
    "title": "Project Work Day",
    "section": "Today’s Lab",
    "text": "Today’s Lab\n– Find two data sets that meet the criteria. The Resources for datasets section in your project instructions are a great resource.\n– Next, you will then upload each dataset into your data folder in your summer-project repo."
  },
  {
    "objectID": "slides/projectworkday1.html#upload-data",
    "href": "slides/projectworkday1.html#upload-data",
    "title": "Project Work Day",
    "section": "Upload Data",
    "text": "Upload Data\nThere are a few ways to upload data into this data folder. I suggest the following:\n\nOn the GitHub repo website, have 1 group member click the data folder; click Add file in the top right; Click upload files; Drag your file into the repository; Click Commit Changes\nNext, have EVERY team member pull\nRepeat steps when you are ready to upload your second data set"
  },
  {
    "objectID": "slides/projectworkday1.html#data-format",
    "href": "slides/projectworkday1.html#data-format",
    "title": "Project Work Day",
    "section": "Data Format",
    "text": "Data Format\nFor this class, we have worked with csv files. These are comma separated excel files. If you have an excel file that is not a csv file, you can make it one by going to File -> Save as -> CSV UTF-8 (Comma delimited)"
  },
  {
    "objectID": "slides/projectworkday1.html#introduction-data",
    "href": "slides/projectworkday1.html#introduction-data",
    "title": "Project Work Day",
    "section": "Introduction + Data",
    "text": "Introduction + Data\n– Identify the source of the data.\n– State when and how it was originally collected (by the original data curator, not necessarily how you found the data).\n– Write a brief description of the observations.\n– Address ethical concerns about the data, if any.\nReminder, this is done in the proposal.qmd"
  },
  {
    "objectID": "slides/projectworkday1.html#research-question",
    "href": "slides/projectworkday1.html#research-question",
    "title": "Project Work Day",
    "section": "Research question",
    "text": "Research question\n– There is no recommendation to the number of variables you need to include when writing your research question. It can be between 2, it can have more than 2.\n– Your research question can (and probably will) change as you get feedback / we move through the Summer session. That’s okay for this class project!\n– You will answer this question using statistical procedures we will learn after Exam 1."
  },
  {
    "objectID": "slides/projectworkday1.html#example-research-question",
    "href": "slides/projectworkday1.html#example-research-question",
    "title": "Project Work Day",
    "section": "Example research question",
    "text": "Example research question\n– What is the relationship between baldness and age?\n– Is it possible that VEGF has an effect in plant photosynthesis?"
  },
  {
    "objectID": "slides/projectworkday1.html#incomplete-research-question",
    "href": "slides/projectworkday1.html#incomplete-research-question",
    "title": "Project Work Day",
    "section": "Incomplete research question",
    "text": "Incomplete research question\n– How are children affected by exposure to social media?\nUnclear what social media means in this context. Unclear how children are defined.\nBetter: What is the effect of Instagram Likes on the self-esteem of young children under the age of 12?"
  },
  {
    "objectID": "slides/projectworkday1.html#literature",
    "href": "slides/projectworkday1.html#literature",
    "title": "Project Work Day",
    "section": "Literature",
    "text": "Literature\n– Find one published credible article on the topic you are interested in researching. Typically, people use Google Scholar\n– Provide a one paragraph summary about the article.\n– In 1-2 sentences, explain how your research question builds on / is different than the article you have cited.\nLiterature reviews are often exhaustive. This is meant to get us initial experience with what literature reviews are and why they are important!"
  },
  {
    "objectID": "slides/projectworkday1.html#glimpse",
    "href": "slides/projectworkday1.html#glimpse",
    "title": "Project Work Day",
    "section": "glimpse",
    "text": "glimpse\nLastly, take a glimpse of your data in the proposal.qmd"
  },
  {
    "objectID": "slides/projectworkday1.html#workflow-and-formatting",
    "href": "slides/projectworkday1.html#workflow-and-formatting",
    "title": "Project Work Day",
    "section": "Workflow and formatting",
    "text": "Workflow and formatting\n– Is everyone contributing? Have a meaningful commit?\n– Does it Render?\n– Is the Repo organized? No added unnecessary documents?"
  },
  {
    "objectID": "slides/projectworkday1.html#merge-conflict-you-cant-fix",
    "href": "slides/projectworkday1.html#merge-conflict-you-cant-fix",
    "title": "Project Work Day",
    "section": "Merge Conflict You Can’t Fix?",
    "text": "Merge Conflict You Can’t Fix?\nSometimes, we create multiple merge conflicts that become “to far gone” to fix. In these circumstances for this class, we resort to the following:\n– If you do not have any work that you would like saved (all your group’s current work is on GitHub), delete your local repo by clicking the repo file in the Files tab of R and Delete.\n– Next, go re-clone the project repo.\n\n\n\n🔗 sta199-summer-1.github.io"
  },
  {
    "objectID": "workflow_formatting.html",
    "href": "workflow_formatting.html",
    "title": "Workflow and Formatting",
    "section": "",
    "text": "Common Mistakes\n1. meaningless labels\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   0.3.5\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.1     ✔ stringr 1.4.1\n✔ readr   2.1.3     ✔ forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tidyr' was built under R version 4.2.2\n\n\nWarning: package 'readr' was built under R version 4.2.2\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\niris |>\n  glimpse()\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nSome good examples\n\niris |>\n  glimpse()\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\n\niris |>\n  glimpse()\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nIf you have multiple models or plots for the homework/labs, you can number them.\n\niris_sum <- iris |>\n  as_tibble() |>\n  lm(formula = Petal.Width ~ Sepal.Width) |>\n  summary()\n\n\niris_boxplot <- iris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + geom_boxplot()\n\n2. Inconsistent use of operator\nBad examples: use both %>% and |>, both <- and = in the homework/lab.\n\niris_boxplot <- iris |>\n  as_tibble() %>%\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot()\n\n\niris_tbl <- iris |>\n  as_tibble()\niris_boxplot = ggplot(iris_tbl, aes(y = Petal.Width, x = Species)) + \n  geom_boxplot()\n\nGood examples:\n\niris_boxplot <- iris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot()\n\n\niris_tbl <- iris |>\n  as_tibble()\niris_boxplot <- ggplot(iris_tbl, aes(y = Petal.Width, x = Species)) + \n  geom_boxplot()\n\n3. Narrative and text exceeding character limit\nBad examples: text overflow. Only part of the text will appear in both coding part and plot.\n\niris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot() +\n  labs(title = \"The title is super long and exceeds the word limits. Please do not take my points off.\")\n\n\n\n\nPossible solutions: have a new line inside your code or have subtitle. It is always a good idea to do proofreading on your knitted pdf file.\n\niris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot() +\n  labs(title = \"The title is super long and exceeds the word limits.\n       Please do not take my points off.\")\n\n\n\niris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot() +\n  labs(title = \"The title is super long and exceeds the word limits.\",\n       subtitle = \"Please do not take my points off.\")\n\n\n\n\nBad examples: text overflow when the functions have a lot of arguments needed specification\n\niris_boxplot <- iris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species, fill = Species)) + \n  geom_boxplot() +\n  labs(title = \"Boxplot for petal width versus species\", x = \"species\", y = \"petal width\", fill = \"species\")\n\nA solution: represent them in separate lines\n\niris_boxplot <- iris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species, fill = Species)) + \n  geom_boxplot() +\n  labs(title = \"Boxplot for petal width versus species\", \n       x = \"species\", \n       y = \"petal width\", \n       fill = \"species\")\n\n4. Inappropriate use of spacing\nBad example: +/-/=/</| are not surrounded by spaces\n\niris_boxplot<-iris|>\n  as_tibble()|>\n  ggplot(aes(y=Petal.Width, x=Species, fill=Species))+ \n  geom_boxplot() \n\nGood example:\n\niris_boxplot <- iris |>\n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species, fill = Species)) + \n  geom_boxplot() \n\n5. New layer/pipline not begin with a newline\nThe code should be in a newline if it is a new function, such as pipeline, ggplot layers, model fitting.\nBad examples:\n\niris_boxplot <- iris |> as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot() \n\n\niris_boxplot <- iris |> \n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + geom_boxplot() \n\n\niris_boxplot <- iris |> \n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot() + ggtitle(\"Boxplot for width versus species\")\n\n\niris_sum <- iris |>\n  as_tibble() |>\n  lm(formula = Petal.Width ~ Sepal.Width) |> summary()\n\nGood examples\n\niris_boxplot <- iris |> \n  as_tibble() |>\n  ggplot(aes(y = Petal.Width, x = Species)) + \n  geom_boxplot() + \n  ggtitle(\"Boxplot for width versus species\")"
  }
]